"""
ğŸ§  ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì - ë©”ëª¨ë¦¬ ë±…í¬ ê¸°ë°˜ êµ¬ì¡°
==========================================

project_contextì˜ ìƒì„±, ê´€ë¦¬, ì ‘ê·¼ì„ ì „ë‹´í•˜ëŠ” ëª¨ë“ˆ.
ë©”ëª¨ë¦¬ ë±…í¬ ê¸°ë°˜ êµ¬ì¡°: ì½”ë“œì™€ ë°ì´í„° ë¶„ë¦¬
"""

import uuid
import datetime as dt
import os
import json

def get_memory_bank_root():
    """ë©”ëª¨ë¦¬ ë±…í¬ ë£¨íŠ¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°"""
    # 1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ í™•ì¸
    if 'MEMORY_BANK_ROOT' in os.environ:
        return os.environ['MEMORY_BANK_ROOT']
    
    # 2. Claude Desktop ì„¤ì •ì—ì„œ í™•ì¸
    config_path = os.path.expanduser("~/AppData/Roaming/Claude/claude_desktop_config.json")
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # ai-coding-brain-mcp ì„œë²„ ì„¤ì •ì—ì„œ MEMORY_BANK_ROOT ì¶”ì¶œ
            memory_root = config['mcpServers']['ai-coding-brain-mcp']['env']['MEMORY_BANK_ROOT']
            return memory_root
        except:
            pass
    
    # 3. ê¸°ë³¸ê°’
    return os.path.expanduser("~/Desktop/memory")

def initialize_context(project_path, project_name):
    """í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” (ì™„ì „ ê°œì„  ë²„ì „)
    
    1. ë©”ëª¨ë¦¬ ë±…í¬ì—ì„œ í”„ë¡œì íŠ¸ ì„¤ì • ë¡œë“œ
    2. ìºì‹œ íŒŒì¼ì—ì„œ ì´ì „ ì„¸ì…˜ ë°ì´í„° ë³µì›
    3. ëª¨ë“  ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì™„ì „í•œ context ë°˜í™˜
    """
    import os
    import json
    from datetime import datetime
    
    # ê¸°ë³¸ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡°
    project_context = {
        'project_id': project_name,
        'project_name': project_name,
        'project_path': project_path,
        'memory_path': os.path.join(get_memory_bank_root(), project_name),
        'version': 'memory_bank_based',
        'created_at': datetime.now().isoformat(),
        'session_id': None,
        
        # í•µì‹¬ ë°ì´í„° êµ¬ì¡° (ë¹ˆ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”)
        'analyzed_files': {},
        'symbol_index': {},
        'work_tracking': {},
        'tasks': {'next': [], 'done': []},
        'current_focus': None,
        'modification_log': [],
        'project_insights': {},
        
        # ìºì‹œ ê´€ë ¨
        'cache': {
            'active_file': None,
            'current_focus': None,
            'last_result': None,
            'error_count': 0
        },
        
        # í†µê³„
        'stats': {
            'total_operations': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'files_analyzed': 0
        }
    }
    
    # 1. ë©”ëª¨ë¦¬ ë±…í¬ì—ì„œ í”„ë¡œì íŠ¸ ì„¤ì • ë¡œë“œ
    try:
        memory_bank_root = get_memory_bank_root()
        project_memory_path = os.path.join(memory_bank_root, project_name)
        
        if os.path.exists(project_memory_path):
            # ğŸ”§ ë©”ëª¨ë¦¬ë±…í¬ êµ¬ì¡° ê²€ì¦ ë° ìˆ˜ì •
            issues_fixed = validate_memory_bank_structure(project_memory_path)
            if issues_fixed:
                print(f"âœ… ë©”ëª¨ë¦¬ë±…í¬ êµ¬ì¡° ìˆ˜ì •: {', '.join(issues_fixed)}")
            
            # project.json ë¡œë“œ
            project_json_path = os.path.join(project_memory_path, 'project.json')
            if os.path.exists(project_json_path):
                with open(project_json_path, 'r', encoding='utf-8') as f:
                    project_data = json.load(f)
                    project_context.update(project_data)
            
            # coding_flow.md íŒŒì‹±
            coding_flow_path = os.path.join(project_memory_path, 'coding_flow.md')
            if os.path.exists(coding_flow_path):
                with open(coding_flow_path, 'r', encoding='utf-8') as f:
                    flow_content = f.read()
                    # ê°„ë‹¨í•œ íŒŒì‹± (í•„ìš”ì‹œ ë” ì •êµí•˜ê²Œ)
                    if "## Current Focus" in flow_content:
                        start = flow_content.find("## Current Focus") + len("## Current Focus")
                        end = flow_content.find("\n##", start)
                        if end == -1:
                            end = flow_content.find("\n\n", start)
                        if end != -1:
                            focus = flow_content[start:end].strip()
                            if focus:
                                project_context['current_focus'] = focus
            
            print(f"âœ… ë©”ëª¨ë¦¬ ë±…í¬ì—ì„œ í”„ë¡œì íŠ¸ ì„¤ì • ë¡œë“œ: {project_name}")
    except Exception as e:
        print(f"âš ï¸  ë©”ëª¨ë¦¬ ë±…í¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    # 2. ìºì‹œ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    cache_file = os.path.join(project_path, f'cache_{project_name}.json')
    
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            print(f"âœ… ìºì‹œ ë¡œë“œ ì„±ê³µ: {os.path.basename(cache_file)}")
            
            # ìºì‹œ ë°ì´í„° ë³‘í•© (ì§ì ‘ì ì´ê³  ëª…í™•í•˜ê²Œ)
            # analyzed_files
            if 'analyzed_files' in cache_data and cache_data['analyzed_files']:
                project_context['analyzed_files'] = cache_data['analyzed_files']
                print(f"   â€¢ analyzed_files: {len(cache_data['analyzed_files'])}ê°œ")
            
            # symbol_index
            if 'symbol_index' in cache_data and cache_data['symbol_index']:
                project_context['symbol_index'] = cache_data['symbol_index']
                print(f"   â€¢ symbol_index: {len(cache_data['symbol_index'])}ê°œ")
            
            # work_tracking
            if 'work_tracking' in cache_data and cache_data['work_tracking']:
                project_context['work_tracking'] = cache_data['work_tracking']
                print(f"   â€¢ work_tracking: {len(cache_data['work_tracking'])}ê°œ")
            
            # tasks
            if 'tasks' in cache_data and cache_data['tasks']:
                project_context['tasks'] = cache_data['tasks']
            
            # current_focus (ìºì‹œê°€ ë” ìµœì‹ ì´ë©´ ì‚¬ìš©)
            if 'current_focus' in cache_data and cache_data['current_focus']:
                project_context['current_focus'] = cache_data['current_focus']
            
            # modification_log
            if 'modification_log' in cache_data:
                project_context['modification_log'] = cache_data['modification_log']
            
            # project_insights
            if 'project_insights' in cache_data:
                project_context['project_insights'] = cache_data['project_insights']
            
            # ì¤‘ì²©ëœ cache êµ¬ì¡° ì²˜ë¦¬ (êµ¬ë²„ì „ ìºì‹œ í˜¸í™˜ì„±)
            if 'cache' in cache_data and isinstance(cache_data['cache'], dict):
                cache_inner = cache_data['cache']
                
                # cache ë‚´ë¶€ì˜ analyzed_filesê°€ ë” ë§ìœ¼ë©´ ì‚¬ìš©
                if 'analyzed_files' in cache_inner and len(cache_inner.get('analyzed_files', {})) > len(project_context.get('analyzed_files', {})):
                    project_context['analyzed_files'] = cache_inner['analyzed_files']
                    print(f"   â€¢ analyzed_files (from cache.analyzed_files): {len(cache_inner['analyzed_files'])}ê°œ")
                
                # cache ë‚´ë¶€ì˜ symbol_indexê°€ ë” ë§ìœ¼ë©´ ì‚¬ìš©
                if 'symbol_index' in cache_inner and len(cache_inner.get('symbol_index', {})) > len(project_context.get('symbol_index', {})):
                    project_context['symbol_index'] = cache_inner['symbol_index']
                    print(f"   â€¢ symbol_index (from cache.symbol_index): {len(cache_inner['symbol_index'])}ê°œ")
                
                # cache ë‚´ë¶€ì˜ work_tracking ë³‘í•©
                if 'work_tracking' in cache_inner and cache_inner['work_tracking']:
                    if isinstance(cache_inner['work_tracking'], dict):
                        # ê¸°ì¡´ work_trackingê³¼ ë³‘í•©
                        for key, value in cache_inner['work_tracking'].items():
                            if key not in project_context['work_tracking']:
                                project_context['work_tracking'][key] = value
            
            print("âœ… ìºì‹œ ë°ì´í„°ê°€ project_contextì— ë³‘í•©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ğŸ”§ ì¤‘ìš”: ì£¼ìš” í•„ë“œë¥¼ ìµœìƒìœ„ ë ˆë²¨ë¡œë„ ë³µì‚¬ (ì§ì ‘ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)
            for key in ['analyzed_files', 'symbol_index', 'work_tracking', 
                        'current_focus', 'tasks', 'active_file']:
                if key in cache_data and key not in project_context:
                    project_context[key] = cache_data[key]
                    print(f"   âœ… {key} â†’ ìµœìƒìœ„ ë ˆë²¨ë¡œ ë³µì‚¬ë¨")
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    else:
        print(f"â„¹ï¸  ìºì‹œ íŒŒì¼ ì—†ìŒ: {cache_file}")
    
    # 3. ì‘ì—… ì¶”ì  ì´ˆê¸°í™” (ì—†ìœ¼ë©´)
    if not project_context.get('work_tracking'):
        project_context['work_tracking'] = {}
    
    # 4. ì„¸ì…˜ ID ìƒì„±
    import uuid
    project_context['session_id'] = str(uuid.uuid4())
    
    # 5. ê¸€ë¡œë²Œ project_context ì—…ë°ì´íŠ¸ (ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)
    globals()['project_context'] = project_context
    
    # 6. ìµœì¢… í™•ì¸ ì¶œë ¥
    print(f"\nğŸ“Š ì´ˆê¸°í™” ì™„ë£Œ:")
    print(f"   â€¢ í”„ë¡œì íŠ¸: {project_context['project_name']}")
    print(f"   â€¢ ë¶„ì„ëœ íŒŒì¼: {len(project_context.get('analyzed_files', {}))}ê°œ")
    print(f"   â€¢ ì‹¬ë³¼ ì¸ë±ìŠ¤: {len(project_context.get('symbol_index', {}))}ê°œ")
    print(f"   â€¢ ì‘ì—… ì¶”ì : {len(project_context.get('work_tracking', {}))}ê°œ")
    print(f"   â€¢ í˜„ì¬ í¬ì»¤ìŠ¤: {project_context.get('current_focus', 'None')}")
    
    return project_context
def trigger_vibe_sync(context, trigger_reason: str):
    """Vibe Memory ë™ê¸°í™”ë¥¼ ìœ„í•œ ë‹¨ì¼ í†µí•© íŠ¸ë¦¬ê±° í•¨ìˆ˜"""
    # 1. ì‹¤ì‹œê°„ ë™ê¸°í™”ê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if not context.get('sync_status', {}).get('realtime_enabled', False):
        return False

    # 2. Vibe Memory ì‹œìŠ¤í…œì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    if not VIBE_MEMORY_AVAILABLE:
        return False

    try:
        # 3. ìºì‹œì˜ í˜„ì¬ ìƒíƒœë¥¼ .md íŒŒì¼ì— ì¦‰ì‹œ ë™ê¸°í™”
        print(f"ğŸ”„ Vibe Sync Triggered by: {trigger_reason}")
        sync_to_vibe_memory(context, trigger=trigger_reason)
        return True
    except Exception as e:
        print(f"âŒ Vibe Sync Trigger ì‹¤íŒ¨: {e}")
        return False



def propose_next_steps(context: dict, limit: int = 3) -> list:
    """
    í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì— í•  ì¼ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    
    Args:
        context: project_context
        limit: ìµœëŒ€ ì œì•ˆ ê°œìˆ˜
        
    Returns:
        list: ì œì•ˆ ëª©ë¡ [{type, text, priority, rationale}, ...]
    """
    if 'cache' not in context or 'work_tracking' not in context.get('cache', {}):
        return []

    suggestions = []
    summary = get_work_tracking_summary(context)

    # 1. ê°€ì¥ ë§ì´ ì ‘ê·¼í•œ íŒŒì¼ ê¸°ë°˜ Focus ì œì•ˆ
    most_accessed = summary.get('most_accessed_files', [])
    # access_data ì²˜ë¦¬
    file_path, access_data = most_accessed[0]
    access_count = access_data.get('access_count', 0) if isinstance(access_data, dict) else access_data
    if most_accessed and len(most_accessed) > 0 and access_count > 5:  # 5íšŒ ì´ìƒ ì ‘ê·¼ ì‹œ
        file_path = most_accessed[0][0]
        suggestions.append({
            'type': 'focus',
            'text': f"'{os.path.basename(file_path)}' ê´€ë ¨ ê¸°ëŠ¥ì— ì§‘ì¤‘í•˜ê¸°",
            'priority': 0.9,
            'rationale': f"ìµœê·¼ í•´ë‹¹ íŒŒì¼ì„ {most_accessed[0][1]}íšŒ ì ‘ê·¼í–ˆìŠµë‹ˆë‹¤."
        })

    # 2. ê°€ì¥ ë§ì´ ìˆ˜ì •í•œ í•¨ìˆ˜ ê¸°ë°˜ Task ì œì•ˆ
    most_edited = summary.get('most_edited_functions', [])
    if most_edited and len(most_edited) > 0 and most_edited[0][1] > 3:  # 3íšŒ ì´ìƒ ìˆ˜ì • ì‹œ
        func_key = most_edited[0][0]
        func_name = func_key.split('::')[-1] if '::' in func_key else func_key
        suggestions.append({
            'type': 'task',
            'text': f"'{func_name}' í•¨ìˆ˜ ì•ˆì •í™” ë˜ëŠ” ë¦¬íŒ©í† ë§",
            'priority': 0.8,
            'rationale': f"ìµœê·¼ í•´ë‹¹ í•¨ìˆ˜ë¥¼ {most_edited[0][1]}íšŒ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤."
        })

    # 3. ìµœê·¼ ì‘ì—… íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì œì•ˆ
    history = summary.get('recent_history', [])
    for op in history[:10]:  # ìµœê·¼ 10ê°œë§Œ í™•ì¸
        if op.get('operation') == 'create_file':
            file_path = op.get('file', '')
            if file_path:
                suggestions.append({
                    'type': 'task',
                    'text': f"'{os.path.basename(file_path)}' ê¸°ë³¸ ê¸°ëŠ¥ êµ¬í˜„í•˜ê¸°",
                    'priority': 0.7,
                    'rationale': "ìµœê·¼ ìƒˆë¡­ê²Œ ìƒì„±ëœ íŒŒì¼ì…ë‹ˆë‹¤."
                })
                break  # ê°€ì¥ ìµœê·¼ ìƒì„±ëœ íŒŒì¼ í•˜ë‚˜ë§Œ ì œì•ˆ
                
    # 4. TODO/FIXME ê¸°ë°˜ ì œì•ˆ
    if 'analyzed_files' in context.get('cache', {}):
        for file_path, analysis in context['cache']['analyzed_files'].items():
            if 'todos' in analysis:
                for todo in analysis['todos'][:2]:  # íŒŒì¼ë‹¹ ìµœëŒ€ 2ê°œ
                    suggestions.append({
                        'type': 'task',
                        'text': f"TODO í•´ê²°: {todo.get('text', 'Unknown')}",
                        'priority': 0.6,
                        'rationale': f"{os.path.basename(file_path)}ì— ìˆëŠ” ë¯¸ì™„ì„± ì‘ì—…"
                    })

    # 5. ì˜¤ë¥˜ê°€ ë°œìƒí•œ íŒŒì¼ì— ëŒ€í•œ ì œì•ˆ
    if 'error_history' in context.get('cache', {}):
        recent_errors = context['cache']['error_history'][-3:]  # ìµœê·¼ 3ê°œ
        for error in recent_errors:
            if 'file' in error:
                suggestions.append({
                    'type': 'task',
                    'text': f"'{os.path.basename(error['file'])}' ì˜¤ë¥˜ ìˆ˜ì •",
                    'priority': 0.85,
                    'rationale': f"ìµœê·¼ ë°œìƒí•œ ì˜¤ë¥˜: {error.get('type', 'Unknown')}"
                })

    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œ ë°˜í™˜
    suggestions.sort(key=lambda x: x['priority'], reverse=True)
    return suggestions[:limit]



def sync_state_to_plan(context: dict):
    """
    ìºì‹œì— ê¸°ë¡ëœ í˜„ì¬ ì‘ì—… ìƒíƒœ(State)ë¥¼ Vibe Memoryì˜ ê³„íš(Plan)ì— ë™ê¸°í™”í•©ë‹ˆë‹¤.
    (ì˜ˆ: í˜„ì¬ ì‘ì—… íŒŒì¼ ëª©ë¡, ìë™ ê°ì§€ëœ í¬ì»¤ìŠ¤ ë“±)
    
    Args:
        context: project_context
        
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    if 'cache' not in context:
        return False
    
    try:
        summary = get_work_tracking_summary(context)
        
        # 1. í˜„ì¬ ì‘ì—… íŒŒì¼ ëª©ë¡ì„ Vibe Memoryì— ì—…ë°ì´íŠ¸
        most_accessed = summary.get('most_accessed_files', [])
        if most_accessed and 'live_context' in context:
            # ìƒìœ„ 5ê°œ íŒŒì¼ì„ ì‘ì—… íŒŒì¼ë¡œ ì„¤ì •
            working_files = [f[0] for f in most_accessed[:5]]
            
            # live_context ì—…ë°ì´íŠ¸
            if 'coding_flow' not in context['live_context']:
                context['live_context']['coding_flow'] = {}
            
            context['live_context']['coding_flow']['working_files'] = working_files
            print(f"ğŸ“ ì‘ì—… íŒŒì¼ ìë™ ì—…ë°ì´íŠ¸: {len(working_files)}ê°œ")
        
        # 2. í˜„ì¬ í¬ì»¤ìŠ¤ ìë™ ê°ì§€ ë° ì—…ë°ì´íŠ¸
        if most_accessed and len(most_accessed) > 0:
            top_file = most_accessed[0][0]
            access_count = most_accessed[0][1]
            
            # ì ‘ê·¼ íšŸìˆ˜ê°€ 10íšŒ ì´ìƒì´ë©´ ìë™ìœ¼ë¡œ í¬ì»¤ìŠ¤ ë³€ê²½ ì œì•ˆ
            if access_count >= 10:
                suggested_focus = f"Working on {os.path.basename(top_file)}"
                if 'current_focus' in context.get('cache', {}):
                    current_focus = context['cache'].get('current_focus', '')
                    if current_focus != suggested_focus:
                        print(f"ğŸ’¡ í¬ì»¤ìŠ¤ ë³€ê²½ ì œì•ˆ: '{suggested_focus}' (íŒŒì¼ì„ {access_count}íšŒ ì ‘ê·¼)")
        
        # 3. ì‘ì—… íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ë™ê¸°í™”
        work_pattern = {
            'total_files_accessed': len(summary.get('accessed_files', [])),
            'total_functions_edited': len(summary.get('edited_functions', [])),
            'active_period': summary.get('active_time_range', 'Unknown'),
            'primary_operation': summary.get('primary_operation', 'coding')
        }
        
        if 'stats' not in context:
            context['stats'] = {}
        context['stats']['work_pattern'] = work_pattern
        
        # 4. AI ì œì•ˆì„ live_contextì— í¬í•¨
        suggestions = propose_next_steps(context, limit=5)
        if suggestions and 'live_context' in context:
            context['live_context']['ai_suggestions'] = suggestions
            print(f"ğŸ¤– AI ì œì•ˆ {len(suggestions)}ê°œê°€ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€ë¨")
        
        # 5. ë™ê¸°í™” íŠ¸ë¦¬ê±° í˜¸ì¶œ
        trigger_vibe_sync(context, trigger_reason='sync_state_to_plan')
        print("âœ… ìë™ ìƒíƒœâ†’ê³„íš ë™ê¸°í™” ì™„ë£Œ")
        
        return True
        
    except Exception as e:
        print(f"âŒ sync_state_to_plan ì˜¤ë¥˜: {str(e)}")
        return False


def update_cache(context, key, value):
    """
    ìºì‹œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    
    Args:
        context (dict): project_context
        key (str): ì—…ë°ì´íŠ¸í•  í‚¤
        value: ì—…ë°ì´íŠ¸í•  ê°’
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    if not context or not isinstance(context, dict):
        print("âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ project_contextì…ë‹ˆë‹¤.")
        return False
        
    # 'cache' í‚¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if "cache" not in context:
        context['cache'] = {
        'files': {},
        'analyzed_files': {},
        'symbol_index': {},
        'file_summaries': {},
        'vibe_synced': {},
        'last_sync': None
    }
        print("âš ï¸ project_contextì— 'cache' í‚¤ê°€ ì—†ì–´ì„œ ìë™ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    
    context['cache'][key] = value
    
    # 'stats' í‚¤ë„ í™•ì¸
    if 'stats' not in context:
        context['stats'] = {
            'total_operations': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'files_analyzed': 0,
            'cache_evictions': 0
        }
    
    context['stats']['total_operations'] += 1
    
    # íŠ¹ì • í‚¤ì— ëŒ€í•œ ì¶”ê°€ ì²˜ë¦¬
    if key == 'active_file':
        print(f"âœ… í™œì„± íŒŒì¼ ë³€ê²½: {value}")
    
    # --- âœ¨ ë™ê¸°í™” ë¡œì§ í†µí•© âœ¨ ---
    # Vibe Memoryì™€ ë™ê¸°í™”ê°€ í•„ìš”í•œ ì¤‘ìš”í•œ í‚¤ ëª©ë¡
    important_keys_for_sync = [
        'current_focus', 'active_file', 
        'analyzed_files', 'symbol_index'
    ]

    if key in important_keys_for_sync:
        # ë‹¨ì¼ íŠ¸ë¦¬ê±° í•¨ìˆ˜ í˜¸ì¶œ
        trigger_vibe_sync(context, trigger_reason=f"cache_update_on_{key}")
        
        # Phase 2: ìƒíƒœ->ê³„íš ìë™ ë™ê¸°í™”
        if key in ['active_file', 'current_focus']:
            try:
                sync_state_to_plan(context)
            except Exception as e:
                print(f"âš ï¸ ìƒíƒœ-ê³„íš ë™ê¸°í™” ì‹¤íŒ¨: {e}")
    
    return True

def build_index(context, analyzed_files=None):
    """
    ì‹¬ë³¼ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    
    Args:
        context (dict): project_context
        analyzed_files (dict, optional): ë¶„ì„ëœ íŒŒì¼ ë°ì´í„°
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    print("âœ… ì‹¬ë³¼ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘...")
    symbol_index = {}
    
    # ë¶„ì„í•  íŒŒì¼ ë°ì´í„° ê²°ì •
    files_to_index = analyzed_files or context.get("cache", {}).get("analyzed_files", {})
    
    if not files_to_index:
        print("âš ï¸ ì¸ë±ì‹±í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    for file_path, analysis_data in files_to_index.items():
        if not isinstance(analysis_data, dict):
            continue
        
        # í•¨ìˆ˜ ì¸ë±ì‹±
        for func in analysis_data.get("functions", []):
            if func.get("name"):
                symbol_index[func["name"]] = file_path
        
        # í´ë˜ìŠ¤ ë° ë©”ì„œë“œ ì¸ë±ì‹±
        for class_info in analysis_data.get("classes", []):
            class_name = class_info.get("name")
            if class_name:
                symbol_index[class_name] = file_path
                
                # í´ë˜ìŠ¤ ë©”ì„œë“œ ì¸ë±ì‹±
                for method in class_info.get("methods", []):
                    method_name = method.get("name")
                    if method_name:
                        symbol_index[f"{class_name}.{method_name}"] = file_path
    
    context["cache"]["symbol_index"] = symbol_index
    print(f"âœ… ì‹¬ë³¼ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ. {len(symbol_index)}ê°œ í•­ëª© ì¸ë±ì‹±ë¨.")
    return True

def get_value(context, key, default=None):
    """
    ìºì‹œì—ì„œ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        context (dict): project_context
        key (str): ê°€ì ¸ì˜¬ í‚¤
        default: ê¸°ë³¸ê°’
    
    Returns:
        Any: ì°¾ì€ ê°’ ë˜ëŠ” ê¸°ë³¸ê°’
    """
    if not context or not isinstance(context, dict):
        return default
        
    # 'cache' í‚¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if "cache" not in context:
        context['cache'] = {
        'files': {},
        'analyzed_files': {},
        'symbol_index': {},
        'file_summaries': {},
        'vibe_synced': {},
        'last_sync': None
    }
        print("âš ï¸ project_contextì— 'cache' í‚¤ê°€ ì—†ì–´ì„œ ìë™ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    
    value = context["cache"].get(key, default)
    
    # 'stats' í‚¤ë„ í™•ì¸
    if 'stats' not in context:
        context['stats'] = {
            'total_operations': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'files_analyzed': 0,
            'cache_evictions': 0
        }
    
    if value != default:
        context['stats']['cache_hits'] += 1
    else:
        context['stats']['cache_misses'] += 1
    
    return value

def find_symbol(context, symbol_name):
    """
    ì‹¬ë³¼ì˜ íŒŒì¼ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        context (dict): project_context
        symbol_name (str): ì°¾ì„ ì‹¬ë³¼ ì´ë¦„
    
    Returns:
        str: íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    symbol_index = get_value(context, "symbol_index", {})
    return symbol_index.get(symbol_name)

def add_operation(context, operation):
    """
    ì‘ì—… ê¸°ë¡ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        context (dict): project_context
        operation (dict): ì‘ì—… ì •ë³´
    """
    if not context or "cache" not in context:
        return
    
    recent_ops = context["cache"].get("recent_operations", [])
    
    # ì‘ì—… ì •ë³´ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
    operation["timestamp"] = dt.datetime.now().isoformat()
    
    # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
    recent_ops.append(operation)
    if len(recent_ops) > 100:
        recent_ops = recent_ops[-100:]
    
    context["cache"]["recent_operations"] = recent_ops
    context['stats']['total_operations'] += 1

def update_file_summary(context, file_path, analysis_result):
    """
    íŒŒì¼ ë¶„ì„ ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    
    Args:
        context (dict): project_context
        file_path (str): íŒŒì¼ ê²½ë¡œ
        analysis_result (dict): ë¶„ì„ ê²°ê³¼
    """
    if not context or "cache" not in context:
        return False
    
    summary = {
        "timestamp": dt.datetime.now().isoformat(),
        "functions": len(analysis_result.get("functions", [])),
        "classes": len(analysis_result.get("classes", [])),
        "lines": analysis_result.get("total_lines", 0),
        "has_errors": analysis_result.get("has_errors", False)
    }
    
    context["cache"]["file_summaries"][file_path] = summary
    context["cache"]["analyzed_files"][file_path] = analysis_result
    context['stats']['files_analyzed'] += 1
    
    print(f"âœ… íŒŒì¼ ë¶„ì„ ìš”ì•½ ì—…ë°ì´íŠ¸: {file_path}")
    return True

def get_statistics(context):
    """
    í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        context (dict): project_context
    
    Returns:
        dict: í†µê³„ ì •ë³´
    """
    if not context:
        return {}
    
    stats = context.get("stats", {})
    cache = context.get("cache", {})
    
    # ì¶”ê°€ í†µê³„ ê³„ì‚°
    total_symbols = len(cache.get("symbol_index", {}))
    total_files = len(cache.get("analyzed_files", {}))
    
    return {
        "cache_hits": stats.get("cache_hits", 0),
        "cache_misses": stats.get("cache_misses", 0),
        "hit_rate": stats.get("cache_hits", 0) / max(stats.get("cache_hits", 0) + stats.get("cache_misses", 0), 1),
        "total_operations": stats.get("total_operations", 0),
        "total_analyzed_files": total_files,
        "total_indexed_symbols": total_symbols,
        "session_id": context.get("session_id"),
        "version": context.get("version")
    }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    new_context = initialize_context()
    print("\n--- ìƒì„±ëœ 2ê³„ì¸µ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡° ---")
    import json
    print(json.dumps(new_context, indent=2, ensure_ascii=False))
    
    # í†µê³„ ì¶œë ¥
    stats = get_statistics(new_context)
    print("\n--- ìºì‹œ í†µê³„ ---")
    print(json.dumps(stats, indent=2, ensure_ascii=False))


# ============================================================================
# Vibe Memory System í†µí•© í•¨ìˆ˜ë“¤
# ============================================================================

# Vibe Memory System ë™ì  import
try:
    import vibe_memory_system
    VIBE_MEMORY_AVAILABLE = True
except ImportError:
    VIBE_MEMORY_AVAILABLE = False
    print("âš ï¸ Vibe Memory Systemì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def integrate_vibe_memory(context, auto_sync=True):
    """
    Vibe Memory Systemì„ Context Managerì— í†µí•©
    
    Args:
        context (dict): project_context
        auto_sync (bool): ìë™ ë™ê¸°í™” í™œì„±í™” ì—¬ë¶€
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    if not VIBE_MEMORY_AVAILABLE:
        print("âš ï¸ Vibe Memory Systemì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return False
    
    try:
        # 1. memory_bank ì •ë³´ ì¶”ê°€
        memory_path = vibe_memory_system._sync_project_context_with_memory_bank(context)
        print(f"âœ… Memory Bank ì—°ë™: {memory_path}")
        
        # 2. live_context ë¡œë“œ
        vibe_memory_system._load_live_context_from_memory(context)
        print(f"âœ… Live Context ë¡œë“œ ì™„ë£Œ")
        
        # 3. ìë™ ë™ê¸°í™” ì„¤ì •
        if auto_sync:
            context['sync_status'] = {
                'auto_sync': True,
                'last_sync': dt.datetime.now().isoformat(),
                'pending_changes': []
            }
        
        # 4. ìºì‹œì— vibe ìƒíƒœ ì¶”ê°€
        context['cache']['vibe_integrated'] = True
        context['cache']['vibe_memory_path'] = memory_path
        
        print(f"âœ… Vibe Memory í†µí•© ì™„ë£Œ (auto_sync={auto_sync})")
        return True
        
    except Exception as e:
        print(f"âŒ Vibe Memory í†µí•© ì‹¤íŒ¨: {e}")
        return False

def sync_vibe_memory(context, direction='both'):
    """
    Vibe Memory ë™ê¸°í™” ì‹¤í–‰
    
    Args:
        context (dict): project_context
        direction (str): 'to', 'from', 'both'
    
    Returns:
        dict: ë™ê¸°í™” ê²°ê³¼
    """
    if not VIBE_MEMORY_AVAILABLE:
        return {'success': False, 'message': 'Vibe Memory not available'}
    
    if 'memory_bank' not in context:
        return {'success': False, 'message': 'Vibe not integrated'}
    
    try:
        results = []
        
        if direction in ['to', 'both']:
            vibe_memory_system._sync_live_context_to_memory(context)
            results.append('to_memory')
            print("âœ… ìºì‹œ â†’ íŒŒì¼ ë™ê¸°í™” ì™„ë£Œ")
        
        if direction in ['from', 'both']:
            vibe_memory_system._load_live_context_from_memory(context)
            results.append('from_memory')
            print("âœ… íŒŒì¼ â†’ ìºì‹œ ë™ê¸°í™” ì™„ë£Œ")
        
        return {'success': True, 'synced': results, 'timestamp': dt.datetime.now().isoformat()}
        
    except Exception as e:
        return {'success': False, 'error': str(e)}

def update_vibe_focus(context, new_focus):
    """
    Vibe Memoryì˜ í˜„ì¬ í¬ì»¤ìŠ¤ ì—…ë°ì´íŠ¸
    
    Args:
        context (dict): project_context
        new_focus (str): ìƒˆë¡œìš´ í¬ì»¤ìŠ¤
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    if not VIBE_MEMORY_AVAILABLE:
        return False
    
    try:
        if 'live_context' in context and 'coding_flow' in context['live_context']:
            context['live_context']['coding_flow']['current_focus'] = new_focus
            context['live_context']['coding_flow']['last_updated'] = dt.datetime.now().isoformat()
            
            # ìë™ ë™ê¸°í™”
            if context.get('sync_status', {}).get('auto_sync'):
                vibe_memory_system._auto_sync_hook(context, trigger='focus_update')
            
            return True
        return False
        
    except Exception as e:
        print(f"âŒ Vibe focus ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False


# ============================================================================
# Vibe Memory ì‹¤ì‹œê°„ ë™ê¸°í™” í•¨ìˆ˜ë“¤ (Context Manager ê°œì„ )
# ============================================================================

def sync_to_vibe_memory(context, trigger='manual'):
    """
    Context Manager â†’ Vibe Memory ì¦‰ì‹œ ë™ê¸°í™”
    ìºì‹œ ë³€ê²½ì‚¬í•­ì„ ë¡œì»¬ .md íŒŒì¼ì— ì‹¤ì‹œê°„ ë°˜ì˜
    """
    if not VIBE_MEMORY_AVAILABLE:
        return False
    
    try:
        # 1. í˜„ì¬ ì‘ì—… ìƒíƒœ ë™ê¸°í™”
        if 'cache' in context:
            cache = context['cache']
            
            # ì‘ì—… ì¤‘ì¸ íŒŒì¼ ëª©ë¡ ë™ê¸°í™”
            if 'analyzed_files' in cache:
                working_files = list(cache['analyzed_files'].keys())[-5:]
                update_vibe_working_files(context, working_files)
            
            # í˜„ì¬ í¬ì»¤ìŠ¤ ë™ê¸°í™”
            if 'current_focus' in cache:
                update_vibe_focus(context, cache['current_focus'])
            
            # ì‹¬ë³¼ ì¸ë±ìŠ¤ ì •ë³´ ë™ê¸°í™”
            if 'symbol_index' in cache and len(cache['symbol_index']) > 0:
                update_vibe_code_insights(context, cache['symbol_index'])
        
        # 2. ë¡œì»¬ íŒŒì¼ì— ì¦‰ì‹œ ì“°ê¸°
        vibe_memory_system._sync_live_context_to_memory(context)
        
        # 3. ë™ê¸°í™” íƒ€ì„ìŠ¤íƒ¬í”„ ì—…ë°ì´íŠ¸
        if 'sync_status' not in context:
            context['sync_status'] = {}
        context['sync_status']['last_realtime_sync'] = dt.datetime.now().isoformat()
        context['sync_status']['sync_trigger'] = trigger
        
        print(f"âœ… Vibe Memory ì‹¤ì‹œê°„ ë™ê¸°í™” ì™„ë£Œ (trigger: {trigger})")
        return True
        
    except Exception as e:
        print(f"âŒ Vibe Memory ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def update_vibe_working_files(context, file_list):
    """ì‘ì—… íŒŒì¼ ëª©ë¡ì„ Vibeì— ì—…ë°ì´íŠ¸"""
    if 'live_context' not in context:
        context['live_context'] = {}
    
    if 'coding_flow' not in context['live_context']:
        context['live_context']['coding_flow'] = {}
    
    # íŒŒì¼ëª…ë§Œ ì¶”ì¶œí•˜ì—¬ ì €ì¥
    file_names = [os.path.basename(f) for f in file_list if f]
    context['live_context']['coding_flow']['working_files'] = file_names
    context['live_context']['coding_flow']['files_count'] = len(file_names)
    context['live_context']['coding_flow']['last_updated'] = dt.datetime.now().isoformat()

def update_vibe_code_insights(context, symbol_index):
    """ì½”ë“œ ë¶„ì„ ì¸ì‚¬ì´íŠ¸ë¥¼ Vibeì— ì—…ë°ì´íŠ¸"""
    if 'live_context' not in context:
        context['live_context'] = {}
    
    if 'code_analysis' not in context['live_context']:
        context['live_context']['code_analysis'] = {}
    
    # ì‹¬ë³¼ í†µê³„ ìƒì„±
    stats = {
        'total_symbols': len(symbol_index),
        'files_indexed': len(set(symbol_index.values())),
        'last_analysis': dt.datetime.now().isoformat()
    }
    
    context['live_context']['code_analysis']['stats'] = stats
    context['live_context']['code_analysis']['recent_symbols'] = list(symbol_index.keys())[-10:]

def enable_realtime_sync(context, enabled=True, write_immediately=True):
    """
    ì‹¤ì‹œê°„ ë™ê¸°í™” í™œì„±í™”/ë¹„í™œì„±í™”
    
    Args:
        context: project_context
        enabled: í™œì„±í™” ì—¬ë¶€
        write_immediately: ë³€ê²½ ì‹œ ì¦‰ì‹œ íŒŒì¼ ì“°ê¸° ì—¬ë¶€
    """
    if 'sync_status' not in context:
        context['sync_status'] = {}
    
    context['sync_status']['realtime_enabled'] = enabled
    context['sync_status']['write_immediately'] = write_immediately
    
    if enabled:
        print(f"âœ… ì‹¤ì‹œê°„ ë™ê¸°í™” í™œì„±í™” (ì¦‰ì‹œ ì“°ê¸°: {write_immediately})")
        # í™œì„±í™” ì‹œ ì¦‰ì‹œ í•œë²ˆ ë™ê¸°í™”
        sync_to_vibe_memory(context, trigger='realtime_enabled')
    else:
        print("â¸ï¸ ì‹¤ì‹œê°„ ë™ê¸°í™” ë¹„í™œì„±í™”")
    
    return True

# update_cache í•¨ìˆ˜ ê°œì„ : ì¦‰ì‹œ ë™ê¸°í™” ì¶”ê°€
def update_cache_enhanced(context, key, value):
    """
    (Deprecated) update_cacheë¡œ ê¸°ëŠ¥ì´ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    return update_cache(context, key, value)
# ============================================================================
# Project ID ê¸°ë°˜ ìºì‹œ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# ============================================================================

def _try_load_cached_context(project_path, project_name):
    """ìºì‹œëœ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì‹œë„ (ê°œì„ ëœ ë²„ì „ - .cache/ ë””ë ‰í† ë¦¬ ì‚¬ìš©)"""
    # .cache ë””ë ‰í† ë¦¬ ê²½ë¡œ
    cache_dir = os.path.join(project_path, '.cache')
    cache_filename = f'cache_{project_name}.json'
    
    # ìš°ì„ ìˆœìœ„: .cache/ > í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ë ˆê±°ì‹œ)
    cache_file = os.path.join(cache_dir, cache_filename)
    legacy_cache_file = os.path.join(project_path, cache_filename)
    
    # ë ˆê±°ì‹œ ìºì‹œ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
    if not os.path.exists(cache_file) and os.path.exists(legacy_cache_file):
        print(f"ğŸ”„ ë ˆê±°ì‹œ ìºì‹œ íŒŒì¼ ë°œê²¬, .cache/ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜")
        os.makedirs(cache_dir, exist_ok=True)
        import shutil
        shutil.copy2(legacy_cache_file, cache_file)
    
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            print(f"âœ… ìºì‹œ ë¡œë“œ ì„±ê³µ: .cache/{cache_filename}")
            
            # ìºì‹œ ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° í‰íƒ„í™”
            result = {}
            
            # ì¤‘ì²©ëœ êµ¬ì¡° ì²˜ë¦¬
            if 'cache' in cache_data:
                # cache ë‚´ë¶€ì˜ ë°ì´í„°ë¥¼ ìµœìƒìœ„ë¡œ ì´ë™
                cache_inner = cache_data.get('cache', {})
                result['symbol_index'] = cache_inner.get('symbol_index', {})
                result['analyzed_files'] = cache_inner.get('analyzed_files', {})
                result['work_tracking'] = cache_inner.get('work_tracking', {})
            
            # ìµœìƒìœ„ ë ˆë²¨ ë°ì´í„° ë³‘í•©
            for key in ['symbol_index', 'analyzed_files', 'work_tracking', 'tasks', 
                       'current_focus', 'modification_log', 'project_insights']:
                if key in cache_data and key not in result:
                    result[key] = cache_data[key]
            
            # ê¸°íƒ€ ë©”íƒ€ë°ì´í„°
            result['project_id'] = cache_data.get('project_id', project_name)
            result['project_path'] = cache_data.get('project_path', project_path)
            
            # .cache ë””ë ‰í† ë¦¬ ê²½ë¡œ ì €ì¥
            result['cache_dir'] = cache_dir
            
            # í†µê³„ ì¶œë ¥
            print(f"   â€¢ symbol_index: {len(result.get('symbol_index', {}))}ê°œ")
            print(f"   â€¢ analyzed_files: {len(result.get('analyzed_files', {}))}ê°œ")
            print(f"   â€¢ work_tracking: {len(result.get('work_tracking', {}))}ê°œ")
            
            return result
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    else:
        print(f"â„¹ï¸ ìºì‹œ íŒŒì¼ ì—†ìŒ: .cache/{cache_filename}")
        # .cache ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(cache_dir, exist_ok=True)
        return None
def save_project_cache(project_context):
    """í”„ë¡œì íŠ¸ ìºì‹œ ì €ì¥ (ê°œì„ ëœ ë²„ì „ - .cache/ ë””ë ‰í† ë¦¬ ì‚¬ìš©)"""
    from datetime import datetime
    if not project_context:
        print("âŒ ì €ì¥í•  contextê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    project_id = project_context.get('project_id', 'unknown')
    project_path = project_context.get('project_path', os.getcwd())
    
    # .cache ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„±
    cache_dir = os.path.join(project_path, '.cache')
    os.makedirs(cache_dir, exist_ok=True)
    
    cache_filename = f'cache_{project_id}.json'
    cache_file = os.path.join(cache_dir, cache_filename)
    
    # ì €ì¥í•  ë°ì´í„° êµ¬ì„± (í‰íƒ„í•œ êµ¬ì¡°)
    cache_data = {
        'project_id': project_id,
        'project_name': project_context.get('project_name', project_id),
        'project_path': project_path,
        'analyzed_files': project_context.get('analyzed_files', {}),
        'symbol_index': project_context.get('symbol_index', {}),
        'work_tracking': project_context.get('work_tracking', {}),
        'tasks': project_context.get('tasks', {'next': [], 'done': []}),
        'current_focus': project_context.get('current_focus'),
        'modification_log': project_context.get('modification_log', []),
        'project_insights': project_context.get('project_insights', {}),
        'last_updated': datetime.now().isoformat()
    }
    
    # ê¸°ì¡´ ìºì‹œì™€ ë³‘í•© (í•„ìš”ì‹œ)
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                existing = json.load(f)
            # ì¤‘ìš”í•œ ë°ì´í„°ëŠ” ë³´ì¡´
            if 'cache' in existing and 'symbol_index' in existing['cache']:
                if not cache_data['symbol_index']:
                    cache_data['symbol_index'] = existing['cache']['symbol_index']
        except:
            pass
    
    # ì €ì¥
    try:
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… í”„ë¡œì íŠ¸ ìºì‹œ ì €ì¥: .cache/{cache_filename}")
        print(f"   - analyzed_files: {len(cache_data['analyzed_files'])} íŒŒì¼")
        print(f"   - symbol_index: {len(cache_data['symbol_index'])} í•­ëª©")
        return True
    except Exception as e:
        print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False
def load_project_cache(context):
    """
    ì €ì¥ëœ ìºì‹œì—ì„œ work_tracking í¬í•¨í•œ ëª¨ë“  ë°ì´í„° ë³µì›
    
    Args:
        context (dict): project_context
        
    Returns:
        bool: ë³µì› ì„±ê³µ ì—¬ë¶€
    """
    try:
        # .ai-brain-project íŒŒì¼ ìš°ì„  í™•ì¸
        brain_file = os.path.join(context['memory_path'], '.ai-brain-project')
        if os.path.exists(brain_file):
            with open(brain_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
                
            # work_tracking ë³µì›
            if 'work_tracking' in saved_data:
                if 'cache' not in context:
                    context['cache'] = {}
                context['cache']['work_tracking'] = saved_data['work_tracking']
                print(f"âœ… work_tracking ë°ì´í„° ë³µì›: {len(saved_data['work_tracking'])} í•­ëª©")
                
            # stats ë³µì›
            if 'stats' in saved_data:
                context['stats'].update(saved_data['stats'])
                
            return True
            
        # ìºì‹œ ë””ë ‰í† ë¦¬ì—ì„œë„ ì‹œë„
        cache_file = context['storage'].get('cache_file')
        if cache_file:
            cache_path = os.path.join(context['storage']['base_path'], '.cache', cache_file)
            if os.path.exists(cache_path):
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    
                if cache_data.get('project_id') == context.get('project_id'):
                    # work_tracking ë³µì›
                    if 'work_tracking' in cache_data:
                        context['cache']['work_tracking'] = cache_data['work_tracking']
                    return True
                    
    except Exception as e:
        print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        
    return False

def validate_project_id(context, expected_path):
    """
    í˜„ì¬ í”„ë¡œì íŠ¸ IDê°€ ì˜ˆìƒ ê²½ë¡œì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦
    
    Args:
        context (dict): project_context
        expected_path (str): ì˜ˆìƒ í”„ë¡œì íŠ¸ ê²½ë¡œ
    
    Returns:
        bool: ì¼ì¹˜ ì—¬ë¶€
    """
    import hashlib
    
    current_id = context.get('project_id')
    if not current_id:
        return False
    
    # ì˜ˆìƒ ID ê³„ì‚°
    normalized_path = os.path.abspath(expected_path).lower()
    expected_id = hashlib.sha256(normalized_path.encode('utf-8')).hexdigest()[:12]
    
    if current_id != expected_id:
        print(f"âš ï¸ í”„ë¡œì íŠ¸ ID ë¶ˆì¼ì¹˜!")
        print(f"  - í˜„ì¬ ID: {current_id}")
        print(f"  - ì˜ˆìƒ ID: {expected_id}")
        return False
    
    return True

# ============================================================================
# mtime ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™” í•¨ìˆ˜ë“¤
# ============================================================================

def validate_cache_entry(context, file_path):
    """
    ìºì‹œ ì—”íŠ¸ë¦¬ê°€ ìœ íš¨í•œì§€ mtimeìœ¼ë¡œ ê²€ì¦
    
    Args:
        context (dict): project_context
        file_path (str): ê²€ì¦í•  íŒŒì¼ ê²½ë¡œ
    
    Returns:
        bool: ìºì‹œê°€ ìœ íš¨í•œì§€ ì—¬ë¶€
    """
    cache = context.get('cache', {})
    analyzed_files = cache.get('analyzed_files', {})
    
    if file_path not in analyzed_files:
        return False
    
    # mtime ê²€ì‚¬ê°€ ë¹„í™œì„±í™”ëœ ê²½ìš°
    if not cache.get('cache_config', {}).get('mtime_check', True):
        return True
    
    cached_entry = analyzed_files[file_path]
    cached_mtime = cached_entry.get('mtime', 0)
    
    try:
        current_mtime = os.path.getmtime(file_path)
        if current_mtime > cached_mtime:
            print(f"âš ï¸ íŒŒì¼ ë³€ê²½ ê°ì§€: {os.path.basename(file_path)}")
            print(f"  - ìºì‹œ ì‹œê°„: {dt.datetime.fromtimestamp(cached_mtime).strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"  - í˜„ì¬ ì‹œê°„: {dt.datetime.fromtimestamp(current_mtime).strftime('%Y-%m-%d %H:%M:%S')}")
            return False
    except Exception as e:
        print(f"âš ï¸ mtime í™•ì¸ ì‹¤íŒ¨: {e}")
        return False
    
    return True

def update_file_cache(context, file_path, analysis_data):
    """
    íŒŒì¼ ìºì‹œ ì—…ë°ì´íŠ¸ (mtime, access_time í¬í•¨)
    
    Args:
        context (dict): project_context
        file_path (str): íŒŒì¼ ê²½ë¡œ
        analysis_data (dict): ë¶„ì„ ë°ì´í„°
    """
    if not context or 'cache' not in context:
        return
    
    analyzed_files = context['cache'].get('analyzed_files', {})
    
    # mtimeê³¼ access_time ì¶”ê°€
    try:
        mtime = os.path.getmtime(file_path)
        access_time = dt.datetime.now().timestamp()
        
        # ìºì‹œ ì—”íŠ¸ë¦¬ ìƒì„±
        cache_entry = {
            'data': analysis_data,
            'mtime': mtime,
            'access_time': access_time,
            'file_size': os.path.getsize(file_path),
            'cached_at': dt.datetime.now().isoformat()
        }
        
        analyzed_files[file_path] = cache_entry
        context['stats']['files_analyzed'] += 1
        
        print(f"âœ… ìºì‹œ ì—…ë°ì´íŠ¸: {os.path.basename(file_path)}")
        print(f"  - mtime: {dt.datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  - í¬ê¸°: {cache_entry['file_size']} bytes")
        
        # LRU ìºì‹œ í¬ê¸° ê´€ë¦¬
        manage_cache_size(context)
        
    except Exception as e:
        print(f"âŒ ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def get_cached_analysis(context, file_path):
    """
    ìºì‹œëœ ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (mtime ê²€ì¦ í¬í•¨)
    
    Args:
        context (dict): project_context
        file_path (str): íŒŒì¼ ê²½ë¡œ
    
    Returns:
        dict or None: ìºì‹œëœ ë°ì´í„° ë˜ëŠ” None
    """
    if not validate_cache_entry(context, file_path):
        # ìºì‹œê°€ ë¬´íš¨í•œ ê²½ìš° ì œê±°
        if file_path in context['cache'].get('analyzed_files', {}):
            del context['cache']['analyzed_files'][file_path]
            print(f"ğŸ—‘ï¸ ë¬´íš¨í•œ ìºì‹œ ì œê±°: {os.path.basename(file_path)}")
        context['stats']['cache_misses'] += 1
        return None
    
    # ìºì‹œ íˆíŠ¸
    cache_entry = context['cache']['analyzed_files'][file_path]
    
    # access_time ì—…ë°ì´íŠ¸
    cache_entry['access_time'] = dt.datetime.now().timestamp()
    context['stats']['cache_hits'] += 1
    
    print(f"âœ… ìºì‹œ íˆíŠ¸: {os.path.basename(file_path)}")
    return cache_entry.get('data')

def invalidate_file_cache(context, file_path):
    """
    íŠ¹ì • íŒŒì¼ì˜ ìºì‹œ ë¬´íš¨í™”
    
    Args:
        context (dict): project_context
        file_path (str): ë¬´íš¨í™”í•  íŒŒì¼ ê²½ë¡œ
    """
    analyzed_files = context['cache'].get('analyzed_files', {})
    
    if file_path in analyzed_files:
        del analyzed_files[file_path]
        print(f"ğŸ—‘ï¸ ìºì‹œ ë¬´íš¨í™”: {os.path.basename(file_path)}")
        
        # ê´€ë ¨ ì‹¬ë³¼ ì¸ë±ìŠ¤ë„ ì •ë¦¬
        symbol_index = context['cache'].get('symbol_index', {})
        symbols_to_remove = [sym for sym, path in symbol_index.items() if path == file_path]
        
        for symbol in symbols_to_remove:
            del symbol_index[symbol]
        
        if symbols_to_remove:
            print(f"  - {len(symbols_to_remove)}ê°œ ì‹¬ë³¼ ì œê±°")

# ============================================================================
# LRU ìºì‹œ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# ============================================================================

def manage_cache_size(context):
    """
    LRU(Least Recently Used) ì •ì±…ìœ¼ë¡œ ìºì‹œ í¬ê¸° ê´€ë¦¬
    
    Args:
        context (dict): project_context
    """
    cache = context.get('cache', {})
    analyzed_files = cache.get('analyzed_files', {})
    cache_config = cache.get('cache_config', {})
    max_size = cache_config.get('max_size', 20)
    
    current_size = len(analyzed_files)
    
    if current_size <= max_size:
        return
    
    # access_time ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
    sorted_files = sorted(
        analyzed_files.items(),
        key=lambda x: x[1].get('access_time', 0)
    )
    
    # ì œê±°í•  í•­ëª© ìˆ˜ ê³„ì‚°
    to_remove = current_size - max_size
    
    print(f"âš ï¸ ìºì‹œ í¬ê¸° ì´ˆê³¼: {current_size}/{max_size}")
    print(f"  - {to_remove}ê°œ í•­ëª© ì œê±° í•„ìš”")
    
    # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ ì œê±°
    for file_path, cache_entry in sorted_files[:to_remove]:
        del analyzed_files[file_path]
        context['stats']['cache_evictions'] += 1
        
        # íŒŒì¼ëª…ë§Œ ì¶œë ¥
        file_name = os.path.basename(file_path)
        cached_time = cache_entry.get('cached_at', 'unknown')
        print(f"  ğŸ—‘ï¸ LRU ì œê±°: {file_name} (ìºì‹œ: {cached_time})")
        
        # ê´€ë ¨ ì‹¬ë³¼ ì¸ë±ìŠ¤ë„ ì •ë¦¬
        symbol_index = cache.get('symbol_index', {})
        symbols_to_remove = [sym for sym, path in symbol_index.items() if path == file_path]
        for symbol in symbols_to_remove:
            del symbol_index[symbol]
    
    print(f"âœ… ìºì‹œ í¬ê¸° ì¡°ì • ì™„ë£Œ: {len(analyzed_files)}/{max_size}")

def get_cache_statistics(context):
    """
    ìºì‹œ í†µê³„ ì •ë³´ ë°˜í™˜
    
    Args:
        context (dict): project_context
        
    Returns:
        dict: ìºì‹œ í†µê³„ ì •ë³´
    """
    stats = context.get('stats', {})
    cache = context.get('cache', {})
    
    total_hits = stats.get('cache_hits', 0)
    total_misses = stats.get('cache_misses', 0)
    total_requests = total_hits + total_misses
    
    # hit_rateëŠ” 0~1 ì‚¬ì´ì˜ ë¹„ìœ¨ (í‘œì‹œí•  ë•Œ %ë¡œ ë³€í™˜)
    if total_requests > 0:
        hit_rate = total_hits / total_requests
    else:
        hit_rate = 0
    
    # ìºì‹œëœ íŒŒì¼ ìˆ˜
    cached_files = len(cache.get('analyzed_files', {}))
    
    # ìºì‹œ í¬ê¸° ê³„ì‚°
    import sys
    cache_size_bytes = sys.getsizeof(str(cache))
    cache_size_mb = cache_size_bytes / (1024 * 1024)
    
    return {
        'total_hits': total_hits,
        'total_misses': total_misses,
        'total_requests': total_requests,
        'hit_rate': hit_rate,  # 0~1 ì‚¬ì´ ê°’
        'cached_files': cached_files,
        'cache_size_mb': cache_size_mb
    }
def clear_cache(context, keep_index=False):
    """
    ìºì‹œ ì´ˆê¸°í™”
    
    Args:
        context (dict): project_context
        keep_index (bool): ì‹¬ë³¼ ì¸ë±ìŠ¤ ìœ ì§€ ì—¬ë¶€
    """
    cache = context.get('cache', {})
    
    # ë¶„ì„ëœ íŒŒì¼ ìºì‹œ ì‚­ì œ
    cache['analyzed_files'] = {}
    
    # íŒŒì¼ ìš”ì•½ ì‚­ì œ
    cache['file_summaries'] = {}
    
    # ì‹¬ë³¼ ì¸ë±ìŠ¤ ì²˜ë¦¬
    if not keep_index:
        cache['symbol_index'] = {}
    
    # í†µê³„ ì—…ë°ì´íŠ¸
    context['stats']['cache_evictions'] += len(cache.get('analyzed_files', {}))
    
    print("âœ… ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
    if keep_index:
        print("  - ì‹¬ë³¼ ì¸ë±ìŠ¤ëŠ” ìœ ì§€ë¨")

def optimize_cache(context):
    """
    ìºì‹œ ìµœì í™” (ì˜¤ë˜ë˜ê³  í° íŒŒì¼ ìš°ì„  ì œê±°)
    
    Args:
        context (dict): project_context
    """
    cache = context.get('cache', {})
    analyzed_files = cache.get('analyzed_files', {})
    cache_config = cache.get('cache_config', {})
    max_size = cache_config.get('max_size', 20)
    
    if len(analyzed_files) <= max_size * 0.8:  # 80% ë¯¸ë§Œì´ë©´ ìµœì í™” ë¶ˆí•„ìš”
        return
    
    # ì ìˆ˜ ê³„ì‚°: (í˜„ì¬ì‹œê°„ - access_time) * file_size
    current_time = dt.datetime.now().timestamp()
    
    scored_files = []
    for file_path, cache_entry in analyzed_files.items():
        access_time = cache_entry.get('access_time', 0)
        file_size = cache_entry.get('file_size', 0)
        age = current_time - access_time
        score = age * (file_size / 1024)  # KB ë‹¨ìœ„ë¡œ ì •ê·œí™”
        
        scored_files.append((file_path, score, cache_entry))
    
    # ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ì œê±° ìš°ì„ ìˆœìœ„)
    scored_files.sort(key=lambda x: x[1], reverse=True)
    
    # ìƒìœ„ 20% ì œê±°
    remove_count = int(len(scored_files) * 0.2)
    
    print(f"ğŸ”§ ìºì‹œ ìµœì í™” ì‹œì‘: {len(analyzed_files)}ê°œ í•­ëª©")
    
    for file_path, score, _ in scored_files[:remove_count]:
        del analyzed_files[file_path]
        context['stats']['cache_evictions'] += 1
        print(f"  ğŸ—‘ï¸ ìµœì í™” ì œê±°: {os.path.basename(file_path)} (ì ìˆ˜: {score:.2f})")
    
    print(f"âœ… ìºì‹œ ìµœì í™” ì™„ë£Œ: {len(analyzed_files)}ê°œ í•­ëª© ë‚¨ìŒ")



# ============================================
# ğŸ¯ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ìë™ ì¶”ì  ì‹œìŠ¤í…œ
# ============================================

def initialize_work_tracking(context):
    """
    ì‘ì—… ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    """
    # 'cache' í‚¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if 'cache' not in context:
        context['cache'] = {
        'files': {},
        'analyzed_files': {},
        'symbol_index': {},
        'file_summaries': {},
        'vibe_synced': {},
        'last_sync': None
    }
        print("âš ï¸ project_contextì— 'cache' í‚¤ê°€ ì—†ì–´ì„œ ìë™ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    
    if 'work_tracking' not in context['cache']:
        context['cache']['work_tracking'] = {
            'current_file': None,
            'current_function': None,
            'current_class': None,
            'last_accessed': None,
            'work_history': [],  # ìµœê·¼ ì‘ì—… ê¸°ë¡
            'file_access_count': {},  # íŒŒì¼ë³„ ì ‘ê·¼ íšŸìˆ˜
            'function_edit_count': {},  # í•¨ìˆ˜ë³„ ìˆ˜ì • íšŸìˆ˜
            'session_start': dt.datetime.now().isoformat()
        }
    return context


def track_file_access(context, file_path, operation='read'):
    """
    íŒŒì¼ ì ‘ê·¼ ì¶”ì 
    
    Args:
        context: project_context
        file_path: ì ‘ê·¼í•œ íŒŒì¼ ê²½ë¡œ
        operation: 'read', 'write', 'edit', 'analyze' ë“±
    """
    initialize_work_tracking(context)
    tracking = context['cache']['work_tracking']
    
    # í˜„ì¬ íŒŒì¼ ì—…ë°ì´íŠ¸
    tracking['current_file'] = file_path
    tracking['last_accessed'] = dt.datetime.now().isoformat()
    
    # íŒŒì¼ ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€
    if file_path not in tracking['file_access_count']:
        tracking['file_access_count'][file_path] = 0
    tracking['file_access_count'][file_path] += 1
    
    # ì‘ì—… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    history_entry = {
        'timestamp': dt.datetime.now().isoformat(),
        'file': file_path,
        'operation': operation,
        'function': tracking.get('current_function'),
        'class': tracking.get('current_class')
    }
    
    tracking['work_history'].append(history_entry)
    
    # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)
    if len(tracking['work_history']) > 100:
        tracking['work_history'] = tracking['work_history'][-100:]
    
    # ë¸Œë¦¿ì§€ í•¨ìˆ˜ ìë™ í˜¸ì¶œ - íŒŒì¼ ì ‘ê·¼ íšŸìˆ˜ê°€ 3ì˜ ë°°ìˆ˜ê°€ ë  ë•Œë§ˆë‹¤ ì—…ë°ì´íŠ¸
    # ìˆœí™˜ ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•œ í”Œë˜ê·¸ í™•ì¸
    if (file_path in tracking['file_access_count'] and 
        tracking['file_access_count'][file_path] % 3 == 0 and
        not context.get('_syncing_to_vibe', False)):
        context['_syncing_to_vibe'] = True
        try:
            sync_work_tracking_to_vibe(context)
        finally:
            context['_syncing_to_vibe'] = False
    
    return context


def track_function_edit(context, file_path, function_name, class_name=None, operation='edit'):
    """
    í•¨ìˆ˜/ë©”ì„œë“œ ìˆ˜ì • ì¶”ì 
    
    Args:
        context: project_context
        file_path: íŒŒì¼ ê²½ë¡œ
        function_name: í•¨ìˆ˜/ë©”ì„œë“œ ì´ë¦„
        class_name: í´ë˜ìŠ¤ ì´ë¦„ (ë©”ì„œë“œì¸ ê²½ìš°)
        operation: 'edit', 'create', 'delete', 'analyze' ë“±
    """
    initialize_work_tracking(context)
    tracking = context['cache']['work_tracking']
    
    # í˜„ì¬ ì‘ì—… ì¤‘ì¸ í•¨ìˆ˜/í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸
    tracking['current_function'] = function_name
    tracking['current_class'] = class_name
    
    # í•¨ìˆ˜ ìˆ˜ì • íšŸìˆ˜ ì¶”ì 
    function_key = f"{file_path}::{class_name or ''}.{function_name}"
    if function_key not in tracking['function_edit_count']:
        tracking['function_edit_count'][function_key] = 0
    tracking['function_edit_count'][function_key] += 1
    
    # íŒŒì¼ ì ‘ê·¼ë„ í•¨ê»˜ ì¶”ì 
    track_file_access(context, file_path, operation)
    
    # ë¸Œë¦¿ì§€ í•¨ìˆ˜ ìë™ í˜¸ì¶œ - í•¨ìˆ˜/ë©”ì„œë“œ ìˆ˜ì •ì€ ì¤‘ìš”í•œ ì‘ì—…ì´ë¯€ë¡œ ì¦‰ì‹œ ë™ê¸°í™”
    # ìˆœí™˜ ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•œ í”Œë˜ê·¸ í™•ì¸
    if not context.get('_syncing_to_vibe', False):
        context['_syncing_to_vibe'] = True
        try:
            sync_work_tracking_to_vibe(context)
        finally:
            context['_syncing_to_vibe'] = False
    
    return context


def track_code_analysis(context, file_path, analysis_result):
    """
    ì½”ë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‘ì—… ì¶”ì ì— ë°˜ì˜
    
    Args:
        context: project_context
        file_path: ë¶„ì„í•œ íŒŒì¼
        analysis_result: AST ë¶„ì„ ê²°ê³¼
    """
    initialize_work_tracking(context)
    
    # ë¶„ì„í•œ íŒŒì¼ ì¶”ì 
    track_file_access(context, file_path, 'analyze')
    
    # ë¶„ì„ ê²°ê³¼ì—ì„œ í•¨ìˆ˜/í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ
    if analysis_result and 'functions' in analysis_result:
        # ê°€ì¥ ìµœê·¼ì— ë¶„ì„í•œ í•¨ìˆ˜ë“¤ ê¸°ë¡
        tracking = context['cache']['work_tracking']
        tracking['last_analyzed_functions'] = [
            f['name'] for f in analysis_result['functions']
        ][:10]  # ìµœëŒ€ 10ê°œë§Œ
    
    return context


def get_current_work_context(context):
    """
    í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ
    
    Returns:
        dict: í˜„ì¬ ì‘ì—… ì¤‘ì¸ íŒŒì¼, í•¨ìˆ˜, í´ë˜ìŠ¤ ì •ë³´
    """
    # contextê°€ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
    if not context or not isinstance(context, dict):
        print("âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ project_contextì…ë‹ˆë‹¤.")
        return {
            'current_file': None,
            'current_function': None,
            'current_class': None,
            'last_accessed': None,
            'session_duration': "Unknown"
        }
    
    initialize_work_tracking(context)
    tracking = context['cache']['work_tracking']
    
    return {
        'current_file': tracking.get('current_file'),
        'current_function': tracking.get('current_function'),
        'current_class': tracking.get('current_class'),
        'last_accessed': tracking.get('last_accessed'),
        'session_duration': _calculate_session_duration(tracking)
    }


def get_work_history(context, limit=10):
    """
    ìµœê·¼ ì‘ì—… íˆìŠ¤í† ë¦¬ ì¡°íšŒ
    
    Args:
        context: project_context
        limit: ë°˜í™˜í•  ìµœëŒ€ í•­ëª© ìˆ˜
        
    Returns:
        list: ìµœê·¼ ì‘ì—… ê¸°ë¡
    """
    initialize_work_tracking(context)
    tracking = context['cache']['work_tracking']
    
    history = tracking.get('work_history', [])
    return history[-limit:] if history else []


def get_most_accessed_files(context, limit=5):
    """
    ê°€ì¥ ë§ì´ ì ‘ê·¼í•œ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
    
    Args:
        context: project_context
        limit: ë°˜í™˜í•  ìµœëŒ€ íŒŒì¼ ìˆ˜
        
    Returns:
        list: [{'file': file_path, 'access_count': count}, ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
    """
    initialize_work_tracking(context)
    tracking = context['cache']['work_tracking']
    
    file_counts = tracking.get('file_access_count', {})
    sorted_files = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)
    
    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
    result = []
    for file_path, count in sorted_files[:limit]:
        result.append({
            'file': file_path,
            'access_count': count
        })
    
    return result


def get_most_edited_functions(context, limit=5):
    """
    ê°€ì¥ ë§ì´ ìˆ˜ì •í•œ í•¨ìˆ˜ ëª©ë¡ ì¡°íšŒ
    
    Args:
        context: project_context
        limit: ë°˜í™˜í•  ìµœëŒ€ í•¨ìˆ˜ ìˆ˜
        
    Returns:
        list: [{'function': function_key, 'edit_count': count}, ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
    """
    initialize_work_tracking(context)
    tracking = context['cache']['work_tracking']
    
    function_counts = tracking.get('function_edit_count', {})
    sorted_functions = sorted(function_counts.items(), key=lambda x: x[1], reverse=True)
    
    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
    result = []
    for function_key, count in sorted_functions[:limit]:
        result.append({
            'function': function_key,
            'edit_count': count
        })
    
    return result


def clear_work_tracking(context, keep_counts=True):
    """
    ì‘ì—… ì¶”ì  ì •ë³´ ì´ˆê¸°í™”
    
    Args:
        context: project_context
        keep_counts: Trueë©´ ì ‘ê·¼/ìˆ˜ì • íšŸìˆ˜ëŠ” ìœ ì§€
    """
    initialize_work_tracking(context)
    tracking = context['cache']['work_tracking']
    
    tracking['current_file'] = None
    tracking['current_function'] = None
    tracking['current_class'] = None
    tracking['work_history'] = []
    
    if not keep_counts:
        tracking['file_access_count'] = {}
        tracking['function_edit_count'] = {}
    
    return context


def _calculate_session_duration(tracking):
    """ì„¸ì…˜ ì§€ì† ì‹œê°„ ê³„ì‚° (ë‚´ë¶€ í•¨ìˆ˜)"""
    if 'session_start' in tracking:
        try:
            start = dt.datetime.fromisoformat(tracking['session_start'])
            duration = dt.datetime.now() - start
            return str(duration).split('.')[0]  # ë§ˆì´í¬ë¡œì´ˆ ì œê±°
        except:
            pass
    return "Unknown"


# ì‘ì—… ì¶”ì  ìƒíƒœ ìš”ì•½ í•¨ìˆ˜
def get_work_tracking_summary(context):
    """
    ì‘ì—… ì¶”ì  ì „ì²´ ìš”ì•½ ì •ë³´
    
    Returns:
        dict: ì‘ì—… ì¶”ì  ìš”ì•½ ì •ë³´
    """
    initialize_work_tracking(context)
    tracking = context['cache']['work_tracking']
    
    return {
        'current_context': get_current_work_context(context),
        'most_accessed_files': get_most_accessed_files(context),
        'most_edited_functions': get_most_edited_functions(context, limit=10),
        'recent_history': get_work_history(context, limit=5),
        'total_files_accessed': len(tracking.get('file_access_count', {})),
        'total_functions_edited': len(tracking.get('function_edit_count', {})),
        'total_operations': len(tracking.get('work_history', []))
    }


def sync_work_tracking_to_vibe(context: dict):
    """
    ì‘ì—… ì¶”ì  ì‹œìŠ¤í…œì˜ ë°ì´í„°ë¥¼ Vibe Memoryê°€ í‘œì‹œí•  ìˆ˜ ìˆë„ë¡ live_contextë¡œ ë™ê¸°í™”í•©ë‹ˆë‹¤.
    """
    if 'cache' not in context:
        return False

    summary = get_work_tracking_summary(context)
    
    # live_context ì´ˆê¸°í™”
    if 'live_context' not in context:
        context['live_context'] = {}
    if 'coding_flow' not in context['live_context']:
        context['live_context']['coding_flow'] = {}
    
    live_context = context['live_context']

    # 1. 'Working Files' ë°ì´í„° ê°€ê³µ
    most_accessed = summary.get('most_accessed_files', [])
    live_context['coding_flow']['working_files'] = [
        {'name': os.path.basename(item['file']), 'count': item['access_count']}
        for item in most_accessed
        if isinstance(item, dict)
    ]

    # 2. 'Session Activity Log' ë°ì´í„° ê°€ê³µ
    history = summary.get('recent_history', [])
    live_context['coding_flow']['activity_log'] = []
    
    for log in history[:10]:
        if isinstance(log, dict) and 'timestamp' in log:
            try:
                time_str = log.get('timestamp', '')
                if time_str:
                    dt_obj = dt.datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                    time_formatted = dt_obj.strftime('%H:%M:%S')
                else:
                    time_formatted = 'N/A'
                    
                live_context['coding_flow']['activity_log'].append({
                    'time': time_formatted,
                    'op': log.get('operation', log.get('action', 'N/A')),
                    'target': os.path.basename(log.get('file', log.get('details', 'N/A')))
                })
            except Exception:
                continue

    # 3. vibe_systemì—ë„ ë°ì´í„° ë³µì‚¬
    if 'vibe_system' in context:
        vibe_sys = context['vibe_system']
        vibe_sys['working_files'] = live_context['coding_flow']['working_files']
        vibe_sys['activity_log'] = live_context['coding_flow']['activity_log']
    
    return True


def analyze_and_cache_file(file_path, language='auto'):
    """
    ì›ìì ìœ¼ë¡œ íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìºì‹±í•˜ëŠ” í†µí•© í•¨ìˆ˜
    Race conditionì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ëª¨ë“  ì‘ì—…ì„ í•œ í•¨ìˆ˜ì—ì„œ ì²˜ë¦¬
    
    Args:
        file_path (str): ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ
        language (str): í”„ë¡œê·¸ë˜ë° ì–¸ì–´
        
    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    # 1. ë¨¼ì € ìºì‹œ í™•ì¸
    cached_result = get_cached_analysis(file_path)
    if cached_result is not None:
        # ìºì‹œ íˆíŠ¸ - ë°”ë¡œ ë°˜í™˜
        return cached_result
    
    # 2. ìºì‹œ ë¯¸ìŠ¤ - í†µê³„ëŠ” get_cached_analysisì—ì„œ ì´ë¯¸ ì—…ë°ì´íŠ¸ë¨
    # ì´ì œ ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
    from ast_parser_helpers import parse_with_snippets as original_parse
    
    # 3. íŒŒì¼ ìƒíƒœë¥¼ ë¨¼ì € ìº¡ì²˜ (ë¶„ì„ ì „ì—!)
    try:
        stat = os.stat(file_path)
        mtime = stat.st_mtime
        size = stat.st_size
    except OSError as e:
        print(f"âŒ íŒŒì¼ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {file_path} - {e}")
        return None
    
    # 4. íŒŒì¼ ë¶„ì„ ìˆ˜í–‰
    try:
        # ì›ë³¸ í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ (ë¬´í•œ ì¬ê·€ ë°©ì§€)
        result = original_parse(file_path, language)
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_path} - {e}")
        return None
    
    # 5. ìºì‹œ ì—”íŠ¸ë¦¬ ìƒì„± (ëª¨ë“  ì •ë³´ë¥¼ í•œ ë²ˆì—)
    cache_entry = {
        'analysis_result': result,
        'mtime': mtime,
        'size': size,
        'language': language,
        'analyzed_at': dt.datetime.now().isoformat(),
        'parsing_success': result.get('parsing_success', False)
    }
    
    # 6. project_context í™•ì¸ ë° ìºì‹œ ì €ì¥
    if 'project_context' in globals():
        context = globals()['project_context']
        
        # ìºì‹œ êµ¬ì¡° í™•ì¸
        if 'cache' not in context:
            context['cache'] = {
                'files': {},
                'analyzed_files': {},
                'symbol_index': {},
                'file_summaries': {},
                'vibe_synced': {},
                'last_sync': None
            }
        
        if 'analyzed_files' not in context['cache']:
            context['cache']['analyzed_files'] = {}
        
        # ì›ìì  ì—…ë°ì´íŠ¸
        context['cache']['analyzed_files'][file_path] = cache_entry
        
        # 7. ì´ë²¤íŠ¸ ì¶”ì  (ìƒíƒœ ë³€ê²½ ì—†ì´ ë¡œê¹…ë§Œ)
        track_file_access(context, file_path, 'parse_with_snippets')
        track_code_analysis(context, file_path, result)
        
        # 8. íŒŒì¼ ìš”ì•½ ì—…ë°ì´íŠ¸ (í˜¸í™˜ì„±)
        if 'file_summaries' not in context['cache']:
            context['cache']['file_summaries'] = {}
            
        context['cache']['file_summaries'][file_path] = {
            'mtime': mtime,
            'size': size,
            'last_analyzed': cache_entry['analyzed_at'],
            'symbols': len(result.get('items', [])),
            'parsing_success': cache_entry['parsing_success']
        }
        
        # 9. ìºì‹œ í¬ê¸° ê´€ë¦¬
        manage_cache_size(context)
    
    # symbol_index ì—…ë°ì´íŠ¸ ì¶”ê°€
    if 'cache' in context:
        if 'symbol_index' not in context['cache']:
            context['cache']['symbol_index'] = {}
        
        symbol_index = context['cache']['symbol_index']
        
        # í•¨ìˆ˜ ì •ë³´ë¥¼ symbol_indexì— ì¶”ê°€
        for func in result.get('functions', []):
            func_key = f"{os.path.basename(file_path)}:{func}"
            symbol_index[func_key] = {
                'file': file_path,
                'type': 'function',
                'name': func,
                'language': language
            }
        
        # í´ë˜ìŠ¤ ì •ë³´ë¥¼ symbol_indexì— ì¶”ê°€
        for cls in result.get('classes', []):
            class_key = f"{os.path.basename(file_path)}:{cls}"
            symbol_index[class_key] = {
                'file': file_path,
                'type': 'class',  
                'name': cls,
                'language': language
            }
        
        print(f"   âœ… symbol_index ì—…ë°ì´íŠ¸: {len(result.get('functions', []))} í•¨ìˆ˜, {len(result.get('classes', []))} í´ë˜ìŠ¤")
    
    return result
def get_cached_analysis(file_path):
    """
    ìºì‹œëœ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜ (ìœ íš¨ì„± ê²€ì¦ í¬í•¨)
    
    Args:
        file_path (str): íŒŒì¼ ê²½ë¡œ
        
    Returns:
        dict or None: ìœ íš¨í•œ ìºì‹œê°€ ìˆìœ¼ë©´ ë¶„ì„ ê²°ê³¼, ì—†ìœ¼ë©´ None
    """
    if 'project_context' not in globals():
        return None
        
    context = globals()['project_context']
    
    # ìºì‹œ í™•ì¸
    cache = context.get('cache', {}).get('analyzed_files', {}).get(file_path)
    if not cache:
        context['stats']['cache_misses'] = context['stats'].get('cache_misses', 0) + 1
        return None
    
    # í˜„ì¬ íŒŒì¼ ìƒíƒœ í™•ì¸
    try:
        current_stat = os.stat(file_path)
    except OSError:
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìºì‹œ ë¬´íš¨
        if file_path in context['cache']['analyzed_files']:
            del context['cache']['analyzed_files'][file_path]
        return None
    
    # mtime ê²€ì¦
    if cache.get('mtime') != current_stat.st_mtime:
        # íŒŒì¼ì´ ìˆ˜ì •ë¨ - ìºì‹œ ë¬´íš¨
        del context['cache']['analyzed_files'][file_path]
        context['stats']['cache_misses'] = context['stats'].get('cache_misses', 0) + 1
        return None
    
    # size ê²€ì¦
    if cache.get('size') != current_stat.st_size:
        # íŒŒì¼ í¬ê¸° ë³€ê²½ - ìºì‹œ ë¬´íš¨
        del context['cache']['analyzed_files'][file_path]
        context['stats']['cache_misses'] = context['stats'].get('cache_misses', 0) + 1
        return None
    
    # ìºì‹œ íˆíŠ¸
    context['stats']['cache_hits'] = context['stats'].get('cache_hits', 0) + 1
    
    # ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
    cache['last_accessed'] = dt.datetime.now().isoformat()
    
    return cache.get('analysis_result')


def reset_cache_statistics(context):
    """
    ìºì‹œ í†µê³„ ì´ˆê¸°í™”
    í…ŒìŠ¤íŠ¸ë‚˜ ìƒˆ ì„¸ì…˜ ì‹œì‘ ì‹œ ì‚¬ìš©
    
    Args:
        context (dict): project_context
    """
    if 'stats' not in context:
        context['stats'] = {}
    
    context['stats'].update({
        'cache_hits': 0,
        'cache_misses': 0,
        'total_operations': 0,
        'cache_evictions': 0,
        'files_analyzed': 0
    })
    
    return context['stats']


def get_cache_health_status(context):
    """
    ìºì‹œ ìƒíƒœ ê±´ê°•ë„ í™•ì¸
    
    Args:
        context (dict): project_context
        
    Returns:
        dict: ìºì‹œ ê±´ê°• ìƒíƒœ ì •ë³´
    """
    cache = context.get('cache', {})
    stats = context.get('stats', {})
    
    # ìºì‹œ ìƒíƒœ ë¶„ì„
    analyzed_files = cache.get('analyzed_files', {})
    total_cached = len(analyzed_files)
    
    # í†µê³„ ì •ë³´
    total_hits = stats.get('cache_hits', 0)
    total_misses = stats.get('cache_misses', 0)
    total_requests = total_hits + total_misses
    
    # ê±´ê°• ìƒíƒœ íŒë‹¨
    health_status = {
        'is_empty': total_cached == 0,
        'is_cold': total_cached > 0 and total_requests == 0,  # ìºì‹œëŠ” ìˆì§€ë§Œ ì‚¬ìš© ì•ˆë¨
        'is_warming': total_cached > 0 and total_requests < 10,  # ì›Œë°ì—… ì¤‘
        'is_hot': total_cached > 0 and total_requests >= 10,  # í™œë°œíˆ ì‚¬ìš© ì¤‘
        'total_cached_files': total_cached,
        'total_requests': total_requests,
        'status_message': ''
    }
    
    # ìƒíƒœ ë©”ì‹œì§€ ì„¤ì •
    if health_status['is_empty']:
        health_status['status_message'] = "ìºì‹œê°€ ë¹„ì–´ìˆìŒ (ì •ìƒ - ìƒˆ ì„¸ì…˜)"
    elif health_status['is_cold']:
        health_status['status_message'] = "ìºì‹œ ì½œë“œ ìƒíƒœ (ì•„ì§ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)"
    elif health_status['is_warming']:
        health_status['status_message'] = "ìºì‹œ ì›Œë°ì—… ì¤‘"
    else:
        health_status['status_message'] = "ìºì‹œ í™œì„± ìƒíƒœ"
    
    return health_status

def get_full_session_status(project_context):
    """
    ì‘ì—… ì»¨í…ìŠ¤íŠ¸ì™€ Vibe Memoryë¥¼ í†µí•©í•œ ì „ì²´ ìƒíƒœ ë°˜í™˜
    
    Args:
        project_context (dict): í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        dict: í†µí•©ëœ ì„¸ì…˜ ìƒíƒœ ì •ë³´
    """
    # ê¸°ë³¸ ì‘ì—… ì»¨í…ìŠ¤íŠ¸
    work_context = get_current_work_context(project_context)
    
    # work_tracking ë°ì´í„°
    work_tracking = project_context.get('cache', {}).get('work_tracking', {})
    
    # Vibe ì‹œìŠ¤í…œ ë°ì´í„°
    vibe_data = project_context.get('vibe_system', {})
    
    # íŒŒì¼ ì ‘ê·¼ ë¡œê·¸ ë¶„ì„
    recent_files = []
    if 'storage' in project_context:
        file_log = project_context['storage'].get('file_access_log', [])
        seen = set()
        for entry in reversed(file_log[-100:]):
            file_path = entry.get('file_path', '')
            if file_path and file_path not in seen:
                recent_files.append(file_path)
                seen.add(file_path)
                if len(recent_files) >= 10:
                    break
    
    # í†µí•© ìƒíƒœ ìƒì„±
    return {
        # ì‘ì—… íŒŒì¼ ì •ë³´
        'current_file': work_context.get('current_file'),
        'current_function': work_context.get('current_function'),
        'current_class': work_context.get('current_class'),
        
        # Vibe Memory (work_tracking ìš°ì„ )
        'current_focus': work_tracking.get('current_focus') or vibe_data.get('current_focus'),
        'next_tasks': work_tracking.get('next_tasks', []) or vibe_data.get('next_tasks', []),
        'completed_tasks': work_tracking.get('completed_tasks', []),
        
        # íŒŒì¼ ì¶”ì 
        'recent_files': recent_files,
        'modified_functions': work_context.get('modified_functions', []),
        
        # ì„¸ì…˜ ì •ë³´
        'session_duration': work_context.get('session_duration'),
        'last_accessed': work_context.get('last_accessed'),
        
        # í†µê³„
        'total_files_accessed': len(project_context.get('storage', {}).get('file_access_log', [])),
        'total_functions_edited': len(project_context.get('storage', {}).get('function_edit_log', []))
    }


def normalize_context_structure(context):
    """Context êµ¬ì¡°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì¼ê´€ëœ ì ‘ê·¼ ë³´ì¥"""
    
    # cache_dataê°€ ì¤‘ì²©ë˜ì–´ ìˆìœ¼ë©´ í‰íƒ„í™”
    if 'cache_data' in context and isinstance(context['cache_data'], dict):
        cache_data = context['cache_data']
        
        # ì£¼ìš” í•„ë“œë“¤ì„ ìµœìƒìœ„ë¡œ ë³µì‚¬ (ë®ì–´ì“°ì§€ ì•ŠìŒ)
        for key in ['analyzed_files', 'symbol_index', 'work_tracking', 
                    'current_focus', 'tasks', 'active_file']:
            if key in cache_data and key not in context:
                context[key] = cache_data[key]
    
    # í•„ìˆ˜ í•„ë“œ ì´ˆê¸°í™”
    context.setdefault('analyzed_files', {})
    context.setdefault('symbol_index', {})
    context.setdefault('work_tracking', {})
    context.setdefault('tasks', {'next': [], 'done': []})
    
    return context


def validate_memory_bank_structure(memory_dir):
    """ë©”ëª¨ë¦¬ë±…í¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° ê²€ì¦ ë° ìˆ˜ì •"""
    
    issues_fixed = []
    
    # .cache ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„±
    cache_dir = os.path.join(memory_dir, '.cache')
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir, exist_ok=True)
        issues_fixed.append('Created .cache directory')
    
    # ë ˆê±°ì‹œ ìºì‹œ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
    project_name = os.path.basename(memory_dir)
    cache_filename = f'cache_{project_name}.json'
    
    old_cache = os.path.join(memory_dir, cache_filename)
    new_cache = os.path.join(cache_dir, cache_filename)
    
    if os.path.exists(old_cache) and not os.path.exists(new_cache):
        import shutil
        shutil.move(old_cache, new_cache)
        issues_fixed.append(f'Migrated {cache_filename} to .cache/')
    
    return issues_fixed
