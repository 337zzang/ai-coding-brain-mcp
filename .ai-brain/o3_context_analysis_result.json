{
  "task_id": "o3_task_0001",
  "completed_at": "2025-07-23T18:53:22.706315",
  "analysis": {
    "answer": "아래 내용은 “AI Coding Brain – MCP” 저장소에 실존하는 파일·클래스 이름( flow_manager.py, cached_flow_service.py …)을 그대로 사용해 서술한 “가능한” 구조/개선안입니다.  \n(실제 코드가 조금 다르면 경로-이름만 맞춰 주시면 됩니다.)\n\n────────────────────────────────────\n1. FlowManager 와 CachedFlowService 현재 구조 분석\n────────────────────────────────────\npython/ai_helpers_new/flow_manager.py\n------------------------------------------------------------------------------\nclass FlowManager:\n    def __init__(self, flow_service: CachedFlowService):  \n        self._service = flow_service              # 메타데이터·캐시 계층\n        self._mem_cache: Dict[str, Task] = {}     # 프로세스 내 캐시\n\n    # ↓ 현재 문제가 된 메서드\n    def update_task_context(self, task_id, key, value) -> None:\n        \"\"\"\n        (1) 인자 시그니처가 key/value 쌍.\n        (2) 기존 컨텍스트와 머지 로직 없음.\n        (3) self._service 쪽 메서드 호출부도 맞지 않는다.\n        \"\"\"\n        ...\n\npython/ai_helpers_new/service/cached_flow_service.py\n------------------------------------------------------------------------------\nclass CachedFlowService:\n    def __init__(self, backend: FlowBackend):  # DB or REST\n        self._backend = backend\n        self._lru_cache = LRUCache(maxsize=128) # 프로세스 내부 캐시\n\n    def get_task(self, task_id) -> Task: ...\n    def save_task(self, task: Task) -> None: ...\n    # 아직 “context” 전용 API 는 없다.\n\n현재 흐름\nFlowManager        ↔        CachedFlowService        ↔        FlowBackend\n(서비스 레이어)             (캐시 +  I/O)                     (DB / REST)\n\n문제점\n• Task.extra_data 같은 필드에 context 를 저장할 수 있는데 FlowManager 쪽 메서드가 이를 활용하지 못한다.  \n• Flow CLI / UI 에서 조회할 수 없는 JSON 파일을 임시로 떨궈 두고 있음.\n\n\n\n────────────────────────────────────\n2. update_task_context “올바른” 시그니처 & 사용법\n────────────────────────────────────\n“컨텍스트 전체 dict” 를 한 번에 전달하고, Merge 동작을 옵션으로 둔다.\n\ndef update_task_context(\n        self,\n        task_id: str,\n        context: Dict[str, Any],\n        *,\n        merge: bool = True\n) -> Dict[str, Any]:\n    \"\"\"\n    • merge=True : 기존 context 와 dict union.\n    • return : 병합 후 최종 context.\n    \"\"\"\n    task = self._service.get_task(task_id)\n\n    existing = (task.extra_data or {}).get(\"context\", {})\n    task.extra_data = task.extra_data or {}\n\n    task.extra_data[\"context\"] = {**existing, **context} if merge else context\n    self._service.save_task(task)\n\n    # 프로세스 캐시 동기화\n    self._mem_cache[task_id] = task\n    return task.extra_data[\"context\"]\n\n호출 예시\nFlowManager.update_task_context(task_id, {\"retrieved_file\": \"spec.yaml\"})\n\n레거시 호환용 래퍼 (legacy_flow_adapter.py)\ndef add_to_context(task_id, key, value):\n    fm = FlowManager.get()            # 싱글톤\n    fm.update_task_context(task_id, {key: value}, merge=True)\n\n\n\n────────────────────────────────────\n3. Flow 시스템과 “완전히” 통합하는 최선의 방법\n────────────────────────────────────\n가. DB/모델 계층\n• Task 테이블(혹은 Document)에 jsonb/text 컬럼 context 추가\n  (있다면 extra_data.context 를 그대로 사용)\n\n나. CachedFlowService 계층\nclass CachedFlowService:\n    ...\n    def get_task_context(self, task_id) -> Dict[str, Any]:\n        task = self.get_task(task_id)\n        return (task.extra_data or {}).get(\"context\", {})\n\n    def set_task_context(self, task_id, ctx: Dict[str, Any]) -> None:\n        task = self.get_task(task_id)\n        task.extra_data = task.extra_data or {}\n        task.extra_data[\"context\"] = ctx\n        self.save_task(task)\n\n다. Flow CLI / Dashboard 노출\n• Metaflow 의 경우 : task.set_tag(\"context\", json.dumps(ctx))  \n• Prefect 2.x : state.result() / task.set_variable()  \n• Dagster : event_metadata={\"context\": ctx}\n\n즉 “태그 또는 메타데이터” 로도 복사해 두면 Flow UI 에서 바로 볼 수 있게 된다.\n\n\n\n────────────────────────────────────\n4. “작업별 컨텍스트 자동 저장” 메커니즘\n────────────────────────────────────\n핵심 아이디어 :  \n(1) 모든 Step/Task 함수가 끝날 때 FlowManager.update_task_context 를 자동 호출  \n(2) 호출부를 최소화 하기 위해 Decorator 또는 ContextManager 사용\n\nDecorator 예시\n------------------------------------------------------------------------------\n# context_integration.py\ndef auto_context(*capture_args):\n    \"\"\"\n    capture_args : 저장할 변수 이름들.\n    \"\"\"\n\n    def decorator(fn):\n        @functools.wraps(fn)\n        def wrapper(*args, **kwargs):\n            task_id = kwargs.get(\"task_id\") or args[0].task_id\n            result = fn(*args, **kwargs)\n\n            bound = inspect.signature(fn).bind(*args, **kwargs)\n            bound.apply_defaults()\n\n            ctx_update = {name: bound.arguments[name] for name in capture_args\n                          if name in bound.arguments}\n\n            FlowManager.get().update_task_context(task_id, ctx_update)\n            return result\n        return wrapper\n    return decorator\n\n\n사용 예시\n------------------------------------------------------------------------------\nclass GitCloneService:\n    @auto_context(\"repo_url\", \"branch\")\n    def execute(self, task_id: str, repo_url: str, branch: str = \"main\"):\n        ... # 실제 클론 로직\n\n결과  \n• repo_url, branch 두 키가 Task.context 로 자동 저장  \n• 서비스 레이어는 한 줄의 애노테이션만 추가.\n\n\n\n────────────────────────────────────\n5. “최소 수정”으로 기존 코드 살리면서 통합하기\n────────────────────────────────────\nStep 0) JSON 파일 → Flow 로 이관 스크립트(1회성)\n------------------------------------------------------------------------------\n# migrate_json_context.py\nfor file in Path(\"./context_dump\").glob(\"*.json\"):\n    with open(file) as fp:\n        data = json.load(fp)\n        task_id = data[\"task_id\"]\n        FlowManager.get().update_task_context(task_id, data[\"context\"], merge=True)\n\nStep 1) FlowManager 메서드 시그니처 변경 + 구버전 래퍼 유지\n------------------------------------------------------------------------------\n# flow_manager.py\nclass FlowManager:\n    ...\n    def update_task_context(self, task_id, context, *, merge: bool=True):\n        ...\n\n# legacy_flow_adapter.py  (구 메서드 그대로 쓰던 코드 대응)\ndef update_task_context(task_id, key, value):\n    FlowManager.get().update_task_context(task_id, {key: value}, merge=True)\n\n기존 코드에서는\nlegacy_flow_adapter.update_task_context(task_id, \"last_file\", \"foo.txt\")\n처럼 호출하므로 수정 필요 없다.\n\nStep 2) CachedFlowService 에 context 전용 API 소규모 추가\n------------------------------------------------------------------------------\nclass CachedFlowService:\n    def get_task_context(self, task_id): ...\n    def set_task_context(self, task_id, ctx): ...\n\nsave_task / get_task 는 이미 있으므로 구현은 10~15줄.\n\nStep 3) (선택) 각 Service 메서드에 @auto_context 적용\n• 점진적 도입 : 컨텍스트가 꼭 필요한 일부 서비스부터 붙인다.\n• 데코레이터 한 줄 추가만으로 끝.\n\nStep 4) Flow UI 태그 연동\n• FlowManager.update_task_context 내부에서\n  self._service.add_tag(task_id, \"context:\"+base64.b64encode(json.dumps(ctx)))\n  정도를 호출해 놓으면 CLI 검색도 가능.\n\n\n\n────────────────────────────────────\n요약\n────────────────────────────────────\n1. update_task_context 시그니처를 (task_id, context_dict, merge=True) 로 단일화한다.  \n2. CachedFlowService 에 get/set_task_context API 를 15줄 이하로 추가한다.  \n3. legacy_flow_adapter 에 thin-wrapper 를 둬서 기존 key/value 호출 코드를 살린다.  \n4. @auto_context 데코레이터(또는 ContextManager) 로 “서비스 → 컨텍스트” 자동 기록을 지원한다.  \n5. extra_data.context 컬럼 + Flow 태그(또는 메타데이터) 2중 저장으로 Flow CLI 에서도 조회할 수 있게 한다.  \n\n이렇게 하면\n• 더 이상 JSON 파일 관리가 필요 없고,  \n• Flow 대시보드/CLI 로도 컨텍스트를 즉시 조회,  \n• 컨텍스트 기반 추천(“이전 스텝에서 사용한 repo_url 을 자동 제안”) 같은 고급 기능을 손쉽게 붙일 수 있습니다.",
    "reasoning_effort": "high",
    "usage": {
      "prompt_tokens": 349,
      "completion_tokens": 2903,
      "total_tokens": 3252,
      "reasoning_tokens": 0
    }
  }
}