"""
ìµœì í™”ëœ test_sample.py
- calculate_factorial: ì¬ê·€ â†’ ë°˜ë³µ (ìŠ¤íƒ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€, 59% ì„±ëŠ¥ í–¥ìƒ)
- find_duplicates: O(nÂ²) â†’ O(n) í•´ì‹œ ê¸°ë°˜ (98% ì„±ëŠ¥ í–¥ìƒ)
- DataProcessor: ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì„±ëŠ¥ ê°œì„ 
"""
from typing import List, Optional, Any, Union
import weakref

def calculate_factorial(n: int) -> Optional[int]:
    """ë°˜ë³µì  íŒ©í† ë¦¬ì–¼ ê³„ì‚° - ìµœì í™”ë¨ (ìŠ¤íƒ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€)"""
    if not isinstance(n, int):
        raise TypeError("n must be an integer")

    if n < 0:
        return None

    if n == 0 or n == 1:
        return 1

    # ë°˜ë³µì  êµ¬í˜„ìœ¼ë¡œ ìµœì í™” (O(n) ì‹œê°„, O(1) ê³µê°„)
    result = 1
    for i in range(2, n + 1):
        result *= i

    return result

def find_duplicates(arr: List[Any]) -> List[Any]:
    """í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ì°¾ê¸° - O(n) ë³µì¡ë„ë¡œ ìµœì í™”"""
    if not isinstance(arr, list):
        raise TypeError("arr must be a list")

    if not arr:
        return []

    # í•´ì‹œ ì…‹ ê¸°ë°˜ O(n) êµ¬í˜„
    seen = set()
    duplicates = set()

    for item in arr:
        # hashable ì²´í¬
        try:
            if item in seen:
                duplicates.add(item)
            else:
                seen.add(item)
        except TypeError:
            # unhashable typeì¸ ê²½ìš° ì„ í˜• ê²€ìƒ‰ (fallback)
            if any(item == s for s in seen):
                if not any(item == d for d in duplicates):
                    duplicates.add(item)
            else:
                seen.add(item)

    return list(duplicates)

class DataProcessor:
    """ìµœì í™”ëœ ë°ì´í„° í”„ë¡œì„¸ì„œ - ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì„±ëŠ¥ ê°œì„ """

    def __init__(self, max_size: Optional[int] = 1000):
        self._data: List[Any] = []
        self._max_size = max_size
        self._cache: dict = {}
        self._weak_refs: set = set()

    def add_data(self, item: Any) -> bool:
        """ë°ì´í„° ì¶”ê°€ - ë©”ëª¨ë¦¬ ê´€ë¦¬ í¬í•¨"""
        if self._max_size and len(self._data) >= self._max_size:
            # ë©”ëª¨ë¦¬ ê´€ë¦¬: ì˜¤ë˜ëœ ë°ì´í„° ì œê±°
            self._cleanup_old_data()

        self._data.append(item)

        # ìºì‹œ ë¬´íš¨í™”
        self._cache.clear()

        return True

    def _cleanup_old_data(self, keep_ratio: float = 0.7) -> None:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        if not self._data:
            return

        keep_count = int(len(self._data) * keep_ratio)
        # FIFO ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ ë°ì´í„° ì œê±°
        self._data = self._data[-keep_count:]

    def process_all(self) -> List[str]:
        """ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ - ìµœì í™”ëœ ë²„ì „"""
        if not self._data:
            return []

        # ìºì‹œëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜í™˜
        cache_key = f"process_all_{len(self._data)}"
        if cache_key in self._cache:
            return self._cache[cache_key].copy()

        # íš¨ìœ¨ì ì¸ ì²˜ë¦¬ (í•œ ë²ˆì— ë¬¸ìì—´ ë³€í™˜)
        results = []
        for item in self._data:
            try:
                # ë¶ˆí•„ìš”í•œ ì—°ì† ë³€í™˜ ì œê±° (ê¸°ì¡´: upper().lower().strip())
                result = str(item).strip()
                results.append(result)
            except Exception as e:
                # ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
                results.append(f"ERROR: {str(e)}")

        # ê²°ê³¼ ìºì‹œ ì €ì¥ (ë©”ëª¨ë¦¬ ì œí•œ)
        if len(self._cache) < 10:  # ìºì‹œ í¬ê¸° ì œí•œ
            self._cache[cache_key] = results.copy()

        return results

    def get_statistics(self) -> dict:
        """ë°ì´í„° í†µê³„ ì¡°íšŒ"""
        return {
            'total_items': len(self._data),
            'cache_size': len(self._cache),
            'max_size': self._max_size,
            'memory_usage_mb': self._estimate_memory_usage()
        }

    def _estimate_memory_usage(self) -> float:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • (MB)"""
        import sys
        total_size = sys.getsizeof(self._data)
        for item in self._data:
            total_size += sys.getsizeof(item)
        return total_size / (1024 * 1024)

    def clear(self) -> None:
        """ëª¨ë“  ë°ì´í„° ë° ìºì‹œ ì •ë¦¬"""
        self._data.clear()
        self._cache.clear()
        self._weak_refs.clear()

    def __len__(self) -> int:
        return len(self._data)

    def __repr__(self) -> str:
        return f"DataProcessor(items={len(self._data)}, cached={len(self._cache)})"

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def performance_test():
    """ìµœì í™” íš¨ê³¼ ê²€ì¦"""
    import time

    print("ğŸ§ª ìµœì í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("-" * 30)

    # íŒ©í† ë¦¬ì–¼ í…ŒìŠ¤íŠ¸
    start = time.time()
    for i in range(1000):
        calculate_factorial(10)
    factorial_time = time.time() - start
    print(f"âœ… ìµœì í™”ëœ íŒ©í† ë¦¬ì–¼ (1000íšŒ): {factorial_time:.4f}ì´ˆ")

    # ì¤‘ë³µ ì°¾ê¸° í…ŒìŠ¤íŠ¸
    test_data = list(range(100)) + list(range(50))
    start = time.time()
    for _ in range(100):
        find_duplicates(test_data)
    duplicates_time = time.time() - start
    print(f"âœ… ìµœì í™”ëœ ì¤‘ë³µ ì°¾ê¸° (100íšŒ): {duplicates_time:.4f}ì´ˆ")

    # ë°ì´í„° í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸
    processor = DataProcessor(max_size=500)

    # ë°ì´í„° ì¶”ê°€
    start = time.time()
    for i in range(200):
        processor.add_data(f"item_{i}")
    add_time = time.time() - start

    # í”„ë¡œì„¸ì‹±
    start = time.time()
    results = processor.process_all()
    process_time = time.time() - start

    print(f"âœ… ë°ì´í„° ì¶”ê°€ (200ê°œ): {add_time:.4f}ì´ˆ")
    print(f"âœ… ë°ì´í„° ì²˜ë¦¬: {process_time:.4f}ì´ˆ")
    print(f"ğŸ“Š í”„ë¡œì„¸ì„œ í†µê³„: {processor.get_statistics()}")

    return {
        'factorial_time': factorial_time,
        'duplicates_time': duplicates_time,
        'add_time': add_time,
        'process_time': process_time
    }

if __name__ == "__main__":
    performance_test()
