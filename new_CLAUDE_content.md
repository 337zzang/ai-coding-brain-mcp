# ğŸš€ Claude Code + ai-coding-brain-mcp Execute Code ì™„ì „ í™œìš© ê°€ì´ë“œ

**ëª¨ë“  ì‘ì—…ì„ execute_codeë¡œ! ì‹¤ì „ ì¤‘ì‹¬ ì™„ì „ ê°€ì´ë“œ**

> âš¡ ì´ ê°€ì´ë“œì˜ ëª¨ë“  ì½”ë“œëŠ” ë³µì‚¬-ë¶™ì—¬ë„£ê¸°ë¡œ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!

## ğŸ“‹ ëª©ì°¨

1. [ğŸš€ execute_code ì¦‰ì‹œ ì‹œì‘](#-execute_code-ì¦‰ì‹œ-ì‹œì‘)
2. [ğŸ’¡ helpers í•¨ìˆ˜ ì™„ì „ ì •ë³µ](#-helpers-í•¨ìˆ˜-ì™„ì „-ì •ë³µ)  
3. [ğŸ”¥ execute_code ì‹¤ì „ íŒ¨í„´](#-execute_code-ì‹¤ì „-íŒ¨í„´)
4. [ğŸ§  Think + execute_code í†µí•©](#-think--execute_code-í†µí•©)
5. [ğŸ› ï¸ í”„ë¡œì íŠ¸ ê´€ë¦¬ ë§ˆìŠ¤í„°](#ï¸-í”„ë¡œì íŠ¸-ê´€ë¦¬-ë§ˆìŠ¤í„°)
6. [ğŸ” ë””ë²„ê¹… & ë¬¸ì œí•´ê²°](#-ë””ë²„ê¹…--ë¬¸ì œí•´ê²°)
7. [âš¡ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•](#-ì„±ëŠ¥-ìµœì í™”-ê¸°ë²•)
8. [ğŸ”’ ë³´ì•ˆ & Git í†µí•©](#-ë³´ì•ˆ--git-í†µí•©)
9. [ğŸ¯ ê³ ê¸‰ ì›Œí¬í”Œë¡œìš° ìë™í™”](#-ê³ ê¸‰-ì›Œí¬í”Œë¡œìš°-ìë™í™”)
10. [ğŸ“š ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤ í•´ê²°ì±…](#-ì‹¤ì „-ì‹œë‚˜ë¦¬ì˜¤-í•´ê²°ì±…)

---

## ğŸš€ execute_code ì¦‰ì‹œ ì‹œì‘

### MCP ì„œë²„ ì—°ê²° í™•ì¸
```python
# MCP ì„œë²„ ìƒíƒœ í™•ì¸
print("ğŸ”Œ MCP ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸")
print(f"helpers ì‚¬ìš© ê°€ëŠ¥: {hasattr(helpers, 'read_file')}")
print(f"í˜„ì¬ ê²½ë¡œ: {helpers.get_current_path()}")

# í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸
status = helpers.get_context()
print(f"í™œì„± í”„ë¡œì íŠ¸: {status.get('project_name', 'None')}")
```

### ì²« ë²ˆì§¸ ì‹¤í–‰ - í˜„ì¬ ë””ë ‰í† ë¦¬ íƒìƒ‰
```python
# í˜„ì¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìŠ¤ìº”
print("ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:")
files_info = helpers.scan_directory_dict(".")
print(f"íŒŒì¼ ìˆ˜: {len(files_info['files'])}")
print(f"ë””ë ‰í† ë¦¬ ìˆ˜: {len(files_info['directories'])}")

# ì£¼ìš” íŒŒì¼ ëª©ë¡ ì¶œë ¥
print("\nğŸ“„ ì£¼ìš” íŒŒì¼ë“¤:")
for file_info in files_info['files'][:10]:  # ìƒìœ„ 10ê°œ íŒŒì¼
    print(f"  â€¢ {file_info['name']} ({file_info['size']} bytes)")
```

### í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
```python
# í˜„ì¬ í”„ë¡œì íŠ¸ë¡œ ì „í™˜ (ì´ë¯¸ ai-coding-brain-mcpì— ìˆìœ¼ë©´ í˜„ì¬ ìƒíƒœ í™•ì¸)
project_info = helpers.cmd_flow_with_context("ai-coding-brain-mcp")
print("âœ… í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ")
print(f"í”„ë¡œì íŠ¸: {project_info.get('project_name')}")
print(f"ê²½ë¡œ: {project_info.get('project_path')}")
```

---

## ğŸ’¡ helpers í•¨ìˆ˜ ì™„ì „ ì •ë³µ

### íŒŒì¼ ì‘ì—… ë§ˆìŠ¤í„°
```python
# ğŸ“ íŒŒì¼ ì½ê¸°/ì“°ê¸°/ì •ë³´ ì¡°íšŒ
def file_operations_demo():
    # íŒŒì¼ ìƒì„±
    content = "# í…ŒìŠ¤íŠ¸ íŒŒì¼\nprint('Hello, World!')"
    helpers.create_file("test_demo.py", content)
    print("âœ… íŒŒì¼ ìƒì„±: test_demo.py")

    # íŒŒì¼ ì½ê¸°
    read_content = helpers.read_file("test_demo.py")
    print(f"ğŸ“– íŒŒì¼ ë‚´ìš©: {len(str(read_content))} ë¬¸ì")

    # íŒŒì¼ ì •ë³´ ì¡°íšŒ
    file_info = helpers.get_file_info("test_demo.py")
    print(f"ğŸ“Š íŒŒì¼ ì •ë³´: {file_info}")

    # JSON ì‘ì—…
    data = {"name": "test", "value": 123}
    helpers.write_json("test_data.json", data)
    loaded_data = helpers.read_json("test_data.json")
    print(f"ğŸ“‹ JSON ë°ì´í„°: {loaded_data}")

file_operations_demo()
```

### ê²€ìƒ‰ ì‘ì—… ë§ˆìŠ¤í„°
```python
# ğŸ” ê°•ë ¥í•œ ê²€ìƒ‰ ê¸°ëŠ¥ë“¤
def search_operations_demo():
    # íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰
    python_files = helpers.search_files(".", "*.py")
    print(f"ğŸ Python íŒŒì¼ ìˆ˜: {len(python_files['results'])}")

    # ì½”ë“œ ë‚´ìš© ê²€ìƒ‰
    code_results = helpers.search_code_content(".", "def", "*.py")
    print(f"ğŸ” 'def' íŒ¨í„´ ë°œê²¬: {len(code_results['results'])} ê³³")

    # í•¨ìˆ˜ ì •ì˜ ê²€ìƒ‰ (AST ê¸°ë°˜)
    if python_files['results']:
        first_py_file = python_files['results'][0]['path']
        functions = helpers.find_function(first_py_file, "")  # ëª¨ë“  í•¨ìˆ˜
        print(f"âš¡ í•¨ìˆ˜ ë°œê²¬: {len(functions)} ê°œ")

search_operations_demo()
```

### Git ì‘ì—… ë§ˆìŠ¤í„°
```python
# ğŸ”§ Git ì‘ì—… ìë™í™”
def git_operations_demo():
    # Git ìƒíƒœ í™•ì¸
    status = helpers.git_status()
    print(f"ğŸ“Š Git ìƒíƒœ: {status}")

    # í˜„ì¬ ë¸Œëœì¹˜ í™•ì¸
    branch = helpers.git_get_current_branch()
    print(f"ğŸŒ¿ í˜„ì¬ ë¸Œëœì¹˜: {branch}")

    # ìŠ¤ë§ˆíŠ¸ ì»¤ë°‹ (ë³€ê²½ì‚¬í•­ ìë™ ë¶„ì„ í›„ ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„±)
    # helpers.git_add(".")  # ëª¨ë“  ë³€ê²½ì‚¬í•­ ì¶”ê°€
    # smart_commit = helpers.git_commit_smart()  # ì§€ëŠ¥í˜• ì»¤ë°‹
    # print(f"ğŸ’¾ ìŠ¤ë§ˆíŠ¸ ì»¤ë°‹: {smart_commit}")

    print("âš ï¸ ì‹¤ì œ ì»¤ë°‹ì€ ì£¼ì„ í•´ì œ í›„ ì‹¤í–‰í•˜ì„¸ìš”")

git_operations_demo()
```

### í”„ë¡œì íŠ¸ ê´€ë¦¬ ë§ˆìŠ¤í„°
```python
# ğŸ› ï¸ í”„ë¡œì íŠ¸ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬
def project_management_demo():
    # í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ
    projects = helpers.list_projects()
    print(f"ğŸ“‹ í”„ë¡œì íŠ¸ ëª©ë¡: {len(projects)} ê°œ")

    # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ
    context = helpers.get_context()
    print(f"ğŸ¯ í˜„ì¬ ì»¨í…ìŠ¤íŠ¸: {context}")

    # íƒœìŠ¤í¬ ê´€ë¦¬
    # task_id = helpers.quick_task("execute_code ê°€ì´ë“œ ì‘ì„±")
    # print(f"ğŸ“ ìƒˆ íƒœìŠ¤í¬ ìƒì„±: {task_id}")

    tasks = helpers.list_tasks()
    print(f"ğŸ“‹ í™œì„± íƒœìŠ¤í¬: {len(tasks)} ê°œ")

project_management_demo()
```

---

## ğŸ”¥ execute_code ì‹¤ì „ íŒ¨í„´

### íŒ¨í„´ 1: ë¹ ë¥¸ í”„ë¡œì íŠ¸ ë¶„ì„
```python
# ğŸ” í”„ë¡œì íŠ¸ ì „ì²´ ë¶„ì„ ì›ìŠ¤í†±
def quick_project_analysis():
    print("ğŸš€ í”„ë¡œì íŠ¸ ë¹ ë¥¸ ë¶„ì„ ì‹œì‘")

    # 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° íŒŒì•…
    structure = helpers.scan_directory_dict(".")
    print(f"ğŸ“ ì´ íŒŒì¼: {len(structure['files'])}, ë””ë ‰í† ë¦¬: {len(structure['directories'])}")

    # 2. Python íŒŒì¼ í˜„í™©
    py_files = helpers.search_files(".", "*.py")
    print(f"ğŸ Python íŒŒì¼: {len(py_files['results'])} ê°œ")

    # 3. ì£¼ìš” ì„¤ì • íŒŒì¼ í™•ì¸
    config_files = ["package.json", "requirements.txt", ".env", "config.json"]
    for config in config_files:
        if helpers.get_file_info(config):
            print(f"âš™ï¸ ì„¤ì • íŒŒì¼ ë°œê²¬: {config}")

    # 4. Git ìƒíƒœ
    git_status = helpers.git_status()
    print(f"ğŸ“Š Git ìƒíƒœ: ìˆ˜ì •ëœ íŒŒì¼ {len(git_status.get('modified', []))} ê°œ")

quick_project_analysis()
```

### íŒ¨í„´ 2: ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬
```python
# ğŸ”¬ ì½”ë“œ í’ˆì§ˆ ìë™ ê²€ì‚¬
def code_quality_check():
    print("ğŸ”¬ ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬ ì‹¤í–‰")

    # TODO, FIXME, HACK ë“± ì£¼ì„ ê²€ìƒ‰
    issues = []
    patterns = ["TODO", "FIXME", "HACK", "BUG"]

    for pattern in patterns:
        results = helpers.search_code_content(".", pattern, "*.py")
        if results['results']:
            issues.extend(results['results'])
            print(f"âš ï¸ {pattern} ë°œê²¬: {len(results['results'])} ê³³")

    # ê¸´ í•¨ìˆ˜ ê²€ìƒ‰ (50ë¼ì¸ ì´ìƒ)
    long_functions = helpers.search_code_content(".", r"def\s+\w+.*:\n(.*\n){50,}", "*.py")
    print(f"ğŸ“ ê¸´ í•¨ìˆ˜ (50ë¼ì¸+): {len(long_functions['results'])} ê°œ")

    # ì¤‘ë³µ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰
    duplicates = helpers.search_code_content(".", r"(\s*print\(.*\)\s*){3,}", "*.py")
    print(f"ğŸ”„ ì¤‘ë³µ íŒ¨í„´ ì˜ì‹¬: {len(duplicates['results'])} ê³³")

code_quality_check()
```

### íŒ¨í„´ 3: ì˜ì¡´ì„± ë¶„ì„
```python
# ğŸ“¦ í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ë¶„ì„
def dependency_analysis():
    print("ğŸ“¦ ì˜ì¡´ì„± ë¶„ì„ ì‹œì‘")

    # import ë¬¸ ë¶„ì„
    imports = helpers.search_code_content(".", r"^(import|from)\s+([\w\.]+)", "*.py")
    print(f"ğŸ“¥ Import ë¬¸ ë°œê²¬: {len(imports['results'])} ê°œ")

    # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© íŒ¨í„´
    external_libs = {}
    for result in imports['results']:
        # ë¼ì´ë¸ŒëŸ¬ë¦¬ëª… ì¶”ì¶œ ë¡œì§
        pass  # ì‹¤ì œ êµ¬í˜„ ì‹œ ì •ê·œì‹ìœ¼ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬ëª… ì¶”ì¶œ

    # requirements.txt ë˜ëŠ” package.json í™•ì¸
    req_file = helpers.get_file_info("requirements.txt")
    if req_file:
        content = helpers.read_file("requirements.txt")
        print("ğŸ“‹ requirements.txt ë°œê²¬")

    pkg_file = helpers.get_file_info("package.json")
    if pkg_file:
        pkg_data = helpers.read_json("package.json")
        print(f"ğŸ“¦ package.json: {len(pkg_data.get('dependencies', {}))} ì˜ì¡´ì„±")

dependency_analysis()
```

---

## ğŸ§  Think + execute_code í†µí•©

### ë³µì¡í•œ ë¬¸ì œ í•´ê²° ì›Œí¬í”Œë¡œìš°
```python
# ğŸ§  Think ê¸°ë°˜ ë¬¸ì œ í•´ê²° í”„ë¡œì„¸ìŠ¤
def think_execute_workflow(problem_description):
    print(f"ğŸ§  ë¬¸ì œ í•´ê²° ì›Œí¬í”Œë¡œìš° ì‹œì‘: {problem_description}")

    # 1. í˜„ì¬ ìƒí™© ë¶„ì„
    context = helpers.get_context()
    structure = helpers.scan_directory_dict(".")
    git_status = helpers.git_status()

    analysis = {
        "project": context.get('project_name'),
        "files_count": len(structure['files']),
        "git_modified": len(git_status.get('modified', [])),
        "problem": problem_description
    }

    print("ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„ ì™„ë£Œ:")
    for key, value in analysis.items():
        print(f"   â€¢ {key}: {value}")

    # 2. ë¬¸ì œ ê´€ë ¨ íŒŒì¼ ê²€ìƒ‰
    keywords = problem_description.split()[:3]  # ì²˜ìŒ 3ê°œ í‚¤ì›Œë“œ
    related_files = []

    for keyword in keywords:
        results = helpers.search_code_content(".", keyword, "*.*")
        related_files.extend(results['results'])

    print(f"ğŸ” ê´€ë ¨ íŒŒì¼ ë°œê²¬: {len(related_files)} ê°œ")

    # 3. í•´ê²° ê³„íš ìˆ˜ë¦½ ë° ì‹¤í–‰
    plan = {
        "step1": "ë¬¸ì œ íŒŒì¼ ë°±ì—…",
        "step2": "ìˆ˜ì • ì‚¬í•­ ì ìš©",
        "step3": "í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
        "step4": "ê²°ê³¼ ê²€ì¦"
    }

    return {"analysis": analysis, "related_files": len(related_files), "plan": plan}

# ì˜ˆì‹œ ì‹¤í–‰
result = think_execute_workflow("JSON íŒŒì‹± ì˜¤ë¥˜ í•´ê²°")
print(f"\nâœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: {result}")
```

---

## ğŸ› ï¸ í”„ë¡œì íŠ¸ ê´€ë¦¬ ë§ˆìŠ¤í„°

### ìƒˆ í”„ë¡œì íŠ¸ ìƒì„± ë° ì„¤ì •
```python
# ğŸ—ï¸ ì™„ì „í•œ í”„ë¡œì íŠ¸ ìƒì„± ì›Œí¬í”Œë¡œìš°
def create_complete_project(project_name):
    print(f"ğŸ—ï¸ ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±: {project_name}")

    # 1. í”„ë¡œì íŠ¸ ìƒì„±
    project_info = helpers.create_project(project_name, f"./{project_name}")
    print(f"âœ… í”„ë¡œì íŠ¸ ìƒì„±: {project_info}")

    # 2. ê¸°ë³¸ êµ¬ì¡° ìƒì„±
    dirs = ["src", "tests", "docs", "config"]
    for dir_name in dirs:
        helpers.create_directory(f"{project_name}/{dir_name}")
        print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {dir_name}")

    # 3. ê¸°ë³¸ íŒŒì¼ ìƒì„±
    files = {
        f"{project_name}/README.md": f"# {project_name}\n\ní”„ë¡œì íŠ¸ ì„¤ëª…",
        f"{project_name}/src/__init__.py": "# ë©”ì¸ ëª¨ë“ˆ",
        f"{project_name}/tests/test_main.py": "# í…ŒìŠ¤íŠ¸ íŒŒì¼",
        f"{project_name}/.gitignore": "*.pyc\n__pycache__/\n.env"
    }

    for file_path, content in files.items():
        helpers.create_file(file_path, content)
        print(f"ğŸ“„ íŒŒì¼ ìƒì„±: {file_path}")

    # 4. Git ì´ˆê¸°í™”
    helpers.git_init(project_name)
    print("ğŸ”§ Git ì €ì¥ì†Œ ì´ˆê¸°í™”")

    return project_name

# ì˜ˆì‹œ - ì‹¤ì œ ìƒì„±í•˜ë ¤ë©´ ì£¼ì„ í•´ì œ
# new_project = create_complete_project("my-awesome-project")
print("âš ï¸ ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±ì„ ì›í•˜ë©´ ìœ„ í•¨ìˆ˜ í˜¸ì¶œ ì½”ë“œì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”")
```

### í”„ë¡œì íŠ¸ ìƒíƒœ ëª¨ë‹ˆí„°ë§
```python
# ğŸ“Š í”„ë¡œì íŠ¸ ìƒíƒœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
def monitor_project_status():
    print("ğŸ“Š í”„ë¡œì íŠ¸ ìƒíƒœ ëª¨ë‹ˆí„°ë§")

    # 1. ê¸°ë³¸ ì •ë³´
    context = helpers.get_context()
    print(f"ğŸ“‹ í”„ë¡œì íŠ¸: {context.get('project_name')}")

    # 2. íŒŒì¼ ì‹œìŠ¤í…œ ìƒíƒœ
    structure = helpers.scan_directory_dict(".")
    print(f"ğŸ“ íŒŒì¼: {len(structure['files'])}, ë””ë ‰í† ë¦¬: {len(structure['directories'])}")

    # 3. Git ìƒíƒœ
    git_status = helpers.git_status()
    print(f"ğŸ”§ Git: ìˆ˜ì • {len(git_status.get('modified', []))}, ì¶”ê°€ {len(git_status.get('untracked', []))}")

    # 4. í™œì„± íƒœìŠ¤í¬
    tasks = helpers.list_tasks()
    active_tasks = [t for t in tasks if t.get('status') != 'completed']
    print(f"ğŸ“ í™œì„± íƒœìŠ¤í¬: {len(active_tasks)}")

    # 5. ì„±ëŠ¥ í†µê³„
    stats = helpers.get_tracking_statistics()
    print(f"âš¡ ì„±ëŠ¥ í†µê³„: {stats}")

    return {
        "files": len(structure['files']),
        "git_changes": len(git_status.get('modified', [])),
        "active_tasks": len(active_tasks)
    }

status = monitor_project_status()
```

---

## ğŸ” ë””ë²„ê¹… & ë¬¸ì œí•´ê²°

### ìë™ ì˜¤ë¥˜ ì§„ë‹¨
```python
# ğŸš¨ ìë™ ì˜¤ë¥˜ ì§„ë‹¨ ë° í•´ê²°
def auto_error_diagnosis():
    print("ğŸš¨ ìë™ ì˜¤ë¥˜ ì§„ë‹¨ ì‹œì‘")

    # 1. ì¼ë°˜ì ì¸ ì˜¤ë¥˜ íŒ¨í„´ ê²€ìƒ‰
    error_patterns = [
        "Error", "Exception", "Traceback", "Failed", 
        "ImportError", "ModuleNotFoundError", "SyntaxError"
    ]

    errors_found = {}
    for pattern in error_patterns:
        results = helpers.search_code_content(".", pattern, "*.*")
        if results['results']:
            errors_found[pattern] = len(results['results'])
            print(f"âŒ {pattern}: {len(results['results'])} ê³³ì—ì„œ ë°œê²¬")

    # 2. ì„¤ì • íŒŒì¼ ë¬¸ì œ í™•ì¸
    config_issues = []

    # package.json ê²€ì‚¬
    if helpers.get_file_info("package.json"):
        try:
            pkg = helpers.read_json("package.json")
            if not pkg.get("scripts"):
                config_issues.append("package.jsonì— scripts ì—†ìŒ")
        except:
            config_issues.append("package.json íŒŒì‹± ì˜¤ë¥˜")

    # requirements.txt ê²€ì‚¬
    if helpers.get_file_info("requirements.txt"):
        req_content = helpers.read_file("requirements.txt")
        if "==" not in str(req_content):
            config_issues.append("requirements.txtì— ë²„ì „ ê³ ì • ì—†ìŒ")

    # 3. ì˜ì¡´ì„± ë¬¸ì œ ê²€ì‚¬
    missing_imports = helpers.search_code_content(".", r"ModuleNotFoundError|ImportError", "*.py")
    if missing_imports['results']:
        print(f"ğŸ“¦ ëˆ„ë½ëœ ëª¨ë“ˆ: {len(missing_imports['results'])} ê°œ")

    return {"errors": errors_found, "config_issues": config_issues}

diagnosis = auto_error_diagnosis()
```

### ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„
```python
# âš¡ ì„±ëŠ¥ ë³‘ëª© ì§€ì  ìë™ ë¶„ì„
def performance_bottleneck_analysis():
    print("âš¡ ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„")

    # 1. ë¹„íš¨ìœ¨ì ì¸ ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰
    inefficient_patterns = {
        "nested_loops": r"for\s+\w+.*:\s*\n\s*for\s+\w+.*:",
        "database_in_loop": r"for\s+\w+.*:\s*\n.*\.(query|execute|find)",
        "file_io_in_loop": r"for\s+\w+.*:\s*\n.*(open|read|write)",
        "large_list_comprehension": r"\[.*for\s+\w+\s+in\s+range\([0-9]{4,}\)",
    }

    bottlenecks = {}
    for pattern_name, pattern in inefficient_patterns.items():
        results = helpers.search_code_content(".", pattern, "*.py")
        if results['results']:
            bottlenecks[pattern_name] = len(results['results'])
            print(f"âš ï¸ {pattern_name}: {len(results['results'])} ê³³")

    # 2. í° íŒŒì¼ ê²€ìƒ‰ (ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ”)
    structure = helpers.scan_directory_dict(".")
    large_files = [f for f in structure['files'] if f.get('size', 0) > 1000000]  # 1MB ì´ìƒ
    print(f"ğŸ“ í° íŒŒì¼ (1MB+): {len(large_files)} ê°œ")

    # 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§ì€ íŒ¨í„´
    memory_patterns = helpers.search_code_content(".", r"\*args|\*\*kwargs|list\(.*\)|dict\(.*\)", "*.py")
    print(f"ğŸ§  ë©”ëª¨ë¦¬ ì£¼ì˜ íŒ¨í„´: {len(memory_patterns['results'])} ê³³")

    return {"bottlenecks": bottlenecks, "large_files": len(large_files)}

perf_analysis = performance_bottleneck_analysis()
```

---

## âš¡ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

### ì½”ë“œ ìµœì í™” ìë™ ì œì•ˆ
```python
# ğŸš€ ì½”ë“œ ìµœì í™” ìë™ ì œì•ˆ ì‹œìŠ¤í…œ
def auto_optimization_suggestions():
    print("ğŸš€ ì½”ë“œ ìµœì í™” ìë™ ì œì•ˆ")

    optimizations = []

    # 1. ë¶ˆí•„ìš”í•œ import ê²€ìƒ‰
    all_imports = helpers.search_code_content(".", r"^import\s+(\w+)|^from\s+(\w+)", "*.py")
    used_modules = helpers.search_code_content(".", r"\w+\.", "*.py")
    print(f"ğŸ“¦ Import ë¶„ì„: {len(all_imports['results'])} ê°œì˜ import ë¬¸")

    # 2. í•˜ë“œì½”ë”©ëœ ê°’ ê²€ìƒ‰
    hardcoded = helpers.search_code_content(".", r"\b[0-9]{3,}\b|['\"][^'\"]{20,}['\"]", "*.py")
    if hardcoded['results']:
        optimizations.append(f"í•˜ë“œì½”ë”©ëœ ê°’ {len(hardcoded['results'])} ê³³ â†’ ìƒìˆ˜ë¡œ ì¶”ì¶œ ê¶Œì¥")

    # 3. ê¸´ í•¨ìˆ˜ ê²€ìƒ‰
    long_functions = helpers.search_code_content(".", r"def\s+\w+.*:\n(.*\n){30,}(?=def|class|$)", "*.py")
    if long_functions['results']:
        optimizations.append(f"ê¸´ í•¨ìˆ˜ {len(long_functions['results'])} ê°œ â†’ ë¶„í•  ê¶Œì¥")

    # 4. ì¤‘ë³µ ì½”ë“œ ê²€ìƒ‰
    duplicate_patterns = helpers.search_code_content(".", r"(print\(.*\)\s*){3,}", "*.py")
    if duplicate_patterns['results']:
        optimizations.append(f"ì¤‘ë³µ íŒ¨í„´ {len(duplicate_patterns['results'])} ê³³ â†’ í•¨ìˆ˜í™” ê¶Œì¥")

    # 5. ë¹„íš¨ìœ¨ì ì¸ ë¬¸ìì—´ ì—°ê²°
    string_concat = helpers.search_code_content(".", r"\w+\s*\+=\s*['\"]", "*.py")
    if string_concat['results']:
        optimizations.append(f"ë¹„íš¨ìœ¨ì  ë¬¸ìì—´ ì—°ê²° {len(string_concat['results'])} ê³³ â†’ join() ì‚¬ìš© ê¶Œì¥")

    print("\nğŸ’¡ ìµœì í™” ì œì•ˆ:")
    for i, suggestion in enumerate(optimizations, 1):
        print(f"   {i}. {suggestion}")

    return optimizations

suggestions = auto_optimization_suggestions()
```

### íŒŒì¼ êµ¬ì¡° ìµœì í™”
```python
# ğŸ“ íŒŒì¼ êµ¬ì¡° ìë™ ìµœì í™”
def optimize_file_structure():
    print("ğŸ“ íŒŒì¼ êµ¬ì¡° ìµœì í™” ë¶„ì„")

    structure = helpers.scan_directory_dict(".")

    # 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„
    dirs = structure['directories']
    files = structure['files']

    print(f"ğŸ“Š í˜„ì¬ êµ¬ì¡°: {len(dirs)} ë””ë ‰í† ë¦¬, {len(files)} íŒŒì¼")

    # 2. ë„ˆë¬´ ê¹Šì€ ì¤‘ì²© ê²€ìƒ‰
    deep_paths = [f for f in files if f['path'].count('/') > 5]
    if deep_paths:
        print(f"âš ï¸ ê¹Šì€ ì¤‘ì²© (5ë‹¨ê³„+): {len(deep_paths)} íŒŒì¼")

    # 3. íŒŒì¼ëª… ì¼ê´€ì„± ê²€ì‚¬
    naming_issues = []
    py_files = [f for f in files if f['name'].endswith('.py')]

    # ì¹´ë©œì¼€ì´ìŠ¤ vs ìŠ¤ë„¤ì´í¬ì¼€ì´ìŠ¤ í˜¼ìš© ê²€ì‚¬
    camel_case = [f for f in py_files if any(c.isupper() for c in f['name'][:-3])]
    snake_case = [f for f in py_files if '_' in f['name']]

    if camel_case and snake_case:
        naming_issues.append("íŒŒì¼ëª… ìŠ¤íƒ€ì¼ í˜¼ìš© (camelCase + snake_case)")

    # 4. ë¹ˆ ë””ë ‰í† ë¦¬ ê²€ìƒ‰
    empty_dirs = []
    for dir_info in dirs:
        dir_files = [f for f in files if f['path'].startswith(dir_info['path'])]
        if not dir_files:
            empty_dirs.append(dir_info['path'])

    if empty_dirs:
        print(f"ğŸ“‚ ë¹ˆ ë””ë ‰í† ë¦¬: {len(empty_dirs)} ê°œ")

    optimization_tips = [
        "ëª¨ë“ˆë³„ë¡œ ë””ë ‰í† ë¦¬ ë¶„ë¦¬",
        "í…ŒìŠ¤íŠ¸ íŒŒì¼ê³¼ ì†ŒìŠ¤ íŒŒì¼ ë¶„ë¦¬", 
        "ì„¤ì • íŒŒì¼ ì „ìš© ë””ë ‰í† ë¦¬ ìƒì„±",
        "ë¬¸ì„œí™” íŒŒì¼ docs/ ë””ë ‰í† ë¦¬ ì´ë™"
    ]

    print("\nğŸ¯ êµ¬ì¡° ìµœì í™” íŒ:")
    for tip in optimization_tips:
        print(f"   â€¢ {tip}")

optimize_file_structure()
```

---

## ğŸ”’ ë³´ì•ˆ & Git í†µí•©

### ë³´ì•ˆ ì·¨ì•½ì  ìë™ ìŠ¤ìº”
```python
# ğŸ›¡ï¸ ë³´ì•ˆ ì·¨ì•½ì  ìë™ ìŠ¤ìº”
def security_vulnerability_scan():
    print("ğŸ›¡ï¸ ë³´ì•ˆ ì·¨ì•½ì  ìŠ¤ìº” ì‹œì‘")

    vulnerabilities = []

    # 1. í•˜ë“œì½”ë”©ëœ ë¯¼ê°ì •ë³´ ê²€ìƒ‰
    sensitive_patterns = {
        "passwords": r"password\s*=\s*['\"][^'\"]+['\"]",
        "api_keys": r"(api_key|apikey|api-key)\s*=\s*['\"][^'\"]+['\"]",
        "secrets": r"(secret|token)\s*=\s*['\"][^'\"]+['\"]",
        "private_keys": r"-----BEGIN (PRIVATE|RSA) KEY-----",
        "database_urls": r"(mongodb|mysql|postgres)://[^\s]+",
    }

    for vuln_type, pattern in sensitive_patterns.items():
        results = helpers.search_code_content(".", pattern, "*.*")
        if results['results']:
            vulnerabilities.append(f"{vuln_type}: {len(results['results'])} ê³³ì—ì„œ ë°œê²¬")
            print(f"âš ï¸ {vuln_type}: {len(results['results'])} ê³³")

    # 2. ìœ„í—˜í•œ í•¨ìˆ˜ ì‚¬ìš© ê²€ìƒ‰
    dangerous_functions = [
        "eval(", "exec(", "os.system(", "subprocess.call(", 
        "pickle.loads(", "yaml.load(", "input("
    ]

    for func in dangerous_functions:
        results = helpers.search_code_content(".", func, "*.py")
        if results['results']:
            vulnerabilities.append(f"ìœ„í—˜í•œ í•¨ìˆ˜ {func}: {len(results['results'])} ê³³")
            print(f"ğŸš¨ ìœ„í—˜í•œ í•¨ìˆ˜ {func}: {len(results['results'])} ê³³")

    # 3. .env íŒŒì¼ ëˆ„ì¶œ ê²€ì‚¬
    env_files = helpers.search_files(".", ".env*")
    if env_files['results']:
        print(f"ğŸ” í™˜ê²½ ë³€ìˆ˜ íŒŒì¼: {len(env_files['results'])} ê°œ")

        # .gitignoreì— .envê°€ ìˆëŠ”ì§€ í™•ì¸
        gitignore = helpers.get_file_info(".gitignore")
        if gitignore:
            gitignore_content = helpers.read_file(".gitignore")
            if ".env" not in str(gitignore_content):
                vulnerabilities.append(".env íŒŒì¼ì´ .gitignoreì— ì—†ìŒ")

    # 4. ê¶Œí•œ ì„¤ì • íŒŒì¼ ê²€ì‚¬
    chmod_usage = helpers.search_code_content(".", "chmod|777|666", "*.*")
    if chmod_usage['results']:
        vulnerabilities.append(f"ê¶Œí•œ ì„¤ì • ì£¼ì˜: {len(chmod_usage['results'])} ê³³")

    print(f"\nğŸ›¡ï¸ ë³´ì•ˆ ê²€ì‚¬ ì™„ë£Œ: {len(vulnerabilities)} ê°œ ì´ìŠˆ ë°œê²¬")
    return vulnerabilities

security_issues = security_vulnerability_scan()
```

### Git ë³´ì•ˆ ë° ìë™í™”
```python
# ğŸ”§ Git ë³´ì•ˆ ìë™í™”
def git_security_automation():
    print("ğŸ”§ Git ë³´ì•ˆ ìë™í™”")

    # 1. Git ìƒíƒœ í™•ì¸
    status = helpers.git_status()
    print(f"ğŸ“Š Git ìƒíƒœ: ìˆ˜ì • {len(status.get('modified', []))}, ì¶”ê°€ {len(status.get('untracked', []))}")

    # 2. ë¯¼ê°ì •ë³´ ì»¤ë°‹ ë°©ì§€ ê²€ì‚¬
    staged_files = status.get('staged', [])
    security_risks = []

    for file_path in staged_files:
        if file_path.endswith(('.env', '.key', '.pem', '.p12')):
            security_risks.append(f"ë¯¼ê°í•œ íŒŒì¼: {file_path}")

        # íŒŒì¼ ë‚´ìš© ê²€ì‚¬
        content = helpers.read_file(file_path)
        if any(pattern in str(content).lower() for pattern in ['password', 'secret', 'api_key']):
            security_risks.append(f"ë¯¼ê°ì •ë³´ í¬í•¨ ê°€ëŠ¥: {file_path}")

    if security_risks:
        print("ğŸš¨ ì»¤ë°‹ ì „ ë³´ì•ˆ ê²€ì‚¬ í•„ìš”:")
        for risk in security_risks:
            print(f"   âš ï¸ {risk}")
    else:
        print("âœ… ë³´ì•ˆ ê²€ì‚¬ í†µê³¼")

    # 3. ë¸Œëœì¹˜ ë³´í˜¸ ìƒíƒœ í™•ì¸
    branch = helpers.git_get_current_branch()
    print(f"ğŸŒ¿ í˜„ì¬ ë¸Œëœì¹˜: {branch}")

    if branch == "main" or branch == "master":
        print("âš ï¸ ë©”ì¸ ë¸Œëœì¹˜ì—ì„œ ì§ì ‘ ì‘ì—… ì¤‘ - ë¸Œëœì¹˜ ìƒì„± ê¶Œì¥")

    # 4. ì»¤ë°‹ ë©”ì‹œì§€ í’ˆì§ˆ ê²€ì‚¬
    recent_commits = helpers.git_log(5)  # ìµœê·¼ 5ê°œ ì»¤ë°‹
    short_messages = [c for c in recent_commits if len(c.get('message', '')) < 10]

    if short_messages:
        print(f"ğŸ“ ì§§ì€ ì»¤ë°‹ ë©”ì‹œì§€: {len(short_messages)} ê°œ - ë” ìƒì„¸í•œ ì„¤ëª… ê¶Œì¥")

    return {"security_risks": len(security_risks), "branch": branch}

git_security = git_security_automation()
```

---

## ğŸ¯ ê³ ê¸‰ ì›Œí¬í”Œë¡œìš° ìë™í™”

### CI/CD íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜
```python
# ğŸš€ CI/CD íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜
def cicd_pipeline_simulation():
    print("ğŸš€ CI/CD íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜")

    pipeline_steps = []

    # 1. ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬
    print("1ï¸âƒ£ ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬")
    py_files = helpers.search_files(".", "*.py")
    if py_files['results']:
        # ë¬¸ë²• ì˜¤ë¥˜ ê²€ì‚¬ ì‹œë®¬ë ˆì´ì…˜
        syntax_errors = helpers.search_code_content(".", "SyntaxError", "*.py")
        pipeline_steps.append(("Syntax Check", len(syntax_errors['results']) == 0))

        # ìŠ¤íƒ€ì¼ ê²€ì‚¬ ì‹œë®¬ë ˆì´ì…˜
        style_issues = helpers.search_code_content(".", "^\s{1,3}\w|^\t\w", "*.py")  # ë“¤ì—¬ì“°ê¸°
        pipeline_steps.append(("Style Check", len(style_issues['results']) < 10))

    # 2. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
    print("2ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    test_files = helpers.search_files(".", "*test*.py")
    pipeline_steps.append(("Unit Tests", len(test_files['results']) > 0))

    # 3. ë³´ì•ˆ ê²€ì‚¬
    print("3ï¸âƒ£ ë³´ì•ˆ ê²€ì‚¬")
    security_patterns = helpers.search_code_content(".", "password|secret|key", "*.*")
    pipeline_steps.append(("Security Scan", len(security_patterns['results']) == 0))

    # 4. ì˜ì¡´ì„± ê²€ì‚¬
    print("4ï¸âƒ£ ì˜ì¡´ì„± ê²€ì‚¬")
    requirements_exist = helpers.get_file_info("requirements.txt") is not None
    pipeline_steps.append(("Dependencies", requirements_exist))

    # 5. ë¬¸ì„œí™” ê²€ì‚¬
    print("5ï¸âƒ£ ë¬¸ì„œí™” ê²€ì‚¬")
    readme_exist = helpers.get_file_info("README.md") is not None
    pipeline_steps.append(("Documentation", readme_exist))

    # íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š íŒŒì´í”„ë¼ì¸ ê²°ê³¼:")
    all_passed = True
    for step_name, passed in pipeline_steps:
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"   {step_name}: {status}")
        if not passed:
            all_passed = False

    print(f"\nğŸ† ì „ì²´ íŒŒì´í”„ë¼ì¸: {'âœ… ì„±ê³µ' if all_passed else 'âŒ ì‹¤íŒ¨'}")
    return {"steps": pipeline_steps, "success": all_passed}

pipeline_result = cicd_pipeline_simulation()
```

### ìë™ ë°°í¬ ì¤€ë¹„ ê²€ì‚¬
```python
# ğŸ“¦ ìë™ ë°°í¬ ì¤€ë¹„ ê²€ì‚¬
def deployment_readiness_check():
    print("ğŸ“¦ ë°°í¬ ì¤€ë¹„ ê²€ì‚¬")

    readiness_score = 0
    max_score = 10

    checks = [
        # 1. ì½”ë“œ ì•ˆì •ì„±
        ("ëª¨ë“  í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¡´ì¬", lambda: len(helpers.search_files(".", "*test*.py")['results']) > 0),
        ("README.md ì¡´ì¬", lambda: helpers.get_file_info("README.md") is not None),
        ("requirements.txt ì¡´ì¬", lambda: helpers.get_file_info("requirements.txt") is not None),

        # 2. Git ìƒíƒœ
        ("Git ì»¤ë°‹ ìƒíƒœ ê¹”ë”", lambda: len(helpers.git_status().get('modified', [])) == 0),
        ("ë©”ì¸ ë¸Œëœì¹˜ ì•„ë‹˜", lambda: helpers.git_get_current_branch() not in ['main', 'master']),

        # 3. ë³´ì•ˆ
        ("ë¯¼ê°ì •ë³´ ì—†ìŒ", lambda: len(helpers.search_code_content(".", "password|secret", "*.*")['results']) == 0),
        (".envê°€ .gitignoreì— ìˆìŒ", lambda: ".env" in str(helpers.read_file(".gitignore") or "")),

        # 4. ì½”ë“œ í’ˆì§ˆ
        ("í° íŒŒì¼ ì—†ìŒ", lambda: all(f.get('size', 0) < 1000000 for f in helpers.scan_directory_dict(".")['files'])),
        ("TODO/FIXME ì ìŒ", lambda: len(helpers.search_code_content(".", "TODO|FIXME", "*.py")['results']) < 5),
        ("ì¤‘ë³µ ì½”ë“œ ì ìŒ", lambda: len(helpers.search_code_content(".", "(print\(.*\)){3,}", "*.py")['results']) < 3)
    ]

    print("\nğŸ” ë°°í¬ ì¤€ë¹„ ìƒíƒœ:")
    for check_name, check_func in checks:
        try:
            passed = check_func()
            status = "âœ…" if passed else "âŒ"
            print(f"   {status} {check_name}")
            if passed:
                readiness_score += 1
        except Exception as e:
            print(f"   âš ï¸ {check_name} (ê²€ì‚¬ ì‹¤íŒ¨: {e})")

    percentage = (readiness_score / max_score) * 100
    print(f"\nğŸ“Š ë°°í¬ ì¤€ë¹„ë„: {readiness_score}/{max_score} ({percentage:.1f}%)")

    if percentage >= 80:
        print("ğŸš€ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ!")
    elif percentage >= 60:
        print("âš ï¸ ë°°í¬ ê°€ëŠ¥í•˜ì§€ë§Œ ê°œì„  ê¶Œì¥")
    else:
        print("âŒ ë°°í¬ ì „ ì¶”ê°€ ì‘ì—… í•„ìš”")

    return {"score": readiness_score, "percentage": percentage}

deployment_check = deployment_readiness_check()
```

---

## ğŸ“š ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤ í•´ê²°ì±…

### ì‹œë‚˜ë¦¬ì˜¤ 1: ìƒˆ íŒ€ì› ì˜¨ë³´ë”©
```python
# ğŸ‘‹ ìƒˆ íŒ€ì›ì„ ìœ„í•œ í”„ë¡œì íŠ¸ ì˜¨ë³´ë”© ìë™í™”
def onboarding_automation():
    print("ğŸ‘‹ ìƒˆ íŒ€ì› ì˜¨ë³´ë”© ìë™í™”")

    # 1. í”„ë¡œì íŠ¸ ê°œìš” ìƒì„±
    structure = helpers.scan_directory_dict(".")
    context = helpers.get_context()

    overview = {
        "project_name": context.get('project_name', 'Unknown'),
        "total_files": len(structure['files']),
        "python_files": len(helpers.search_files(".", "*.py")['results']),
        "test_files": len(helpers.search_files(".", "*test*.py")['results']),
        "config_files": len(helpers.search_files(".", "*.json")['results'])
    }

    print("ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”:")
    for key, value in overview.items():
        print(f"   â€¢ {key}: {value}")

    # 2. í•µì‹¬ íŒŒì¼ ì‹ë³„
    important_files = []

    # ì„¤ì • íŒŒì¼ë“¤
    config_candidates = ["package.json", "requirements.txt", "config.json", ".env.example"]
    for file_name in config_candidates:
        if helpers.get_file_info(file_name):
            important_files.append(f"ğŸ“„ {file_name}: ì„¤ì • íŒŒì¼")

    # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
    main_files = helpers.search_files(".", "main.py")
    main_files.update(helpers.search_files(".", "app.py"))
    main_files.update(helpers.search_files(".", "index.py"))

    for file_info in main_files['results']:
        important_files.append(f"ğŸš€ {file_info['name']}: ë©”ì¸ ì‹¤í–‰ íŒŒì¼")

    # 3. ê°œë°œ í™˜ê²½ ì„¤ì • ê°€ì´ë“œ
    setup_commands = []

    if helpers.get_file_info("requirements.txt"):
        setup_commands.append("pip install -r requirements.txt")

    if helpers.get_file_info("package.json"):
        setup_commands.append("npm install")

    if helpers.get_file_info(".env.example"):
        setup_commands.append("cp .env.example .env")

    print("\nğŸ› ï¸ ê°œë°œ í™˜ê²½ ì„¤ì •:")
    for i, cmd in enumerate(setup_commands, 1):
        print(f"   {i}. {cmd}")

    # 4. ì˜¨ë³´ë”© ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
    checklist = [
        "ì €ì¥ì†Œ í´ë¡ ",
        "ì˜ì¡´ì„± ì„¤ì¹˜",
        "í™˜ê²½ ë³€ìˆ˜ ì„¤ì •",
        "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • (í•´ë‹¹ì‹œ)",
        "í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
        "ê°œë°œ ì„œë²„ ì‹¤í–‰"
    ]

    print("\nâœ… ì˜¨ë³´ë”© ì²´í¬ë¦¬ìŠ¤íŠ¸:")
    for item in checklist:
        print(f"   â–¡ {item}")

    return {"overview": overview, "setup_commands": setup_commands}

onboarding_info = onboarding_automation()
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ê¸´ê¸‰ ë²„ê·¸ ìˆ˜ì •
```python
# ğŸš¨ ê¸´ê¸‰ ë²„ê·¸ ìˆ˜ì • ì›Œí¬í”Œë¡œìš°
def emergency_bug_fix_workflow(bug_description):
    print(f"ğŸš¨ ê¸´ê¸‰ ë²„ê·¸ ìˆ˜ì •: {bug_description}")

    # 1. í˜„ì¬ ìƒíƒœ ë°±ì—…
    print("1ï¸âƒ£ í˜„ì¬ ìƒíƒœ ë°±ì—…")
    git_status = helpers.git_status()
    if git_status.get('modified'):
        print("âš ï¸ ìˆ˜ì •ëœ íŒŒì¼ ìˆìŒ - ìŠ¤íƒœì‹œ ê¶Œì¥")
        # helpers.git_stash("Emergency backup before bug fix")

    # 2. ë²„ê·¸ ê´€ë ¨ íŒŒì¼ ê²€ìƒ‰
    print("2ï¸âƒ£ ë²„ê·¸ ê´€ë ¨ íŒŒì¼ ê²€ìƒ‰")
    keywords = bug_description.lower().split()[:3]
    related_files = []

    for keyword in keywords:
        results = helpers.search_code_content(".", keyword, "*.*")
        related_files.extend(results['results'])

    print(f"ğŸ” ê´€ë ¨ íŒŒì¼ {len(related_files)} ê°œ ë°œê²¬")

    # 3. ìµœê·¼ ë³€ê²½ì‚¬í•­ ë¶„ì„
    print("3ï¸âƒ£ ìµœê·¼ ë³€ê²½ì‚¬í•­ ë¶„ì„")
    recent_commits = helpers.git_log(10)
    recent_files = []

    for commit in recent_commits:
        # ì»¤ë°‹ì—ì„œ ë³€ê²½ëœ íŒŒì¼ë“¤ (ì‹¤ì œë¡œëŠ” git showë¡œ ê°€ì ¸ì™€ì•¼ í•¨)
        if any(keyword in commit.get('message', '').lower() for keyword in keywords):
            print(f"ğŸ“ ì˜ì‹¬ ì»¤ë°‹: {commit.get('message', '')[:50]}...")

    # 4. í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸
    print("4ï¸âƒ£ ê´€ë ¨ í…ŒìŠ¤íŠ¸ í™•ì¸")
    test_files = helpers.search_files(".", "*test*.py")
    relevant_tests = []

    for test_file in test_files['results']:
        test_content = helpers.read_file(test_file['path'])
        if any(keyword in str(test_content).lower() for keyword in keywords):
            relevant_tests.append(test_file['path'])

    print(f"ğŸ§ª ê´€ë ¨ í…ŒìŠ¤íŠ¸: {len(relevant_tests)} ê°œ")

    # 5. ìˆ˜ì • ê³„íš ìˆ˜ë¦½
    fix_plan = [
        "ë²„ê·¸ ì¬í˜„ í…ŒìŠ¤íŠ¸ ì‘ì„±",
        "ë¬¸ì œ ì½”ë“œ ìˆ˜ì •",
        "í…ŒìŠ¤íŠ¸ ì‹¤í–‰ìœ¼ë¡œ ìˆ˜ì • í™•ì¸",
        "íšŒê·€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
        "í•«í”½ìŠ¤ ì»¤ë°‹ ë° ë°°í¬"
    ]

    print("\nğŸ”§ ìˆ˜ì • ê³„íš:")
    for i, step in enumerate(fix_plan, 1):
        print(f"   {i}. {step}")

    return {
        "related_files": len(related_files),
        "relevant_tests": len(relevant_tests),
        "fix_plan": fix_plan
    }

# ì˜ˆì‹œ ì‹¤í–‰
bug_fix_info = emergency_bug_fix_workflow("ì‚¬ìš©ì ë¡œê·¸ì¸ ì‹¤íŒ¨")
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ì„±ëŠ¥ ìµœì í™” í”„ë¡œì íŠ¸
```python
# âš¡ ì„±ëŠ¥ ìµœì í™” í”„ë¡œì íŠ¸ ì›Œí¬í”Œë¡œìš°
def performance_optimization_project():
    print("âš¡ ì„±ëŠ¥ ìµœì í™” í”„ë¡œì íŠ¸ ì‹œì‘")

    optimization_report = {}

    # 1. í˜„ì¬ ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸ ì¸¡ì •
    print("1ï¸âƒ£ ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸ ì¸¡ì •")

    # íŒŒì¼ í¬ê¸° ë¶„ì„
    structure = helpers.scan_directory_dict(".")
    large_files = [f for f in structure['files'] if f.get('size', 0) > 100000]  # 100KB ì´ìƒ
    optimization_report['large_files'] = len(large_files)
    print(f"ğŸ“ í° íŒŒì¼ (100KB+): {len(large_files)} ê°œ")

    # 2. ì½”ë“œ ë³µì¡ë„ ë¶„ì„
    print("2ï¸âƒ£ ì½”ë“œ ë³µì¡ë„ ë¶„ì„")

    # ê¸´ í•¨ìˆ˜ ê²€ìƒ‰
    long_functions = helpers.search_code_content(".", r"def\s+\w+.*:\n(.*\n){25,}", "*.py")
    optimization_report['long_functions'] = len(long_functions['results'])

    # ì¤‘ì²© ë£¨í”„ ê²€ìƒ‰
    nested_loops = helpers.search_code_content(".", r"for\s+\w+.*:\s*\n\s*for\s+\w+.*:", "*.py")
    optimization_report['nested_loops'] = len(nested_loops['results'])

    print(f"ğŸ”„ ê¸´ í•¨ìˆ˜ (25ë¼ì¸+): {len(long_functions['results'])} ê°œ")
    print(f"ğŸ” ì¤‘ì²© ë£¨í”„: {len(nested_loops['results'])} ê°œ")

    # 3. ì˜ì¡´ì„± ë¶„ì„
    print("3ï¸âƒ£ ì˜ì¡´ì„± ìµœì í™” ë¶„ì„")

    # import ë¬¸ ë¶„ì„
    imports = helpers.search_code_content(".", r"^import\s+|^from\s+", "*.py")
    optimization_report['total_imports'] = len(imports['results'])

    # ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê²€ìƒ‰
    heavy_libs = ['pandas', 'numpy', 'tensorflow', 'torch', 'scipy']
    heavy_usage = []

    for lib in heavy_libs:
        usage = helpers.search_code_content(".", f"import {lib}|from {lib}", "*.py")
        if usage['results']:
            heavy_usage.append(lib)

    optimization_report['heavy_libraries'] = len(heavy_usage)
    print(f"ğŸ“¦ ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬: {len(heavy_usage)} ê°œ ({', '.join(heavy_usage)})")

    # 4. ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
    print("4ï¸âƒ£ ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´")

    # ëŒ€ìš©ëŸ‰ ë°ì´í„° êµ¬ì¡° ê²€ìƒ‰
    large_data = helpers.search_code_content(".", r"list\(range\([0-9]{4,}\)|\[[^\]]{100,}\]", "*.py")
    optimization_report['large_data_structures'] = len(large_data['results'])

    # ì „ì—­ ë³€ìˆ˜ ê²€ìƒ‰
    global_vars = helpers.search_code_content(".", r"^[A-Z_]{2,}\s*=", "*.py")
    optimization_report['global_variables'] = len(global_vars['results'])

    print(f"ğŸ§  ëŒ€ìš©ëŸ‰ ë°ì´í„° êµ¬ì¡°: {len(large_data['results'])} ê°œ")
    print(f"ğŸŒ ì „ì—­ ë³€ìˆ˜: {len(global_vars['results'])} ê°œ")

    # 5. ìµœì í™” ìš°ì„ ìˆœìœ„ ê³„ì‚°
    print("\n5ï¸âƒ£ ìµœì í™” ìš°ì„ ìˆœìœ„")

    priorities = []

    if optimization_report['nested_loops'] > 5:
        priorities.append("ğŸ”¥ ë†’ìŒ: ì¤‘ì²© ë£¨í”„ ìµœì í™”")

    if optimization_report['large_files'] > 10:
        priorities.append("ğŸ”¥ ë†’ìŒ: í° íŒŒì¼ ë¶„í• ")

    if optimization_report['long_functions'] > 15:
        priorities.append("ğŸŸ¡ ì¤‘ê°„: í•¨ìˆ˜ ë¶„í• ")

    if optimization_report['heavy_libraries'] > 3:
        priorities.append("ğŸŸ¡ ì¤‘ê°„: ì˜ì¡´ì„± ìµœì í™”")

    if optimization_report['large_data_structures'] > 5:
        priorities.append("ğŸŸ¢ ë‚®ìŒ: ë°ì´í„° êµ¬ì¡° ìµœì í™”")

    print("ğŸ“Š ìµœì í™” ìš°ì„ ìˆœìœ„:")
    for priority in priorities:
        print(f"   â€¢ {priority}")

    return optimization_report

perf_optimization = performance_optimization_project()
```

---

## ğŸ‰ ë§ˆë¬´ë¦¬: execute_code ë§ˆìŠ¤í„° ë˜ê¸°

### í•µì‹¬ ì›ì¹™
1. **ëª¨ë“  ì‘ì—…ì„ execute_codeë¡œ**: íŒŒì¼ ì½ê¸°, ê²€ìƒ‰, Git ì‘ì—… ë“± ëª¨ë“  ê²ƒ
2. **helpers í•¨ìˆ˜ ì ê·¹ í™œìš©**: 97ê°œ í•¨ìˆ˜ë¡œ ëª¨ë“  ê°œë°œ ì‘ì—… ìë™í™”
3. **ì‹¤ì‹œê°„ í”¼ë“œë°±**: ëª¨ë“  ì‹¤í–‰ì˜ ê²°ê³¼ë¥¼ ì¦‰ì‹œ í™•ì¸
4. **ì›Œí¬í”Œë¡œìš° í†µí•©**: ê°œë³„ ì‘ì—…ì´ ì•„ë‹Œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ìë™í™”
5. **ì§€ì†ì  ê°œì„ **: ë§¤ë²ˆ ë” íš¨ìœ¨ì ì¸ íŒ¨í„´ ê°œë°œ

### ë‹¤ìŒ ë‹¨ê³„
```python
# ğŸš€ execute_code ë§ˆìŠ¤í„°ë¡œ ê°€ëŠ” ê¸¸
def become_execute_code_master():
    print("ğŸš€ execute_code ë§ˆìŠ¤í„° ë˜ê¸°")

    # 1. ë§¤ì¼ ì—°ìŠµí•  íŒ¨í„´ë“¤
    daily_practices = [
        "í”„ë¡œì íŠ¸ ìƒíƒœ ëª¨ë‹ˆí„°ë§",
        "ì½”ë“œ í’ˆì§ˆ ìë™ ê²€ì‚¬", 
        "Git ì›Œí¬í”Œë¡œìš° ìë™í™”",
        "ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™”",
        "ë³´ì•ˆ ì·¨ì•½ì  ìŠ¤ìº”"
    ]

    print("ğŸ“… ë§¤ì¼ ì—°ìŠµ:")
    for practice in daily_practices:
        print(f"   â€¢ {practice}")

    # 2. ê³ ê¸‰ ê¸°ìˆ  ë¡œë“œë§µ
    advanced_skills = [
        "ì»¤ìŠ¤í…€ helpers í•¨ìˆ˜ ê°œë°œ",
        "ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìë™í™”",
        "AI ê¸°ë°˜ ì½”ë“œ ë¶„ì„ í†µí•©",
        "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ",
        "ì™„ì „ ìë™í™”ëœ CI/CD"
    ]

    print("\nğŸ¯ ê³ ê¸‰ ê¸°ìˆ  ë¡œë“œë§µ:")
    for skill in advanced_skills:
        print(f"   â€¢ {skill}")

    # 3. ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸
    mastery_checklist = [
        "helpers í•¨ìˆ˜ 97ê°œ ëª¨ë‘ í™œìš© ê°€ëŠ¥",
        "ëª¨ë“  ê°œë°œ ì‘ì—…ì„ execute_codeë¡œ ìˆ˜í–‰",
        "ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìë™í™” êµ¬ì¶•",
        "ì„±ëŠ¥ê³¼ ë³´ì•ˆì„ ë™ì‹œì— ê³ ë ¤",
        "íŒ€ ì „ì²´ì˜ ìƒì‚°ì„± í–¥ìƒì— ê¸°ì—¬"
    ]

    print("\nâœ… ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸:")
    for item in mastery_checklist:
        print(f"   â–¡ {item}")

    print("\nğŸ† ì¶•í•˜í•©ë‹ˆë‹¤! ì´ì œ ì§„ì •í•œ execute_code ë§ˆìŠ¤í„°ì…ë‹ˆë‹¤!")

become_execute_code_master()
```

---

**ğŸ¯ ì´ ê°€ì´ë“œë¡œ Claude Code + ai-coding-brain-mcpì˜ ëª¨ë“  ì ì¬ë ¥ì„ ë°œíœ˜í•˜ì„¸ìš”!**

- ëª¨ë“  ì½”ë“œëŠ” ë³µì‚¬-ë¶™ì—¬ë„£ê¸°ë¡œ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
- 97ê°œ helpers í•¨ìˆ˜ì˜ ì™„ì „í•œ í™œìš©ë²• 
- ì‹¤ì „ ì¤‘ì‹¬ì˜ ë¬¸ì œ í•´ê²° ì›Œí¬í”Œë¡œìš°
- ì§€ì†ì ì¸ í•™ìŠµê³¼ ê°œì„ ì„ ìœ„í•œ ì²´ê³„ì  ì ‘ê·¼

**ğŸš€ ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”!**

---

> ğŸ’¡ **íŒ**: ê° ì„¹ì…˜ì˜ ì½”ë“œë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ë©´ì„œ ì—¬ëŸ¬ë¶„ë§Œì˜ ê°œë°œ ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”!

> ğŸ”— **ì°¸ê³ **: ë” ìì„¸í•œ ê¸°ìˆ  ë¬¸ì„œëŠ” `WORKFLOW_TECHNICAL_DOC.md`ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
