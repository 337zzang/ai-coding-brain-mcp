"""
ë””ë ‰í† ë¦¬ ìŠ¤ìº” ì „ë¬¸ ëª¨ë“ˆ

ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ìŠ¤ìº”í•˜ê³  ë¶„ì„í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import time
from typing import List, Dict, Any, Optional, Union
from pathlib import Path
from datetime import datetime

from ..helper_result import HelperResult
from .types import DirectoryScanResult
from .core import (
    normalize_path,
    should_ignore,
    DEFAULT_IGNORE_PATTERNS
)


def scan_directory(
    path: Union[str, Path] = '.',
    max_depth: int = -1,
    include_hidden: bool = False,
    ignore_patterns: Optional[List[str]] = None
) -> HelperResult:
    """ë””ë ‰í† ë¦¬ ìŠ¤ìº” (ë”•ì…”ë„ˆë¦¬ í˜•ì‹)
    
    Args:
        path: ìŠ¤ìº”í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        max_depth: ìµœëŒ€ ê¹Šì´ (-1ì€ ë¬´ì œí•œ)
        include_hidden: ìˆ¨ê¹€ íŒŒì¼/ë””ë ‰í† ë¦¬ í¬í•¨ ì—¬ë¶€
        ignore_patterns: ë¬´ì‹œí•  íŒ¨í„´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        HelperResult with DirectoryScanResult
    """
    # ê²½ë¡œ ì •ê·œí™”
    directory_path = normalize_path(path)
    
    if not directory_path.exists():
        return HelperResult.fail(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {directory_path}")
    
    if not directory_path.is_dir():
        return HelperResult.fail(f"ë””ë ‰í† ë¦¬ê°€ ì•„ë‹˜: {directory_path}")
    
    # ë¬´ì‹œ íŒ¨í„´ ì„¤ì •
    if ignore_patterns is None:
        ignore_patterns = DEFAULT_IGNORE_PATTERNS
    
    result = {
        'files': [],
        'directories': [],
        'total_size': 0,
        'stats': {
            'file_count': 0,
            'dir_count': 0,
            'by_extension': {}
        }
    }
    
    def scan_recursive(dir_path: Path, current_depth: int = 0):
        """ì¬ê·€ì ìœ¼ë¡œ ë””ë ‰í† ë¦¬ ìŠ¤ìº”"""
        if max_depth != -1 and current_depth > max_depth:
            return
        
        try:
            for item in dir_path.iterdir():
                # ìˆ¨ê¹€ í•­ëª© ì²˜ë¦¬
                if not include_hidden and item.name.startswith('.'):
                    continue
                
                # ë¬´ì‹œ íŒ¨í„´ ì²´í¬
                if should_ignore(item, ignore_patterns):
                    continue
                
                try:
                    if item.is_file():
                        size = item.stat().st_size
                        result['files'].append({
                            'name': item.name,
                            'path': str(item),
                            'size': size
                        })
                        result['total_size'] += size
                        result['stats']['file_count'] += 1
                        
                        # í™•ì¥ìë³„ í†µê³„
                        ext = item.suffix.lower()
                        if ext:
                            result['stats']['by_extension'][ext] = \
                                result['stats']['by_extension'].get(ext, 0) + 1
                    
                    elif item.is_dir():
                        result['directories'].append({
                            'name': item.name,
                            'path': str(item)
                        })
                        result['stats']['dir_count'] += 1
                        
                        # í•˜ìœ„ ë””ë ‰í† ë¦¬ ìŠ¤ìº”
                        scan_recursive(item, current_depth + 1)
                        
                except (PermissionError, OSError):
                    continue
                    
        except (PermissionError, OSError):
            pass
    
    # ìŠ¤ìº” ì‹œì‘
    scan_recursive(directory_path)
    
    return HelperResult.success(result)



def get_directory_tree(
    path: Union[str, Path] = '.',
    max_depth: int = 3,
    show_files: bool = True,
    **kwargs
) -> HelperResult:
    """ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
    
    Args:
        path: ì‹œì‘ ê²½ë¡œ
        max_depth: ìµœëŒ€ ê¹Šì´
        show_files: íŒŒì¼ í‘œì‹œ ì—¬ë¶€
        **kwargs: scan_directoryì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        
    Returns:
        HelperResult with tree structure
    """
    # ë””ë ‰í† ë¦¬ ìŠ¤ìº”
    scan_result = scan_directory(path, max_depth, **kwargs)
    if not scan_result.ok:
        return scan_result
    
    data = scan_result.data
    
    # íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
    tree_lines = []
    base_path = normalize_path(path)
    tree_lines.append(str(base_path.name) + "/")
    
    def build_tree(base: Path, prefix: str = "", depth: int = 0):
        if max_depth != -1 and depth >= max_depth:
            return
        
        items = []
        
        # ë””ë ‰í† ë¦¬ ì¶”ê°€
        for dir_info in data['directories']:
            dir_path = Path(dir_info['path'])
            if dir_path.parent == base:
                items.append(('d', dir_info['name']))
        
        # íŒŒì¼ ì¶”ê°€
        if show_files:
            for file_info in data['files']:
                file_path = Path(file_info['path'])
                if file_path.parent == base:
                    items.append(('f', file_info['name']))
        
        # ì •ë ¬
        items.sort(key=lambda x: (x[0], x[1]))
        
        # ì¶œë ¥
        for i, (item_type, name) in enumerate(items):
            is_last = i == len(items) - 1
            
            if is_last:
                tree_lines.append(prefix + "â””â”€â”€ " + name + ("/" if item_type == 'd' else ""))
                new_prefix = prefix + "    "
            else:
                tree_lines.append(prefix + "â”œâ”€â”€ " + name + ("/" if item_type == 'd' else ""))
                new_prefix = prefix + "â”‚   "
            
            # ë””ë ‰í† ë¦¬ë©´ ì¬ê·€
            if item_type == 'd':
                build_tree(base / name, new_prefix, depth + 1)
    
    build_tree(base_path, "", 0)
    
    return HelperResult.success({
        'tree': '\n'.join(tree_lines),
        'stats': data['stats']
    })


def analyze_directory(
    path: Union[str, Path] = '.',
    **kwargs
) -> HelperResult:
    """ë””ë ‰í† ë¦¬ ìƒì„¸ ë¶„ì„
    
    Args:
        path: ë¶„ì„í•  ê²½ë¡œ
        **kwargs: scan_directoryì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        
    Returns:
        HelperResult with detailed analysis
    """
    # ë””ë ‰í† ë¦¬ ìŠ¤ìº”
    scan_result = scan_directory(path, **kwargs)
    if not scan_result.ok:
        return scan_result
    
    data = scan_result.data
    
    # ìƒì„¸ ë¶„ì„
    analysis = {
        'summary': {
            'total_files': data['stats']['file_count'],
            'total_directories': data['stats']['dir_count'],
            'total_size': data['total_size'],
            'total_size_mb': round(data['total_size'] / (1024 * 1024), 2)
        },
        'by_extension': data['stats']['by_extension'],
        'largest_files': [],
        'newest_files': [],
        'file_types': {}
    }
    
    # ê°€ì¥ í° íŒŒì¼ë“¤
    files_with_details = []
    for file_info in data['files']:
        try:
            file_path = Path(file_info['path'])
            stat = file_path.stat()
            files_with_details.append({
                **file_info,
                'modified': stat.st_mtime
            })
        except:
            pass
    
    # í¬ê¸°ìˆœ ì •ë ¬
    files_by_size = sorted(files_with_details, key=lambda x: x['size'], reverse=True)
    analysis['largest_files'] = files_by_size[:10]
    
    # ìˆ˜ì •ì‹œê°„ìˆœ ì •ë ¬
    files_by_time = sorted(files_with_details, key=lambda x: x['modified'], reverse=True)
    analysis['newest_files'] = files_by_time[:10]
    
    # íŒŒì¼ íƒ€ì… ë¶„ë¥˜
    for ext, count in data['stats']['by_extension'].items():
        file_type = get_file_type(ext)
        analysis['file_types'][file_type] = analysis['file_types'].get(file_type, 0) + count
    
    return HelperResult.success(analysis)


def get_file_type(extension: str) -> str:
    """í™•ì¥ìë¡œ íŒŒì¼ íƒ€ì… ë¶„ë¥˜"""
    ext = extension.lower()
    
    if ext in ['.py', '.pyw']:
        return 'Python'
    elif ext in ['.js', '.jsx', '.ts', '.tsx']:
        return 'JavaScript/TypeScript'
    elif ext in ['.html', '.htm', '.css', '.scss', '.less']:
        return 'Web'
    elif ext in ['.json', '.yaml', '.yml', '.xml', '.toml']:
        return 'Config'
    elif ext in ['.md', '.rst', '.txt']:
        return 'Documentation'
    elif ext in ['.jpg', '.jpeg', '.png', '.gif', '.svg', '.ico']:
        return 'Image'
    elif ext in ['.zip', '.tar', '.gz', '.7z', '.rar']:
        return 'Archive'
    else:
        return 'Other'

def scan_directory_dict(directory_path):
    """ë””ë ‰í† ë¦¬ ìŠ¤ìº” - ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ ë²„ì „

    Args:
        directory_path: ìŠ¤ìº”í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ

    Returns:
        HelperResult: ì„±ê³µ ì‹œ dataì— {
            'files': [{'name': str, 'path': str, 'size': int}],
            'directories': [{'name': str, 'path': str}],
            'total_size': total_bytes,
            'stats': {
                'file_count': n,
                'dir_count': n,
                'by_extension': {'.py': count, ...}
            }
        }
    """
    try:
        result = {
            'files': [],
            'directories': [],
            'total_size': 0,
            'stats': {
                'file_count': 0,
                'dir_count': 0,
                'by_extension': {}
            }
        }

        directory_path = Path(directory_path).resolve()

        if not directory_path.exists():
            return HelperResult(ok=False, data=None, error=f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {directory_path}")

        if not directory_path.is_dir():
            return HelperResult(ok=False, data=None, error=f"ë””ë ‰í† ë¦¬ê°€ ì•„ë‹˜: {directory_path}")

        for item in directory_path.iterdir():
            try:
                if item.is_file():
                    size = item.stat().st_size
                    result['files'].append({
                        'name': item.name,
                        'path': str(item),
                        'size': size
                    })
                    result['total_size'] += size
                    result['stats']['file_count'] += 1

                    # í™•ì¥ìë³„ í†µê³„
                    ext = item.suffix.lower()
                    if ext:
                        result['stats']['by_extension'][ext] = result['stats']['by_extension'].get(ext, 0) + 1

                elif item.is_dir():
                    result['directories'].append({
                        'name': item.name,
                        'path': str(item)
                    })
                    result['stats']['dir_count'] += 1

            except (PermissionError, OSError):
                continue

        return HelperResult(ok=True, data=result, error=None)

    except Exception as e:
        return HelperResult(ok=False, data=None, error=f"ë””ë ‰í† ë¦¬ ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}")


def cache_project_structure(root_path=".", ignore_patterns=None, force_rescan=False):
    """í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ìŠ¤ìº”í•˜ê³  ìºì‹œì— ì €ì¥
    
    Args:
        root_path: ìŠ¤ìº”í•  ë£¨íŠ¸ ê²½ë¡œ
        ignore_patterns: ë¬´ì‹œí•  íŒ¨í„´ ë¦¬ìŠ¤íŠ¸
        force_rescan: ê°•ì œ ì¬ìŠ¤ìº” ì—¬ë¶€
    
    Returns:
        dict: í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ë³´
    """
    import fnmatch
    from datetime import datetime
    from pathlib import Path
    
    # DEBUG: print("\nğŸ” DEBUG: cache_project_structure ì‹œì‘")
    # print(f"   root_path: {root_path}")  # MCP JSON ì‘ë‹µ ì˜¤ì—¼ ë°©ì§€
    # print(f"   ignore_patterns ì „ë‹¬ê°’: {ignore_patterns}")  # MCP JSON ì‘ë‹µ ì˜¤ì—¼ ë°©ì§€
    # print(f"   force_rescan: {force_rescan}")  # MCP JSON ì‘ë‹µ ì˜¤ì—¼ ë°©ì§€
    
    # ê¸°ë³¸ ë¬´ì‹œ íŒ¨í„´
    # ê¸°ë³¸ ë¬´ì‹œ íŒ¨í„´ - ë” í¬ê´„ì ìœ¼ë¡œ ê°œì„ 
    if ignore_patterns is None:
        ignore_patterns = [
            # Python ê´€ë ¨
            "__pycache__", "*.pyc", "*.pyo", "*.pyd", ".Python",
            ".pytest_cache", ".mypy_cache", 
            
            # ê°€ìƒí™˜ê²½
            ".venv", "venv", "ENV", "env",
            
            # ë¹Œë“œ/ë°°í¬
            "dist", "build", "*.egg-info", "node_modules",
            
            # ë²„ì „ ê´€ë¦¬
            ".git", ".svn", ".hg",
            
            # IDE/ì—ë””í„°
            ".vscode", ".idea", "*.swp", "*.swo",
            
            # ë°±ì—…/ì„ì‹œ íŒŒì¼ - ì¤‘ìš”!
            "backup", "backups", "*.bak", "*.backup",
            ".mcp_backup_*", "backup_*", "backup_test_suite",
            
            # í…ŒìŠ¤íŠ¸ - ì¤‘ìš”!
            "test", "tests", "test_*", "*_test",
            
            # ìºì‹œ/ì„¸ì…˜ - ì¤‘ìš”!
            ".cache", ".ai_cache", "cache", ".sessions",
            "session_cache",
            
            # ë¡œê·¸
            "logs", "*.log",
            
            # ë°ì´í„°ë² ì´ìŠ¤
            "*.db", "*.sqlite*", "chroma_db",
            
            # ê¸°íƒ€
            ".vibe", "output", "tmp", "temp"
        ]
    
    # DEBUG: print(f"\nğŸ“‹ DEBUG: ë¬´ì‹œ íŒ¨í„´ ({len(ignore_patterns)}ê°œ):")
    # for i, pattern in enumerate(ignore_patterns[:10]):
    #     print(f"   {i+1}. {pattern}")  # MCP JSON ì‘ë‹µ ì˜¤ì—¼ ë°©ì§€
    # if len(ignore_patterns) > 10:
    #     print(f"   ... ì™¸ {len(ignore_patterns) - 10}ê°œ")  # MCP JSON ì‘ë‹µ ì˜¤ì—¼ ë°©ì§€
    
    # ìºì‹œ í™•ì¸
    cache_key = "project_structure"
    context = get_project_context()
    
    if not force_rescan and context:
        if 'project_structure' in context:
            cached = context.metadata.get('project_structure', {})
        else:
            # _context_managerë¥¼ í†µí•´ì„œë„ í™•ì¸
            try:
                from core.context_manager import get_context_manager
                _context_manager = get_context_manager()
                if _context_manager and hasattr(_context_manager, 'get_value'):
                    cached = _context_manager.get_value(cache_key)
                else:
                    cached = None
            except:
                cached = None
        
        if cached:
            # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬ (24ì‹œê°„)
            try:
                last_scan = datetime.fromisoformat(cached['last_scan'])
                age_hours = (datetime.now() - last_scan).total_seconds() / 3600
                
                if age_hours < 24:
                    print(f"âœ… ìºì‹œëœ êµ¬ì¡° ì‚¬ìš© (ìŠ¤ìº” í›„ {age_hours:.1f}ì‹œê°„ ê²½ê³¼)")
                    return cached
            except:
                pass
    
    # ìƒˆë¡œ ìŠ¤ìº”
    print("ğŸ” í”„ë¡œì íŠ¸ êµ¬ì¡° ìŠ¤ìº” ì¤‘...")
    structure = {}
    total_files = 0
    total_dirs = 0
    
    def should_ignore(path):
        """ê²½ë¡œê°€ ë¬´ì‹œ íŒ¨í„´ì— ë§¤ì¹˜ë˜ëŠ”ì§€ í™•ì¸"""
        import fnmatch
        
        # ì²˜ìŒ 10ë²ˆë§Œ ë””ë²„ê¹…
        if not hasattr(should_ignore, 'call_count'):
            should_ignore.call_count = 0
        
        if should_ignore.call_count < 10:
            # DEBUG: print(f"\nğŸ” DEBUG: should_ignore í˜¸ì¶œ #{should_ignore.call_count + 1}")
            # print(f"   path: {path}")  # MCP JSON ì‘ë‹µ ì˜¤ì—¼ ë°©ì§€
            should_ignore.call_count += 1
        path_str = str(path)
        path_parts = Path(path).parts
        path_name = Path(path).name
        
        # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œë§Œ ì¶œë ¥
        global debug_count
        if 'debug_count' not in globals():
            debug_count = 0
        
        for pattern in ignore_patterns:
            # ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ ì²˜ë¦¬
            if '*' in pattern or '?' in pattern:
                # íŒŒì¼ëª…ì— ëŒ€í•´ íŒ¨í„´ ë§¤ì¹­
                if fnmatch.fnmatch(path_name, pattern):
                    if debug_count < 5:
                        print(f"   ğŸš« Ignored (wildcard): {path_name} matches {pattern}")
                        debug_count += 1
                    return True
            else:
                # ì •í™•í•œ ë§¤ì¹­ (ë””ë ‰í† ë¦¬ ì´ë¦„ ë“±)
                if pattern in path_parts:
                    if debug_count < 5:
                        print(f"   ğŸš« Ignored (exact): {pattern} in {path_parts}")
                        debug_count += 1
                    return True
                # íŒŒì¼ëª… ë§¤ì¹­
                if path_name == pattern:
                    if debug_count < 5:
                        print(f"   ğŸš« Ignored (name): {path_name} == {pattern}")
                        debug_count += 1
                    return True
        
        return False
    def scan_recursive(dir_path, relative_path="/"):
        """ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ìŠ¤ìº”"""
        nonlocal total_files, total_dirs
        
        if should_ignore(dir_path):
            return
        
        try:
            items = os.listdir(dir_path)
            dirs = []
            files = []
            
            for item in items:
                item_path = os.path.join(dir_path, item)
                if os.path.isdir(item_path):
                    if not should_ignore(item_path):
                        dirs.append(item)
                        total_dirs += 1
                else:
                    if not should_ignore(item_path):
                        files.append(item)
                        total_files += 1
            
            # í˜„ì¬ ë””ë ‰í† ë¦¬ ì •ë³´ ì €ì¥
            structure[relative_path] = {
                "type": "directory",
                "children": sorted(dirs),
                "files": sorted(files),
                "file_count": len(files),
                "dir_count": len(dirs),
                "last_modified": os.path.getmtime(dir_path)
            }
            
            # í•˜ìœ„ ë””ë ‰í† ë¦¬ ìŠ¤ìº”
            for dir_name in dirs:
                sub_dir_path = os.path.join(dir_path, dir_name)
                sub_relative_path = os.path.join(relative_path, dir_name).replace("\\", "/")
                scan_recursive(sub_dir_path, sub_relative_path)
                
        except PermissionError:
            structure[relative_path] = {
                "type": "directory",
                "error": "Permission denied"
            }
    
    # ìŠ¤ìº” ì‹œì‘
    root_abs = os.path.abspath(root_path)
    scan_recursive(root_abs, "/")
    
    result = {
        "root": root_abs,
        "last_scan": datetime.now().isoformat(),
        "total_files": total_files,
        "total_dirs": total_dirs,
        "structure": structure
    }
    
    # ìºì‹œì— ì €ì¥
    if context:
        context.metadata['project_structure'] = result
        
        # _context_managerë¥¼ í†µí•´ì„œë„ ì €ì¥
        try:
            from core.context_manager import get_context_manager
            _context_manager = get_context_manager()
            if _context_manager and hasattr(_context_manager, 'update_cache'):
                _context_manager.update_cache(cache_key, result)
        except:
            pass
        
        print(f"ğŸ’¾ êµ¬ì¡° ìºì‹œ ì €ì¥ ì™„ë£Œ ({total_files}ê°œ íŒŒì¼, {total_dirs}ê°œ ë””ë ‰í† ë¦¬)")
    
    return result


def get_project_structure(force_rescan=False):
    """ìºì‹œëœ í”„ë¡œì íŠ¸ êµ¬ì¡° ë°˜í™˜ (í•„ìš”ì‹œ ìë™ ìŠ¤ìº”)
    
    Args:
        force_rescan: ê°•ì œ ì¬ìŠ¤ìº” ì—¬ë¶€
    
    Returns:
        dict: í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ë³´
    """
    return cache_project_structure(force_rescan=force_rescan)


def search_in_structure(pattern, search_type="all"):
    """ìºì‹œëœ êµ¬ì¡°ì—ì„œ íŒŒì¼/ë””ë ‰í† ë¦¬ ê²€ìƒ‰
    
    Args:
        pattern: ê²€ìƒ‰ íŒ¨í„´ (glob í˜•ì‹)
        search_type: "file", "dir", "all"
    
    Returns:
        list: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    import fnmatch
    import os
    
    # ìºì‹œëœ êµ¬ì¡° ê°€ì ¸ì˜¤ê¸°
    structure = get_project_structure()
    
    results = []
    
    for path, info in structure['structure'].items():
        if info.get('error'):
            continue
            
        # ë””ë ‰í† ë¦¬ ê²€ìƒ‰
        if search_type in ["dir", "all"] and info['type'] == 'directory':
            dir_name = os.path.basename(path.rstrip('/'))
            if dir_name and fnmatch.fnmatch(dir_name, pattern):
                results.append({
                    'type': 'directory',
                    'path': path,
                    'name': dir_name,
                    'file_count': info.get('file_count', 0),
                    'dir_count': info.get('dir_count', 0)
                })
        
        # íŒŒì¼ ê²€ìƒ‰
        if search_type in ["file", "all"] and 'files' in info:
            for file_name in info['files']:
                if fnmatch.fnmatch(file_name, pattern):
                    file_path = os.path.join(path, file_name).replace("\\", "/")
                    results.append({
                        'type': 'file',
                        'path': file_path,
                        'name': file_name,
                        'dir': path
                    })
    
    return results


