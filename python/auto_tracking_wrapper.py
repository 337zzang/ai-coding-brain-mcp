"""
ìë™ ì¶”ì  ë˜í¼ - v6.2
- execute_code í™˜ê²½ ê°œì„ 
- taskë³„ ì‘ì—… ì¶”ì  ê¸°ëŠ¥ ì¶”ê°€
- ìºì‹œ êµ¬ì¡° ê°œì„ 
- Git ìë™ ì»¤ë°‹ í†µí•© (v6.2)
"""
import sys
import os
import json
import functools
from datetime import datetime
from typing import Any, Dict, Optional, Callable

# Git Version Manager í†µí•©
try:
    from git_version_manager import get_git_manager
    GIT_AVAILABLE = True
except ImportError:
    GIT_AVAILABLE = False
    
try:
    from api.public import get_current_context
    from core.context_manager import UnifiedContextManager
except ImportError:
    pass


# ìºì‹œ ì €ì¥ ì¡°ê±´ ì œì–´ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
_operation_counter = 0
_cache_save_interval = 10  # 10íšŒë§ˆë‹¤ ì €ì¥
_excluded_operations = {'read_file', 'search_files_advanced', 'search_code_content', 'scan_directory_dict'}

# Wisdom Hooks í†µí•©
try:
    from .wisdom_hooks import get_wisdom_hooks
    WISDOM_HOOKS_AVAILABLE = True
except ImportError:
    WISDOM_HOOKS_AVAILABLE = False

    def get_current_context():
        return None
    UnifiedContextManager = None

    def update_md_files(context):
        pass

def _get_project_context():
    """í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤ - execute_code í™˜ê²½ ìµœì í™”"""
    try:
        import __main__
        if hasattr(__main__, 'context') and isinstance(__main__.context, dict):
            return __main__.context
        if 'context' in globals() and isinstance(globals()['context'], dict):
            return globals()['context']
        frame = sys._getframe()
        for _ in range(10):
            if not frame:
                break
            if 'context' in frame.f_globals:
                ctx = frame.f_globals['context']
                if isinstance(ctx, dict):
                    return ctx
            if 'context' in frame.f_locals:
                ctx = frame.f_locals['context']
                if isinstance(ctx, dict):
                    return ctx
            frame = frame.f_back
        if UnifiedContextManager:
            manager = UnifiedContextManager()
            return manager.context
        ctx = get_current_context()
        if ctx:
            return ctx
        return {'project_name': 'unknown', 'cache_version': '6.1', 'task_tracking': {}, 'current_task': None}
    except Exception as e:
        print(f'âš ï¸ Context íšë“ ì‹¤íŒ¨: {e}')
        return {'project_name': 'unknown', 'task_tracking': {}}

def track_task_operation(task_id: str, operation: str, details: Dict[str, Any]=None):
    """Task ê´€ë ¨ ì‘ì—…ì„ ì¶”ì í•©ë‹ˆë‹¤"""
    context = _get_project_context()
    if not context:
        return
    if 'task_tracking' not in context:
        context['task_tracking'] = {}
    if task_id not in context['task_tracking']:
        context['task_tracking'][task_id] = {'operations': [], 'files_modified': set(), 'functions_edited': set(), 'start_time': datetime.now().isoformat(), 'status': 'in_progress'}
    operation_record = {'timestamp': datetime.now().isoformat(), 'operation': operation, 'details': details or {}}
    context['task_tracking'][task_id]['operations'].append(operation_record)

def track_file_operation(operation_type: str):
    """íŒŒì¼ ì‘ì—… ì¶”ì  ë°ì½”ë ˆì´í„° - Task ì—°ë™ ê°œì„ """

    def decorator(func: Callable) -> Callable:

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            context = _get_project_context()
            current_task = context.get('current_task') if context else None
            file_path = args[0] if args else kwargs.get('path', kwargs.get('filepath', ''))
            result = func(*args, **kwargs)

            # Wisdom Hooks ì²´í¬ (create ì‘ì—… ì‹œ) - ê°œì„ ëœ ë²„ì „
            if WISDOM_HOOKS_AVAILABLE and operation_type == 'create':
                try:
                    from wisdom_hooks import get_wisdom_hooks
                    wisdom_hooks = get_wisdom_hooks()
                    file_path = args[0] if args else kwargs.get('file_path', '')
                    
                    # ì‹¤ì œ ë°±ì—… ì²´í¬
                    if file_path and os.path.exists(file_path):
                        wisdom_hooks.check_file_operation(file_path, operation_type)
                    
                    # ì½”ë“œ íŒ¨í„´ ì²´í¬ (.py íŒŒì¼ ì œì™¸ë¨)
                    content = args[1] if len(args) > 1 else kwargs.get('content', '')
                    if file_path and content and isinstance(content, str):
                        patterns = wisdom_hooks.check_code_patterns(content, file_path)
                        # íŒ¨í„´ ê°ì§€ ì‹œ ê²½ê³ ëŠ” wisdom_hooksì—ì„œ ìë™ ì¶œë ¥ë¨
                except Exception:
                    pass

            
            # claude_code_ai_brainì˜ track_file_access í˜¸ì¶œ
            try:
                from api.public import track_file_access as brain_track_file_access
                brain_track_file_access(file_path, operation_type)
                # ë””ë²„ê·¸ ì¶œë ¥
                if os.environ.get('DEBUG_TRACKING', '').lower() == 'true':
                    print(f"âœ… ì‘ì—… ì¶”ì ë¨: {operation_type} - {os.path.basename(file_path)}")
            except ImportError as e:
                if os.environ.get('DEBUG_TRACKING', '').lower() == 'true':
                    print(f"âŒ Import ì‹¤íŒ¨: {e}")
            except Exception as e:
                if os.environ.get('DEBUG_TRACKING', '').lower() == 'true':
                    print(f"âŒ ì¶”ì  ì‹¤íŒ¨: {e}")
            
            if context and current_task:
                track_task_operation(current_task, f'file_{operation_type}', {'file': file_path, 'operation': operation_type, 'success': bool(result)})
                if operation_type in ['write', 'modify', 'replace']:
                    if 'task_tracking' in context and current_task in context['task_tracking']:
                        context['task_tracking'][current_task]['files_modified'].add(file_path)
            if context:
                if 'file_access_history' not in context:
                    context['file_access_history'] = []
                context['file_access_history'].append({'file': file_path, 'operation': operation_type, 'timestamp': datetime.now().isoformat(), 'task_id': current_task})
                if len(context['file_access_history']) > 100:
                    context['file_access_history'] = context['file_access_history'][-100:]
            
            # Git ìë™ ì»¤ë°‹ (v6.2)
            global _git_commit_counter
            if operation_type in ['create', 'write', 'modify', 'replace']:
                _git_commit_counter += 1
                if _git_commit_counter >= _git_commit_interval:
                    _auto_git_commit(operation_type, file_path, context)
                    _git_commit_counter = 0
            
            return result
        return wrapper
    return decorator

def track_block_operation(operation_type: str):
    """ì½”ë“œ ë¸”ë¡ ì‘ì—… ì¶”ì  ë°ì½”ë ˆì´í„° - Task ì—°ë™ ê°œì„ """

    def decorator(func: Callable) -> Callable:

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            context = _get_project_context()
            current_task = context.get('current_task') if context else None
            file_path = args[0] if args else kwargs.get('file_path', '')
            block_name = args[1] if len(args) > 1 else kwargs.get('block_name', '')
            result = func(*args, **kwargs)
            if context and current_task and result:
                track_task_operation(current_task, f'block_{operation_type}', {'file': file_path, 'block': block_name, 'operation': operation_type})
                if 'task_tracking' in context and current_task in context['task_tracking']:
                    context['task_tracking'][current_task]['functions_edited'].add(f'{file_path}::{block_name}')
            if context and result:
                if 'function_edit_history' not in context:
                    context['function_edit_history'] = []
                context['function_edit_history'].append({'file': file_path, 'function': block_name, 'operation': operation_type, 'timestamp': datetime.now().isoformat(), 'task_id': current_task})
                if len(context['function_edit_history']) > 50:
                    context['function_edit_history'] = context['function_edit_history'][-50:]
            
            # Git ìë™ ì»¤ë°‹ (v6.2)
            global _git_commit_counter
            if result and operation_type in ['replace', 'insert', 'modify']:
                _git_commit_counter += 1
                if _git_commit_counter >= _git_commit_interval:
                    _auto_git_commit(operation_type, file_path, context)
                    _git_commit_counter = 0
            
            return result
        return wrapper
    return decorator

def auto_update_context(func: Callable) -> Callable:
    """
    í•¨ìˆ˜ ì‹¤í–‰ í›„ ìë™ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°ì½”ë ˆì´í„°
    """

    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        global _operation_counter
        result = func(*args, **kwargs)
        
        # í•¨ìˆ˜ëª… í™•ì¸
        func_name = func.__name__
        
        # read/search ì‘ì—…ì€ ì¹´ìš´í„°ë§Œ ì¦ê°€, ì €ì¥í•˜ì§€ ì•ŠìŒ
        if func_name in _excluded_operations:
            _operation_counter += 1
            return result
            
        # ë‹¤ë¥¸ ì‘ì—…ë“¤ì€ ì¹´ìš´í„° ì¦ê°€ í›„ ì¡°ê±´ë¶€ ì €ì¥
        _operation_counter += 1
        
        # 10íšŒë§ˆë‹¤ ë˜ëŠ” íŠ¹ì • ì¡°ê±´ì—ì„œë§Œ ì €ì¥
        if _operation_counter >= _cache_save_interval:
            import claude_code_ai_brain
            if hasattr(claude_code_ai_brain, '_context_manager') and claude_code_ai_brain._context_manager:
                try:
                    claude_code_ai_brain.save_context()
                    _operation_counter = 0  # ì¹´ìš´í„° ë¦¬ì…‹
                except Exception:
                    pass
        
        return result
    
    return wrapper

def track_task_start(task_id: str, task_info: Dict[str, Any]):
    """Task ì‹œì‘ì„ ì¶”ì í•©ë‹ˆë‹¤"""
    context = _get_project_context()
    if not context:
        return
    context['current_task'] = task_id
    track_task_operation(task_id, 'start', task_info)

def track_task_complete(task_id: str):
    """Task ì™„ë£Œë¥¼ ì¶”ì í•©ë‹ˆë‹¤"""
    context = _get_project_context()
    if not context:
        return
    if 'task_tracking' in context and task_id in context['task_tracking']:
        context['task_tracking'][task_id]['status'] = 'completed'
        context['task_tracking'][task_id]['end_time'] = datetime.now().isoformat()
        task_data = context['task_tracking'][task_id]
        summary = {'files_modified': list(task_data.get('files_modified', set())), 'functions_edited': list(task_data.get('functions_edited', set())), 'operation_count': len(task_data.get('operations', [])), 'duration': 'calculated_later'}
        track_task_operation(task_id, 'complete', summary)
    if context.get('current_task') == task_id:
        context['current_task'] = None

def track_file_access(file_path, operation, details=None):
    """íŒŒì¼ ì ‘ê·¼ ì¶”ì  í—¬í¼ í•¨ìˆ˜"""
    context = _get_project_context()
    if not context:
        return
    if 'file_access_history' not in context:
        context['file_access_history'] = []
    access_record = {'file': file_path, 'operation': operation, 'timestamp': datetime.now().isoformat(), 'task_id': context.get('current_task')}
    if details:
        access_record['details'] = details
    context['file_access_history'].append(access_record)
    if len(context['file_access_history']) > 100:
        context['file_access_history'] = context['file_access_history'][-100:]
try:
    # ì ˆëŒ€ importë¡œ ë³€ê²½í•˜ì—¬ ìˆœí™˜ import ë¬¸ì œ í•´ê²°
    from file_system_helpers import read_file as _read_file, create_file as _create_file, backup_file as _backup_file, restore_backup as _restore_backup, replace_block as _replace_block, insert_block as _insert_block
    from ast_parser_helpers import parse_with_snippets as _parse_with_snippets, get_snippet_preview as _get_snippet_preview
    from search_helpers import scan_directory as _scan_directory, search_files_advanced as _search_files_advanced, search_code_content as _search_code_content
except ImportError as e:
    print(f'Warning: ì¼ë¶€ í—¬í¼ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}')

    def _read_file(*args, **kwargs):
        raise ImportError('file_system_helpers not available')

    def _create_file(*args, **kwargs):
        raise ImportError('file_system_helpers not available')

    def _backup_file(*args, **kwargs):
        raise ImportError('file_system_helpers not available')

    def _restore_backup(*args, **kwargs):
        raise ImportError('file_system_helpers not available')

    def _replace_block(*args, **kwargs):
        raise ImportError('file_system_helpers not available')

    def _insert_block(*args, **kwargs):
        raise ImportError('file_system_helpers not available')

    def _parse_with_snippets(*args, **kwargs):
        raise ImportError('ast_parser_helpers not available')

    def _get_snippet_preview(*args, **kwargs):
        raise ImportError('ast_parser_helpers not available')

    def _scan_directory(*args, **kwargs):
        raise ImportError('search_helpers not available')

    def _search_files_advanced(*args, **kwargs):
        raise ImportError('search_helpers not available')

    def _search_code_content(*args, **kwargs):
        raise ImportError('search_helpers not available')

# ===== ì¶”ì  ê¸°ëŠ¥ì´ ì ìš©ëœ ìµœì¢… í•¨ìˆ˜ ì •ì˜ =====

# 1. ì¼ë°˜ì ì¸ ì¶”ì  í•¨ìˆ˜ë“¤ (ë°ì½”ë ˆì´í„° ì²´ì´ë‹)
read_file = track_file_operation('read')(_read_file)
create_file = auto_update_context(track_file_operation('create')(_create_file))
restore_backup = auto_update_context(track_file_operation('restore')(_restore_backup))
replace_block = auto_update_context(track_block_operation('replace')(_replace_block))
insert_block = auto_update_context(track_block_operation('insert')(_insert_block))

# 2. backup_file: Wisdom Hooksë¥¼ ìœ„í•œ ì¶”ê°€ ë¡œì§ì´ í•„ìš”í•˜ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
def backup_file_wisdom_wrapper(*args, **kwargs):
    """Wisdom Hooks ì¶”ì  ë¡œì§ì„ í¬í•¨í•˜ëŠ” ë‚´ë¶€ ë˜í¼"""
    # file_system_helpersì—ì„œ ê°€ì ¸ì˜¨ ìˆœìˆ˜ í•¨ìˆ˜ í˜¸ì¶œ
    result = _backup_file(*args, **kwargs)

    # ë°±ì—… ì„±ê³µ ì‹œ Wisdom Hooksì— ê¸°ë¡
    if result and WISDOM_HOOKS_AVAILABLE:
        try:
            from wisdom_hooks import get_wisdom_hooks
            wisdom_hooks = get_wisdom_hooks()
            file_path = args[0] if args else kwargs.get('filepath', '')
            if file_path:
                wisdom_hooks.track_backup(file_path)
        except Exception as e:
            # ì¶”ì  ì˜¤ë¥˜ëŠ” ì „ì²´ ì‹¤í–‰ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ ì²˜ë¦¬
            if os.environ.get('DEBUG_TRACKING', '').lower() == 'true':
                print(f"âŒ Wisdom Hook (backup) ì¶”ì  ì‹¤íŒ¨: {e}")

    return result

# ìµœì¢…ì ìœ¼ë¡œ backup_file í•¨ìˆ˜ì— ëª¨ë“  ë°ì½”ë ˆì´í„°ë¥¼ ì ìš©
# ìˆœì„œ: task ì¶”ì  -> ì»¨í…ìŠ¤íŠ¸ ìë™ ì—…ë°ì´íŠ¸
backup_file = auto_update_context(track_file_operation('backup')(backup_file_wisdom_wrapper))

def parse_with_snippets(file_path, language='auto', include_snippets=True):
    """íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ì •ë³´ì™€ ì½”ë“œ ìŠ¤ë‹ˆí« ì¶”ì¶œ - ìë™ ìºì‹œ ì €ì¥ í¬í•¨"""
    import os
    from datetime import datetime
    result = _parse_with_snippets(file_path, language, include_snippets)
    if os.path.exists(file_path):
        try:
            from api.public import track_file_access
            track_file_access(file_path, 'parse')
        except:
            pass
    if result and result.get('parsing_success'):
        context = _get_project_context()
        if context:
            if 'analyzed_files' not in context:
                context['analyzed_files'] = {}
            file_info = {'path': file_path, 'language': result.get('language', 'unknown'), 'size': os.path.getsize(file_path), 'last_analyzed': datetime.now().isoformat(), 'functions': len(result.get('functions', [])), 'classes': len(result.get('classes', [])), 'imports': len(result.get('imports', [])), 'function_names': [f.get('name', '') for f in result.get('functions', [])], 'class_names': [c.get('name', '') for c in result.get('classes', [])], 'snippets': []}
            for func in result.get('functions', [])[:10]:
                file_info['snippets'].append({'type': 'function', 'name': func.get('name'), 'line_start': func.get('line_start'), 'line_end': func.get('line_end')})
            for cls in result.get('classes', []):
                file_info['snippets'].append({'type': 'class', 'name': cls.get('name'), 'line_start': cls.get('line_start'), 'line_end': cls.get('line_end')})
            context['analyzed_files'][file_path] = file_info
            if os.environ.get('DEBUG_CACHE', '').lower() == 'true':
                print(f"âœ… ìºì‹œ ìë™ ì €ì¥: {os.path.basename(file_path)} (í•¨ìˆ˜: {file_info['functions']}ê°œ, í´ë˜ìŠ¤: {file_info['classes']}ê°œ)")
    return result

def get_snippet_preview(file_path, element_name, element_type='function', max_lines=10, start_line=-1, end_line=-1):
    """ì½”ë“œ ìŠ¤ë‹ˆí« ë¯¸ë¦¬ë³´ê¸° (ì¶”ì  í¬í•¨)"""
    import os
    result = _get_snippet_preview(file_path, element_name, element_type, max_lines, start_line, end_line)
    if os.path.exists(file_path):
        try:
            from api.public import track_file_access
            track_file_access(file_path, 'preview')
        except:
            pass
    return result



def scan_directory_dict(directory_path):
    """ë””ë ‰í† ë¦¬ ìŠ¤ìº” - ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ ë²„ì „
    
    Args:
        directory_path: ìŠ¤ìº”í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        dict: {
            'files': {filename: {'size': bytes, 'size_str': '1.2KB'}},
            'directories': [dirname1, dirname2, ...],
            'total_size': total_bytes,
            'stats': {
                'file_count': n,
                'dir_count': n,
                'by_extension': {'.py': count, ...}
            }
        }
    """
    # scan_directory í˜¸ì¶œ (ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
    scan_list = scan_directory(directory_path)
    
    result = {
        'files': {},
        'directories': [],
        'total_size': 0,
        'stats': {
            'file_count': 0,
            'dir_count': 0,
            'by_extension': {}
        }
    }
    
    for item in scan_list:
        if '[FILE]' in item:
            # "[FILE] filename.ext (123B)" í˜•ì‹ íŒŒì‹±
            parts = item.replace('[FILE]', '').strip()
            if '(' in parts and ')' in parts:
                filename = parts[:parts.rfind('(')].strip()
                size_str = parts[parts.rfind('(')+1:parts.rfind(')')].strip()
                
                # í¬ê¸° ë³€í™˜ (B, KB, MB, GB)
                size_bytes = 0
                try:
                    if size_str.endswith('GB'):
                        size_bytes = int(float(size_str[:-2]) * 1024 * 1024 * 1024)
                    elif size_str.endswith('MB'):
                        size_bytes = int(float(size_str[:-2]) * 1024 * 1024)
                    elif size_str.endswith('KB'):
                        size_bytes = int(float(size_str[:-2]) * 1024)
                    elif size_str.endswith('B'):
                        size_bytes = int(float(size_str[:-1]))
                except ValueError:
                    size_bytes = 0
                
                result['files'][filename] = {
                    'size': size_bytes,
                    'size_str': size_str
                }
                result['total_size'] += size_bytes
                result['stats']['file_count'] += 1
                
                # í™•ì¥ìë³„ í†µê³„
                if '.' in filename:
                    ext = filename[filename.rfind('.'):]
                    result['stats']['by_extension'][ext] = result['stats']['by_extension'].get(ext, 0) + 1
            else:
                # í¬ê¸° ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
                filename = parts
                result['files'][filename] = {'size': 0, 'size_str': '0B'}
                result['stats']['file_count'] += 1
                
        elif '[DIR]' in item:
            dirname = item.replace('[DIR]', '').strip()
            result['directories'].append(dirname)
            result['stats']['dir_count'] += 1
    
    # ì¶”ì  ì—…ë°ì´íŠ¸
    try:
        track_file_access(directory_path, 'scan_directory_dict')
    except:
        pass
    
    return result
def search_files_advanced(directory, pattern='*', file_extensions=None, exclude_patterns=None, 
                           case_sensitive=False, recursive=True, max_results=100, 
                           include_dirs=False, timeout_ms=30000):
    """
    ê³ ê¸‰ íŒŒì¼ ê²€ìƒ‰ (ì¶”ì  í¬í•¨)
    
    Args:
        directory: ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬
        pattern: íŒŒì¼ëª… íŒ¨í„´ (ê¸°ë³¸: '*')
        file_extensions: íŒŒì¼ í™•ì¥ì í•„í„° (ë¯¸ì‚¬ìš©, í˜¸í™˜ì„± ìœ ì§€)
        exclude_patterns: ì œì™¸ íŒ¨í„´ (ë¯¸ì‚¬ìš©, í˜¸í™˜ì„± ìœ ì§€)
        case_sensitive: ëŒ€ì†Œë¬¸ì êµ¬ë¶„ (ë¯¸ì‚¬ìš©, í˜¸í™˜ì„± ìœ ì§€)
        recursive: í•˜ìœ„ ë””ë ‰í† ë¦¬ í¬í•¨ (ê¸°ë³¸: True)
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 100)
        include_dirs: ë””ë ‰í† ë¦¬ í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸: False)
        timeout_ms: íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸: 30000ms)
        
    Returns:
        dict: ê²€ìƒ‰ ê²°ê³¼
    """
    # íŒŒì¼ í™•ì¥ì ì²˜ë¦¬ (í˜¸í™˜ì„± ìœ ì§€)
    if file_extensions:
        if isinstance(file_extensions, list):
            for ext in file_extensions:
                if not ext.startswith('.'):
                    ext = '.' + ext
                if not pattern.endswith('*' + ext):
                    pattern = pattern.rstrip('*') + '*' + ext
                break  # ì²« ë²ˆì§¸ í™•ì¥ìë§Œ ì‚¬ìš©
        else:
            ext = file_extensions if file_extensions.startswith('.') else '.' + file_extensions
            if not pattern.endswith('*' + ext):
                pattern = pattern.rstrip('*') + '*' + ext
    
    # ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
    result = _search_files_advanced(
        path=directory, 
        pattern=pattern, 
        recursive=recursive, 
        max_results=max_results, 
        include_dirs=include_dirs, 
        timeout_ms=timeout_ms
    )
    
    # ì‘ì—… ì¶”ì 
    try:
        track_file_access(directory, 'search_files')
    except:
        pass
        
    return result
def search_code_content(path: str = '.', pattern: str = '', 
                       file_pattern: str = '*', max_results: int = 50,
                       case_sensitive: bool = False, whole_word: bool = False):
    """ì½”ë“œ ë‚´ìš© ê²€ìƒ‰ (ì¶”ì  í¬í•¨) - ì›ë³¸ê³¼ ë™ì¼í•œ ì‹œê·¸ë‹ˆì²˜
    
    Args:
        path: ê²€ìƒ‰í•  ê²½ë¡œ
        pattern: ê²€ìƒ‰ íŒ¨í„´ (ì •ê·œì‹ ì§€ì›)
        file_pattern: íŒŒì¼ íŒ¨í„´ (ì˜ˆ: '*.py')
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        case_sensitive: ëŒ€ì†Œë¬¸ì êµ¬ë¶„
        whole_word: ë‹¨ì–´ ë‹¨ìœ„ ê²€ìƒ‰
    
    Returns:
        SearchHelper.search_code ê²°ê³¼
    """
    # ----- (1) ì¶”ì  -----
    track_file_access('search_code', path)
    
    # ----- (2) SearchHelper í˜¸ì¶œ -----
    # _search_code_contentëŠ” search_helpers.search_code_content
    result = _search_code_content(
        path=path,
        pattern=pattern,
        file_pattern=file_pattern,
        max_results=max_results,
        case_sensitive=case_sensitive,
        whole_word=whole_word
    )
    
    # ----- (3) ê²°ê³¼ì— ì¶”ì  ì •ë³´ ì¶”ê°€ -----
    if result and 'results' in result:
        for file_result in result['results']:
            if 'file_path' in file_result:
                track_file_access('search_code', file_result['file_path'])
    
    return result
globals()['parse_with_snippets'] = parse_with_snippets
globals()['get_snippet_preview'] = get_snippet_preview
globals()['scan_directory'] = _scan_directory
globals()['search_files_advanced'] = search_files_advanced
globals()['search_code_content'] = search_code_content
globals()['track_file_access'] = track_file_access

# ===== í´ë” êµ¬ì¡° ìºì‹± í•¨ìˆ˜ë“¤ =====

def cache_project_structure(root_path=".", ignore_patterns=None, force_rescan=False):
    """í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ìŠ¤ìº”í•˜ê³  ìºì‹œì— ì €ì¥
    
    Args:
        root_path: ìŠ¤ìº”í•  ë£¨íŠ¸ ê²½ë¡œ
        ignore_patterns: ë¬´ì‹œí•  íŒ¨í„´ ë¦¬ìŠ¤íŠ¸
        force_rescan: ê°•ì œ ì¬ìŠ¤ìº” ì—¬ë¶€
    
    Returns:
        dict: í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ë³´
    """
    import fnmatch
    from datetime import datetime
    from pathlib import Path
    
    # DEBUG: print("\nğŸ” DEBUG: cache_project_structure ì‹œì‘")
    print(f"   root_path: {root_path}")
    print(f"   ignore_patterns ì „ë‹¬ê°’: {ignore_patterns}")
    print(f"   force_rescan: {force_rescan}")
    
    # ê¸°ë³¸ ë¬´ì‹œ íŒ¨í„´
    # ê¸°ë³¸ ë¬´ì‹œ íŒ¨í„´ - ë” í¬ê´„ì ìœ¼ë¡œ ê°œì„ 
    if ignore_patterns is None:
        ignore_patterns = [
            # Python ê´€ë ¨
            "__pycache__", "*.pyc", "*.pyo", "*.pyd", ".Python",
            ".pytest_cache", ".mypy_cache", 
            
            # ê°€ìƒí™˜ê²½
            ".venv", "venv", "ENV", "env",
            
            # ë¹Œë“œ/ë°°í¬
            "dist", "build", "*.egg-info", "node_modules",
            
            # ë²„ì „ ê´€ë¦¬
            ".git", ".svn", ".hg",
            
            # IDE/ì—ë””í„°
            ".vscode", ".idea", "*.swp", "*.swo",
            
            # ë°±ì—…/ì„ì‹œ íŒŒì¼ - ì¤‘ìš”!
            "backup", "backups", "*.bak", "*.backup",
            ".mcp_backup_*", "backup_*", "backup_test_suite",
            
            # í…ŒìŠ¤íŠ¸ - ì¤‘ìš”!
            "test", "tests", "test_*", "*_test",
            
            # ìºì‹œ/ì„¸ì…˜ - ì¤‘ìš”!
            ".cache", ".ai_cache", "cache", ".sessions",
            "session_cache",
            
            # ë¡œê·¸
            "logs", "*.log",
            
            # ë°ì´í„°ë² ì´ìŠ¤
            "*.db", "*.sqlite*", "chroma_db",
            
            # ê¸°íƒ€
            ".vibe", "output", "tmp", "temp"
        ]
    
    # DEBUG: print(f"\nğŸ“‹ DEBUG: ë¬´ì‹œ íŒ¨í„´ ({len(ignore_patterns)}ê°œ):")
    for i, pattern in enumerate(ignore_patterns[:10]):
        print(f"   {i+1}. {pattern}")
    if len(ignore_patterns) > 10:
        print(f"   ... ì™¸ {len(ignore_patterns) - 10}ê°œ")
    
    # ìºì‹œ í™•ì¸
    cache_key = "project_structure"
    context = _get_project_context()
    
    if not force_rescan and context:
        if 'project_structure' in context:
            cached = context['project_structure']
        else:
            # _context_managerë¥¼ í†µí•´ì„œë„ í™•ì¸
            try:
                from core.context_manager import get_context_manager
                _context_manager = get_context_manager()
                if _context_manager and hasattr(_context_manager, 'get_value'):
                    cached = _context_manager.get_value(cache_key)
                else:
                    cached = None
            except:
                cached = None
        
        if cached:
            # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬ (24ì‹œê°„)
            try:
                last_scan = datetime.fromisoformat(cached['last_scan'])
                age_hours = (datetime.now() - last_scan).total_seconds() / 3600
                
                if age_hours < 24:
                    print(f"âœ… ìºì‹œëœ êµ¬ì¡° ì‚¬ìš© (ìŠ¤ìº” í›„ {age_hours:.1f}ì‹œê°„ ê²½ê³¼)")
                    return cached
            except:
                pass
    
    # ìƒˆë¡œ ìŠ¤ìº”
    print("ğŸ” í”„ë¡œì íŠ¸ êµ¬ì¡° ìŠ¤ìº” ì¤‘...")
    structure = {}
    total_files = 0
    total_dirs = 0
    
    def should_ignore(path):
        """ê²½ë¡œê°€ ë¬´ì‹œ íŒ¨í„´ì— ë§¤ì¹˜ë˜ëŠ”ì§€ í™•ì¸"""
        import fnmatch
        
        # ì²˜ìŒ 10ë²ˆë§Œ ë””ë²„ê¹…
        if not hasattr(should_ignore, 'call_count'):
            should_ignore.call_count = 0
        
        if should_ignore.call_count < 10:
            # DEBUG: print(f"\nğŸ” DEBUG: should_ignore í˜¸ì¶œ #{should_ignore.call_count + 1}")
            print(f"   path: {path}")
            should_ignore.call_count += 1
        path_str = str(path)
        path_parts = Path(path).parts
        path_name = Path(path).name
        
        # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œë§Œ ì¶œë ¥
        global debug_count
        if 'debug_count' not in globals():
            debug_count = 0
        
        for pattern in ignore_patterns:
            # ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ ì²˜ë¦¬
            if '*' in pattern or '?' in pattern:
                # íŒŒì¼ëª…ì— ëŒ€í•´ íŒ¨í„´ ë§¤ì¹­
                if fnmatch.fnmatch(path_name, pattern):
                    if debug_count < 5:
                        print(f"   ğŸš« Ignored (wildcard): {path_name} matches {pattern}")
                        debug_count += 1
                    return True
            else:
                # ì •í™•í•œ ë§¤ì¹­ (ë””ë ‰í† ë¦¬ ì´ë¦„ ë“±)
                if pattern in path_parts:
                    if debug_count < 5:
                        print(f"   ğŸš« Ignored (exact): {pattern} in {path_parts}")
                        debug_count += 1
                    return True
                # íŒŒì¼ëª… ë§¤ì¹­
                if path_name == pattern:
                    if debug_count < 5:
                        print(f"   ğŸš« Ignored (name): {path_name} == {pattern}")
                        debug_count += 1
                    return True
        
        return False
    def scan_recursive(dir_path, relative_path="/"):
        """ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ìŠ¤ìº”"""
        nonlocal total_files, total_dirs
        
        if should_ignore(dir_path):
            return
        
        try:
            items = os.listdir(dir_path)
            dirs = []
            files = []
            
            for item in items:
                item_path = os.path.join(dir_path, item)
                if os.path.isdir(item_path):
                    if not should_ignore(item_path):
                        dirs.append(item)
                        total_dirs += 1
                else:
                    if not should_ignore(item_path):
                        files.append(item)
                        total_files += 1
            
            # í˜„ì¬ ë””ë ‰í† ë¦¬ ì •ë³´ ì €ì¥
            structure[relative_path] = {
                "type": "directory",
                "children": sorted(dirs),
                "files": sorted(files),
                "file_count": len(files),
                "dir_count": len(dirs),
                "last_modified": os.path.getmtime(dir_path)
            }
            
            # í•˜ìœ„ ë””ë ‰í† ë¦¬ ìŠ¤ìº”
            for dir_name in dirs:
                sub_dir_path = os.path.join(dir_path, dir_name)
                sub_relative_path = os.path.join(relative_path, dir_name).replace("\\", "/")
                scan_recursive(sub_dir_path, sub_relative_path)
                
        except PermissionError:
            structure[relative_path] = {
                "type": "directory",
                "error": "Permission denied"
            }
    
    # ìŠ¤ìº” ì‹œì‘
    root_abs = os.path.abspath(root_path)
    scan_recursive(root_abs, "/")
    
    result = {
        "root": root_abs,
        "last_scan": datetime.now().isoformat(),
        "total_files": total_files,
        "total_dirs": total_dirs,
        "structure": structure
    }
    
    # ìºì‹œì— ì €ì¥
    if context:
        context['project_structure'] = result
        
        # _context_managerë¥¼ í†µí•´ì„œë„ ì €ì¥
        try:
            from core.context_manager import get_context_manager
            _context_manager = get_context_manager()
            if _context_manager and hasattr(_context_manager, 'update_cache'):
                _context_manager.update_cache(cache_key, result)
        except:
            pass
        
        print(f"ğŸ’¾ êµ¬ì¡° ìºì‹œ ì €ì¥ ì™„ë£Œ ({total_files}ê°œ íŒŒì¼, {total_dirs}ê°œ ë””ë ‰í† ë¦¬)")
    
    return result


def get_project_structure(force_rescan=False):
    """ìºì‹œëœ í”„ë¡œì íŠ¸ êµ¬ì¡° ë°˜í™˜ (í•„ìš”ì‹œ ìë™ ìŠ¤ìº”)
    
    Args:
        force_rescan: ê°•ì œ ì¬ìŠ¤ìº” ì—¬ë¶€
    
    Returns:
        dict: í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ë³´
    """
    return cache_project_structure(force_rescan=force_rescan)


def search_in_structure(pattern, search_type="all"):
    """ìºì‹œëœ êµ¬ì¡°ì—ì„œ íŒŒì¼/ë””ë ‰í† ë¦¬ ê²€ìƒ‰
    
    Args:
        pattern: ê²€ìƒ‰ íŒ¨í„´ (glob í˜•ì‹)
        search_type: "file", "dir", "all"
    
    Returns:
        list: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    import fnmatch
    
    # ìºì‹œëœ êµ¬ì¡° ê°€ì ¸ì˜¤ê¸°
    structure = get_project_structure()
    
    results = []
    
    for path, info in structure['structure'].items():
        if info.get('error'):
            continue
            
        # ë””ë ‰í† ë¦¬ ê²€ìƒ‰
        if search_type in ["dir", "all"] and info['type'] == 'directory':
            dir_name = os.path.basename(path.rstrip('/'))
            if dir_name and fnmatch.fnmatch(dir_name, pattern):
                results.append({
                    'type': 'directory',
                    'path': path,
                    'name': dir_name,
                    'file_count': info.get('file_count', 0),
                    'dir_count': info.get('dir_count', 0)
                })
        
        # íŒŒì¼ ê²€ìƒ‰
        if search_type in ["file", "all"] and 'files' in info:
            for file_name in info['files']:
                if fnmatch.fnmatch(file_name, pattern):
                    file_path = os.path.join(path, file_name).replace("\\", "/")
                    results.append({
                        'type': 'file',
                        'path': file_path,
                        'name': file_name,
                        'parent': path
                    })
    
    return results


def get_directory_tree(path="/", max_depth=3, show_files=True):
    """ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    
    Args:
        path: ì‹œì‘ ê²½ë¡œ
        max_depth: ìµœëŒ€ ê¹Šì´
        show_files: íŒŒì¼ í‘œì‹œ ì—¬ë¶€
    
    Returns:
        str: íŠ¸ë¦¬ í˜•íƒœì˜ í…ìŠ¤íŠ¸
    """
    structure = get_project_structure()
    
    def build_tree(current_path, depth=0, prefix=""):
        if depth > max_depth:
            return ""
        
        tree = ""
        if current_path not in structure['structure']:
            return tree
            
        info = structure['structure'][current_path]
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ í•˜ìœ„ í•­ëª©ë“¤
        children = info.get('children', [])
        files = info.get('files', []) if show_files else []
        
        # ë””ë ‰í† ë¦¬ ì¶œë ¥
        for i, child in enumerate(children):
            is_last_dir = (i == len(children) - 1 and len(files) == 0)
            child_path = os.path.join(current_path, child).replace("\\", "/")
            
            connector = "â””â”€â”€ " if is_last_dir else "â”œâ”€â”€ "
            tree += f"{prefix}{connector}{child}/\n"
            
            # ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ ë””ë ‰í† ë¦¬ ì²˜ë¦¬
            extension = "    " if is_last_dir else "â”‚   "
            tree += build_tree(child_path, depth + 1, prefix + extension)
        
        # íŒŒì¼ ì¶œë ¥ (ìµœëŒ€ 5ê°œë§Œ)
        if show_files:
            for i, file in enumerate(files[:5]):
                is_last = (i == len(files) - 1) or (i == 4)
                connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                tree += f"{prefix}{connector}{file}\n"
            
            if len(files) > 5:
                tree += f"{prefix}â””â”€â”€ ... ({len(files) - 5}ê°œ íŒŒì¼ ë”)\n"
        
        return tree
    
    # ë£¨íŠ¸ì—ì„œ ì‹œì‘
    if path == "/":
        tree = "ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°\n"
    else:
        tree = f"ğŸ“ {path}\n"
    
    tree += build_tree(path, 0, "")
    return tree


def get_structure_stats():
    """í”„ë¡œì íŠ¸ êµ¬ì¡° í†µê³„ ì •ë³´ ë°˜í™˜
    
    Returns:
        dict: íŒŒì¼ íƒ€ì…ë³„ í†µê³„, ë””ë ‰í† ë¦¬ ê¹Šì´ ë“±
    """
    from collections import defaultdict
    
    structure = get_project_structure()
    
    # í†µê³„ ì´ˆê¸°í™”
    stats = {
        'total_files': structure['total_files'],
        'total_dirs': structure['total_dirs'],
        'file_types': defaultdict(int),
        'max_depth': 0,
        'largest_dirs': []
    }
    
    # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
    for path, info in structure['structure'].items():
        if 'files' in info:
            for file_name in info['files']:
                ext = os.path.splitext(file_name)[1].lower()
                if ext:
                    stats['file_types'][ext] += 1
                else:
                    stats['file_types']['[no extension]'] += 1
            
            # ê°€ì¥ í° ë””ë ‰í† ë¦¬ë“¤
            if info['file_count'] > 0:
                stats['largest_dirs'].append({
                    'path': path,
                    'file_count': info['file_count']
                })
        
        # ìµœëŒ€ ê¹Šì´ ê³„ì‚°
        depth = path.count('/')
        if depth > stats['max_depth']:
            stats['max_depth'] = depth
    
    # ê°€ì¥ í° ë””ë ‰í† ë¦¬ ì •ë ¬
    stats['largest_dirs'].sort(key=lambda x: x['file_count'], reverse=True)
    stats['largest_dirs'] = stats['largest_dirs'][:10]  # ìƒìœ„ 10ê°œë§Œ
    
    # file_typesë¥¼ ì¼ë°˜ dictë¡œ ë³€í™˜
    stats['file_types'] = dict(stats['file_types'])
    
    return stats

# ìƒˆë¡œìš´ í•¨ìˆ˜ë“¤ì„ ì „ì—­ì— ë“±ë¡
globals()['cache_project_structure'] = cache_project_structure
globals()['get_project_structure'] = get_project_structure
globals()['search_in_structure'] = search_in_structure
globals()['get_directory_tree'] = get_directory_tree
globals()['get_structure_stats'] = get_structure_stats


def force_save_context():
    """íŠ¹ì • ëª…ë ¹ì–´(/next ë“±)ì—ì„œ ì¦‰ì‹œ ìºì‹œë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    global _operation_counter
    import claude_code_ai_brain
    if hasattr(claude_code_ai_brain, '_context_manager') and claude_code_ai_brain._context_manager:
        try:
            claude_code_ai_brain.save_context()
            print("âœ… ì»¨í…ìŠ¤íŠ¸ ì¦‰ì‹œ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("âš ï¸ ContextManagerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def _auto_git_commit(operation_type: str, file_path: str, context: Optional[Dict] = None):
    """Git ìë™ ì»¤ë°‹ ìˆ˜í–‰"""
    if not GIT_AVAILABLE:
        return
    
    # ì œì™¸í•  íŒŒì¼ íƒ€ì…
    exclude_patterns = ['.log', '.tmp', '.cache', '__pycache__', '.pyc']
    if any(pattern in file_path for pattern in exclude_patterns):
        return
    
    # ì¤‘ìš”í•œ ì‘ì—…ë§Œ ìë™ ì»¤ë°‹
    commit_operations = ['create', 'write', 'modify', 'replace', 'backup']
    if operation_type not in commit_operations:
        return
    
    try:
        git_manager = get_git_manager()
        
        # í˜„ì¬ ìƒíƒœ í™•ì¸
        status = git_manager.git_status()
        if status['clean']:
            return  # ë³€ê²½ì‚¬í•­ ì—†ìŒ
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        task_info = ""
        if context and context.get('current_task'):
            task_info = f"[{context['current_task']}] "
        
        # ìë™ ì»¤ë°‹ ë©”ì‹œì§€
        file_name = os.path.basename(file_path)
        message = f"{task_info}Auto: {operation_type} {file_name}"
        
        # ì»¤ë°‹ ì‹¤í–‰
        result = git_manager.git_commit_smart(message, auto_add=True)
        
        if result['success'] and os.environ.get('DEBUG_GIT', '').lower() == 'true':
            print(f"ğŸ”„ Git ìë™ ì»¤ë°‹: {result['commit_hash'][:8]}")
            
    except Exception as e:
        if os.environ.get('DEBUG_GIT', '').lower() == 'true':
            print(f"âš ï¸ Git ìë™ ì»¤ë°‹ ì‹¤íŒ¨: {e}")


# ìë™ ì»¤ë°‹ ê´€ë ¨ ì„¤ì •
_git_commit_counter = 0
_git_commit_interval = 5  # 5íšŒ ì‘ì—…ë§ˆë‹¤ ìë™ ì»¤ë°‹
_operation_counter = 0  # ì¹´ìš´í„° ë¦¬ì…‹
