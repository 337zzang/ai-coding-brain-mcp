# ===========================================
# Public API - Only these 8 functions are exposed
# ===========================================
__all__ = [
    'initialize_context',      # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    'save_context',           # ì»¨í…ìŠ¤íŠ¸ ì €ì¥
    'update_cache',           # ìºì‹œ ì—…ë°ì´íŠ¸
    'get_value',              # ìºì‹œ ê°’ ì¡°íšŒ
    'find_symbol',            # ì‹¬ë³¼ ì°¾ê¸°
    'track_file_access',      # íŒŒì¼ ì ‘ê·¼ ì¶”ì 
    'track_function_edit',    # í•¨ìˆ˜ ìˆ˜ì • ì¶”ì 
    'get_work_tracking_summary' # ì‘ì—… ì¶”ì  ìš”ì•½
]

"""
ğŸ§  ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì v2.0 - ë©”ëª¨ë¦¬ ë±…í¬ ê¸°ë°˜ êµ¬ì¡°
==========================================

project_contextì˜ ìƒì„±, ê´€ë¦¬, ì ‘ê·¼ì„ ì „ë‹´í•˜ëŠ” ëª¨ë“ˆ.
ë©”ëª¨ë¦¬ ë±…í¬ ê¸°ë°˜ êµ¬ì¡°: ì½”ë“œì™€ ë°ì´í„° ë¶„ë¦¬

v2.0 ë³€ê²½ì‚¬í•­:
- vibe_memory_systemê³¼ í†µí•© ê°œì„ 
- í´ë˜ìŠ¤ ê¸°ë°˜ êµ¬ì¡°ë¡œ ë¦¬íŒ©í† ë§
- ì¤‘ë³µ ì½”ë“œ ì œê±° ë° êµ¬ì¡° ì •ë¦¬
"""

import os
import json
import datetime as dt
from datetime import datetime
from typing import Dict, Any, Optional, List
import sys

# Vibe Memory System ë™ì  import
try:
    import vibe_memory_system
    VIBE_MEMORY_AVAILABLE = True
except ImportError:
    VIBE_MEMORY_AVAILABLE = False
    print("âš ï¸ Vibe Memory Systemì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ===========================================
# Helper Functions (Private)
# ===========================================

def _ensure_cache_structure(context: dict) -> dict:
    """ìºì‹œ êµ¬ì¡° í™•ì¸ ë° ì´ˆê¸°í™”"""
    if 'cache' not in context:
        context['cache'] = {
            'files': {},
            'analyzed_files': {},
            'symbol_index': {},
            'file_summaries': {},
            'work_tracking': {},
            'vibe_synced': {},
            'last_sync': None
        }
    
    if 'stats' not in context:
        context['stats'] = {
            'total_operations': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'files_analyzed': 0,
            'cache_evictions': 0
        }
    
    return context

def _calculate_session_duration(tracking: dict) -> str:
    """ì„¸ì…˜ ì§€ì† ì‹œê°„ ê³„ì‚°"""
    if 'session_start' in tracking:
        try:
            start = dt.datetime.fromisoformat(tracking['session_start'])
            duration = dt.datetime.now() - start
            return str(duration).split('.')[0]  # ë§ˆì´í¬ë¡œì´ˆ ì œê±°
        except:
            pass
    return "Unknown"

def _normalize_context_structure(context: dict) -> dict:
    """Context êµ¬ì¡°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì¼ê´€ëœ ì ‘ê·¼ ë³´ì¥"""
    # cache_dataê°€ ì¤‘ì²©ë˜ì–´ ìˆìœ¼ë©´ í‰íƒ„í™”
    if 'cache_data' in context and isinstance(context['cache_data'], dict):
        cache_data = context['cache_data']
        
        # ì£¼ìš” í•„ë“œë“¤ì„ ìµœìƒìœ„ë¡œ ë³µì‚¬ (ë®ì–´ì“°ì§€ ì•ŠìŒ)
        for key in ['analyzed_files', 'symbol_index', 'work_tracking', 
                    'current_focus', 'tasks', 'active_file']:
            if key in cache_data and key not in context:
                context[key] = cache_data[key]
    
    # í•„ìˆ˜ í•„ë“œ ì´ˆê¸°í™”
    context.setdefault('analyzed_files', {})
    context.setdefault('symbol_index', {})
    context.setdefault('work_tracking', {})
    context.setdefault('tasks', {'next': [], 'done': []})
    
    return context

def _validate_memory_bank_structure(memory_dir: str) -> List[str]:
    """ë©”ëª¨ë¦¬ë±…í¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° ê²€ì¦ ë° ìˆ˜ì •"""
    issues_fixed = []
    
    # .cache ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„±
    cache_dir = os.path.join(memory_dir, '.cache')
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir, exist_ok=True)
        issues_fixed.append('Created .cache directory')
    
    # ë ˆê±°ì‹œ ìºì‹œ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
    project_name = os.path.basename(memory_dir)
    cache_filename = f'cache_{project_name}.json'
    
    old_cache = os.path.join(memory_dir, cache_filename)
    new_cache = os.path.join(cache_dir, cache_filename)
    
    if os.path.exists(old_cache) and not os.path.exists(new_cache):
        import shutil
        shutil.move(old_cache, new_cache)
        issues_fixed.append(f'Migrated {cache_filename} to .cache/')
    
    return issues_fixed

def _try_load_cached_context(project_path: str, project_name: str) -> Optional[dict]:
    """ìºì‹œëœ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì‹œë„"""
    # .cache ë””ë ‰í† ë¦¬ ê²½ë¡œ
    cache_dir = os.path.join(project_path, '.cache')
    cache_filename = f'cache_{project_name}.json'
    
    # ìš°ì„ ìˆœìœ„: .cache/ > í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ë ˆê±°ì‹œ)
    cache_file = os.path.join(cache_dir, cache_filename)
    legacy_cache_file = os.path.join(project_path, cache_filename)
    
    # ë ˆê±°ì‹œ ìºì‹œ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
    if not os.path.exists(cache_file) and os.path.exists(legacy_cache_file):
        print(f"ğŸ”„ ë ˆê±°ì‹œ ìºì‹œ íŒŒì¼ ë°œê²¬, .cache/ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜")
        os.makedirs(cache_dir, exist_ok=True)
        import shutil
        shutil.copy2(legacy_cache_file, cache_file)
    
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            print(f"âœ… ìºì‹œ ë¡œë“œ ì„±ê³µ: .cache/{cache_filename}")
            
            # ìºì‹œ ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° í‰íƒ„í™”
            result = {}
            
            # ì¤‘ì²©ëœ êµ¬ì¡° ì²˜ë¦¬
            if 'cache' in cache_data:
                cache_inner = cache_data.get('cache', {})
                result['symbol_index'] = cache_inner.get('symbol_index', {})
                result['analyzed_files'] = cache_inner.get('analyzed_files', {})
                result['work_tracking'] = cache_inner.get('work_tracking', {})
            
            # ìµœìƒìœ„ ë ˆë²¨ ë°ì´í„° ë³‘í•©
            for key in ['symbol_index', 'analyzed_files', 'work_tracking', 'tasks', 
                       'current_focus', 'modification_log', 'project_insights']:
                if key in cache_data and key not in result:
                    result[key] = cache_data[key]
            
            # ê¸°íƒ€ ë©”íƒ€ë°ì´í„°
            result['project_id'] = cache_data.get('project_id', project_name)
            result['project_path'] = cache_data.get('project_path', project_path)
            result['cache_dir'] = cache_dir
            
            # í†µê³„ ì¶œë ¥
            print(f"   â€¢ symbol_index: {len(result.get('symbol_index', {}))}ê°œ")
            print(f"   â€¢ analyzed_files: {len(result.get('analyzed_files', {}))}ê°œ")
            print(f"   â€¢ work_tracking: {len(result.get('work_tracking', {}))}ê°œ")
            
            return result
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    else:
        print(f"â„¹ï¸ ìºì‹œ íŒŒì¼ ì—†ìŒ: .cache/{cache_filename}")
        os.makedirs(cache_dir, exist_ok=True)
        return None

# ===========================================
# CacheManager í´ë˜ìŠ¤
# ===========================================

class CacheManager:
    """ìºì‹œ ê´€ë¦¬ ì „ë‹´ í´ë˜ìŠ¤"""
    
    def __init__(self, context: dict):
        self.context = _ensure_cache_structure(context)
        self.cache = self.context['cache']
        self.stats = self.context['stats']
        
        # ìºì‹œ ì„¤ì •
        self.cache_config = {
            'max_size': 20,
            'mtime_check': True,
            'auto_save': True
        }
        self.cache['cache_config'] = self.cache_config
    
    def update(self, key: str, value: Any) -> bool:
        """ìºì‹œ ì—…ë°ì´íŠ¸"""
        self.cache[key] = value
        self.stats['total_operations'] += 1
        
        # íŠ¹ì • í‚¤ì— ëŒ€í•œ ì¶”ê°€ ì²˜ë¦¬
        if key == 'active_file':
            print(f"âœ… í™œì„± íŒŒì¼ ë³€ê²½: {value}")
        
        # Vibe ë™ê¸°í™” (VIBE_MEMORY_AVAILABLE ì²´í¬)
        if VIBE_MEMORY_AVAILABLE:
            important_keys = ['current_focus', 'active_file', 'analyzed_files', 'symbol_index']
            if key in important_keys:
                try:
                    # vibe_memory_systemì˜ auto_save í˜¸ì¶œ
                    vibe_memory_system.auto_save()
                except Exception as e:
                    print(f"âš ï¸ Vibe ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        
        return True
    
    def get(self, key: str, default: Any = None) -> Any:
        """ìºì‹œì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°"""
        value = self.cache.get(key, default)
        
        if value != default:
            self.stats['cache_hits'] += 1
        else:
            self.stats['cache_misses'] += 1
        
        return value
    
    def validate_entry(self, file_path: str) -> bool:
        """ìºì‹œ ì—”íŠ¸ë¦¬ ìœ íš¨ì„± ê²€ì¦"""
        analyzed_files = self.cache.get('analyzed_files', {})
        
        if file_path not in analyzed_files:
            return False
        
        # mtime ê²€ì‚¬ê°€ ë¹„í™œì„±í™”ëœ ê²½ìš°
        if not self.cache_config.get('mtime_check', True):
            return True
        
        cached_entry = analyzed_files[file_path]
        cached_mtime = cached_entry.get('mtime', 0)
        
        try:
            current_mtime = os.path.getmtime(file_path)
            if current_mtime > cached_mtime:
                print(f"âš ï¸ íŒŒì¼ ë³€ê²½ ê°ì§€: {os.path.basename(file_path)}")
                return False
        except Exception as e:
            print(f"âš ï¸ mtime í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
        
        return True
    
    def update_file_cache(self, file_path: str, analysis_data: dict) -> None:
        """íŒŒì¼ ìºì‹œ ì—…ë°ì´íŠ¸"""
        analyzed_files = self.cache.get('analyzed_files', {})
        
        try:
            mtime = os.path.getmtime(file_path)
            
            # ìºì‹œ ì—”íŠ¸ë¦¬ ìƒì„±
            cache_entry = {
                'data': analysis_data,
                'mtime': mtime,
                'access_time': datetime.now().timestamp(),
                'file_size': os.path.getsize(file_path),
                'cached_at': datetime.now().isoformat()
            }
            
            analyzed_files[file_path] = cache_entry
            self.stats['files_analyzed'] += 1
            
            print(f"âœ… ìºì‹œ ì—…ë°ì´íŠ¸: {os.path.basename(file_path)}")
            
            # LRU ìºì‹œ í¬ê¸° ê´€ë¦¬
            self._manage_cache_size()
            
            # symbol_index ì—…ë°ì´íŠ¸
            self._update_symbol_index(file_path, analysis_data)
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _update_symbol_index(self, file_path: str, analysis_data: dict) -> None:
        """ì‹¬ë³¼ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸"""
        if 'symbol_index' not in self.cache:
            self.cache['symbol_index'] = {}
        
        symbol_index = self.cache['symbol_index']
        language = analysis_data.get('language', 'python')
        
        # í•¨ìˆ˜ ì •ë³´ ì¶”ê°€
        for func in analysis_data.get('functions', []):
            func_key = f"{os.path.basename(file_path)}:{func}"
            symbol_index[func_key] = {
                'file': file_path,
                'type': 'function',
                'name': func,
                'language': language
            }
        
        # í´ë˜ìŠ¤ ì •ë³´ ì¶”ê°€
        for cls in analysis_data.get('classes', []):
            class_key = f"{os.path.basename(file_path)}:{cls}"
            symbol_index[class_key] = {
                'file': file_path,
                'type': 'class',
                'name': cls,
                'language': language
            }
    
    def _manage_cache_size(self) -> None:
        """LRU ì •ì±…ìœ¼ë¡œ ìºì‹œ í¬ê¸° ê´€ë¦¬"""
        analyzed_files = self.cache.get('analyzed_files', {})
        max_size = self.cache_config.get('max_size', 20)
        
        current_size = len(analyzed_files)
        if current_size <= max_size:
            return
        
        # access_time ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_files = sorted(
            analyzed_files.items(),
            key=lambda x: x[1].get('access_time', 0)
        )
        
        # ì œê±°í•  í•­ëª© ìˆ˜
        to_remove = current_size - max_size
        
        print(f"âš ï¸ ìºì‹œ í¬ê¸° ì´ˆê³¼: {current_size}/{max_size}")
        
        # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ ì œê±°
        for file_path, _ in sorted_files[:to_remove]:
            del analyzed_files[file_path]
            self.stats['cache_evictions'] += 1
            print(f"  ğŸ—‘ï¸ LRU ì œê±°: {os.path.basename(file_path)}")

# ===========================================
# WorkTracker í´ë˜ìŠ¤
# ===========================================

class WorkTracker:
    """ì‘ì—… ì¶”ì  ì „ë‹´ í´ë˜ìŠ¤"""
    
    def __init__(self, context: dict):
        self.context = context
        self._initialize()
    
    def _initialize(self) -> None:
        """ì‘ì—… ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        if 'cache' not in self.context:
            self.context['cache'] = {}
        
        if 'work_tracking' not in self.context['cache']:
            self.context['cache']['work_tracking'] = {
                'current_file': None,
                'current_function': None,
                'current_class': None,
                'last_accessed': None,
                'work_history': [],
                'file_access_count': {},
                'function_edit_count': {},
                'session_start': datetime.now().isoformat()
            }
    
    def track_file_access(self, file_path: str, operation: str = 'read') -> dict:
        """íŒŒì¼ ì ‘ê·¼ ì¶”ì """
        self._initialize()
        tracking = self.context['cache']['work_tracking']
        
        # í˜„ì¬ íŒŒì¼ ì—…ë°ì´íŠ¸
        tracking['current_file'] = file_path
        tracking['last_accessed'] = datetime.now().isoformat()
        
        # íŒŒì¼ ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€
        if file_path not in tracking['file_access_count']:
            tracking['file_access_count'][file_path] = 0
        tracking['file_access_count'][file_path] += 1
        
        # ì‘ì—… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        history_entry = {
            'timestamp': datetime.now().isoformat(),
            'file': file_path,
            'operation': operation,
            'function': tracking.get('current_function'),
            'class': tracking.get('current_class')
        }
        
        tracking['work_history'].append(history_entry)
        
        # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
        if len(tracking['work_history']) > 100:
            tracking['work_history'] = tracking['work_history'][-100:]
        
        # Vibe ë™ê¸°í™”
        if VIBE_MEMORY_AVAILABLE and tracking['file_access_count'][file_path] % 3 == 0:
            self._sync_to_vibe()
        
        return self.context
    
    def track_function_edit(self, file_path: str, function_name: str, 
                           class_name: Optional[str] = None, operation: str = 'edit') -> dict:
        """í•¨ìˆ˜/ë©”ì„œë“œ ìˆ˜ì • ì¶”ì """
        self._initialize()
        tracking = self.context['cache']['work_tracking']
        
        # í˜„ì¬ ì‘ì—… ì¤‘ì¸ í•¨ìˆ˜/í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸
        tracking['current_function'] = function_name
        tracking['current_class'] = class_name
        
        # í•¨ìˆ˜ ìˆ˜ì • íšŸìˆ˜ ì¶”ì 
        function_key = f"{file_path}::{class_name or ''}.{function_name}"
        if function_key not in tracking['function_edit_count']:
            tracking['function_edit_count'][function_key] = 0
        tracking['function_edit_count'][function_key] += 1
        
        # íŒŒì¼ ì ‘ê·¼ë„ í•¨ê»˜ ì¶”ì 
        self.track_file_access(file_path, operation)
        
        # Vibe ì¦‰ì‹œ ë™ê¸°í™”
        if VIBE_MEMORY_AVAILABLE:
            self._sync_to_vibe()
        
        return self.context
    
    def get_summary(self) -> dict:
        """ì‘ì—… ì¶”ì  ìš”ì•½ ì •ë³´"""
        self._initialize()
        tracking = self.context['cache']['work_tracking']
        
        # ê°€ì¥ ë§ì´ ì ‘ê·¼í•œ íŒŒì¼
        file_counts = tracking.get('file_access_count', {})
        sorted_files = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)
        most_accessed_files = [(f, {'access_count': c}) for f, c in sorted_files[:5]]
        
        # ê°€ì¥ ë§ì´ ìˆ˜ì •í•œ í•¨ìˆ˜
        function_counts = tracking.get('function_edit_count', {})
        sorted_functions = sorted(function_counts.items(), key=lambda x: x[1], reverse=True)
        most_edited_functions = [(f, c) for f, c in sorted_functions[:10]]
        
        return {
            'current_context': self._get_current_context(),
            'most_accessed_files': most_accessed_files,
            'most_edited_functions': most_edited_functions,
            'recent_history': tracking.get('work_history', [])[-5:],
            'total_files_accessed': len(file_counts),
            'total_functions_edited': len(function_counts),
            'total_operations': len(tracking.get('work_history', []))
        }
    
    def _get_current_context(self) -> dict:
        """í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸"""
        tracking = self.context['cache']['work_tracking']
        
        return {
            'current_file': tracking.get('current_file'),
            'current_function': tracking.get('current_function'),
            'current_class': tracking.get('current_class'),
            'last_accessed': tracking.get('last_accessed'),
            'session_duration': _calculate_session_duration(tracking)
        }
    
    def _sync_to_vibe(self) -> None:
        """Vibe Memoryë¡œ ë™ê¸°í™”"""
        if not VIBE_MEMORY_AVAILABLE:
            return
        
        try:
            # vibe_memory_systemì˜ auto_save í˜¸ì¶œ
            vibe_memory_system.auto_save()
        except Exception as e:
            print(f"âš ï¸ WorkTracker Vibe ë™ê¸°í™” ì‹¤íŒ¨: {e}")

# ===========================================
# ContextManager í´ë˜ìŠ¤
# ===========================================


    def _generate_coding_flow_content(self) -> str:
        """coding_flow.md ë‚´ìš© ìƒì„±"""
        from datetime import datetime
        
        content = f"""# ğŸ”¥ Current Focus
*ì§€ê¸ˆ ë­í•˜ê³  ìˆëŠ”ì§€*

í˜„ì¬ ì„¸ì…˜ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M')}
**í˜„ì¬ Focus**: {self.context.get('current_focus', 'Not set')}

## â­ï¸ Next Up (1-3 items)
*ë°”ë¡œ ë‹¤ìŒì— í•  ì¼ë“¤*

"""
        # Next tasks
        tasks = self.context.get('tasks', {})
        for task in tasks.get('next', [])[:3]:
            content += f"- [ ] {task}\n"
        
        content += "\n\n## âœ… Done (Recent)\n*ìµœê·¼ ì™„ë£Œí•œ ê²ƒë“¤*\n\n"
        
        # Done tasks
        for task in tasks.get('done', [])[-5:]:
            content += f"- [x] {task}\n"
        
        # Progress
        done_count = len(tasks.get('done', []))
        total_count = done_count + len(tasks.get('next', []))
        progress = (done_count / total_count * 100) if total_count > 0 else 0
        
        content += f"\n\n## ğŸ“Š Progress\nì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({done_count}/{total_count})\n"
        
        return content

class ContextManager:
    """í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ í•µì‹¬ í´ë˜ìŠ¤"""
    
    def __init__(self, project_path: str, project_name: str):
        self.project_path = project_path
        self.project_name = project_name
        self.context = self._initialize_context()
        self.cache_manager = CacheManager(self.context)
        self.work_tracker = WorkTracker(self.context)
    
    def _initialize_context(self) -> dict:
        """í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”"""
        # ê¸°ë³¸ êµ¬ì¡°
        context = {
            'project_id': self.project_name,
            'project_name': self.project_name,
            'project_path': self.project_path,
            'version': 'context_manager_v2.0',
            'created_at': datetime.now().isoformat(),
            'session_id': None,
            
            # í•µì‹¬ ë°ì´í„° êµ¬ì¡°
            'analyzed_files': {},
            'symbol_index': {},
            'work_tracking': {},
            'tasks': {'next': [], 'done': []},
            'current_focus': None,
            'modification_log': [],
            'project_insights': {},
            
            # ìºì‹œ ê´€ë ¨
            'cache': {
                'active_file': None,
                'current_focus': None,
                'last_result': None,
                'error_count': 0
            },
            
            # í†µê³„
            'stats': {
                'total_operations': 0,
                'cache_hits': 0,
                'cache_misses': 0,
                'files_analyzed': 0
            }
        }
        
        # Vibe Memory í†µí•©
        if VIBE_MEMORY_AVAILABLE:
            try:
                memory_root = vibe_memory_system.__get_memory_bank_root_from_claude_config()
                context['memory_path'] = os.path.join(memory_root, self.project_name)
                
                # ë©”ëª¨ë¦¬ë±…í¬ êµ¬ì¡° ê²€ì¦
                issues_fixed = _validate_memory_bank_structure(context['memory_path'])
                if issues_fixed:
                    print(f"âœ… ë©”ëª¨ë¦¬ë±…í¬ êµ¬ì¡° ìˆ˜ì •: {', '.join(issues_fixed)}")
                
                # Vibe ë°ì´í„° í˜¸í™˜ì„± ë³´ì¥
                vibe_memory_system._ensure_data_compatibility(context)
                
            except Exception as e:
                print(f"âš ï¸ Vibe Memory í†µí•© ì‹¤íŒ¨: {e}")
        
        # ìºì‹œ ë¡œë“œ ì‹œë„
        cached_data = _try_load_cached_context(self.project_path, self.project_name)
        if cached_data:
            # ìºì‹œ ë°ì´í„° ë³‘í•©
            for key in ['analyzed_files', 'symbol_index', 'work_tracking', 'tasks', 
                       'current_focus', 'modification_log', 'project_insights']:
                if key in cached_data and cached_data[key]:
                    context[key] = cached_data[key]
        
        # ì„¸ì…˜ ID ìƒì„±
        import uuid
        context['session_id'] = str(uuid.uuid4())
        
        # ë™ê¸°í™” ì„¤ì •
        context['sync_status'] = {
            'realtime_enabled': True,
            'auto_sync': True,
            'last_sync': datetime.now().isoformat()
        }
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        cache_dir = os.path.join(self.project_path, '.cache')
        os.makedirs(cache_dir, exist_ok=True)
        
        context['memory_bank'] = {
            'project_path': cache_dir,
            'cache_file': os.path.join(cache_dir, f'cache_{self.project_name}.json')
        }
        
        # ê¸€ë¡œë²Œ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
        globals()['project_context'] = context
        
        print(f"\nğŸ“Š ì´ˆê¸°í™” ì™„ë£Œ:")
        print(f"   â€¢ í”„ë¡œì íŠ¸: {context['project_name']}")
        print(f"   â€¢ ë¶„ì„ëœ íŒŒì¼: {len(context.get('analyzed_files', {}))}ê°œ")
        print(f"   â€¢ ì‹¬ë³¼ ì¸ë±ìŠ¤: {len(context.get('symbol_index', {}))}ê°œ")
        print(f"   â€¢ í˜„ì¬ í¬ì»¤ìŠ¤: {context.get('current_focus', 'None')}")
        
        return context
    
    def save(self) -> bool:
        """ì»¨í…ìŠ¤íŠ¸ ì €ì¥"""
        cache_dir = self.context['memory_bank']['project_path']
        cache_file = self.context['memory_bank']['cache_file']
        
        # ì €ì¥í•  ë°ì´í„° êµ¬ì„±
        cache_data = {
            'project_id': self.context['project_id'],
            'project_name': self.context['project_name'],
            'project_path': self.context['project_path'],
            'analyzed_files': self.context.get('analyzed_files', {}),
            'symbol_index': self.context.get('symbol_index', {}),
            'work_tracking': self.context.get('work_tracking', {}),
            'tasks': self.context.get('tasks', {'next': [], 'done': []}),
            'current_focus': self.context.get('current_focus'),
            'modification_log': self.context.get('modification_log', []),
            'project_insights': self.context.get('project_insights', {}),
            'last_updated': datetime.now().isoformat(),
            'sync_status': self.context.get('sync_status', {}),
            'memory_bank': self.context.get('memory_bank', {})
        }
        
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… í”„ë¡œì íŠ¸ ìºì‹œ ì €ì¥: {os.path.basename(cache_file)}")
            
            # Vibe ë™ê¸°í™”
            if VIBE_MEMORY_AVAILABLE:
                try:
                    vibe_memory_system.sync_to_files()
                except Exception as e:
                    print(f"âš ï¸ Vibe ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            
            
            # ë¬¸ì„œ ìë™ ì €ì¥ ì¶”ê°€
            try:
                memory_path = r"C:\Users\82106\Desktop\memory\ai-coding-brain-mcp"
                
                if os.path.exists(memory_path):
                    # coding_flow.md ì—…ë°ì´íŠ¸
                    flow_content = self._generate_coding_flow_content()
                    flow_path = os.path.join(memory_path, 'coding_flow.md')
                    
                    with open(flow_path, 'w', encoding='utf-8') as f:
                        f.write(flow_content)
                    
                    print("   âœ… coding_flow.md ìë™ ì—…ë°ì´íŠ¸ë¨")
                    
            except Exception as e:
                print(f"   âš ï¸ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                # ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•´ë„ ìºì‹œ ì €ì¥ì€ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
            
            return True
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False

# ===========================================
# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
# ===========================================

_context_manager_instance = None

def _get_context_manager() -> ContextManager:
    """ContextManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _context_manager_instance
    if _context_manager_instance is None:
        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
        _context_manager_instance = ContextManager(os.getcwd(), 'default_project')
    return _context_manager_instance

# ===========================================
# Public API Implementation
# ===========================================

def initialize_context(project_path: str, project_name: str) -> dict:
    """í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”"""
    global _context_manager_instance
    _context_manager_instance = ContextManager(project_path, project_name)
    return _context_manager_instance.context

def save_context() -> bool:
    """ì»¨í…ìŠ¤íŠ¸ ì €ì¥"""
    cm = _get_context_manager()
    return cm.save()

def update_cache(context: dict, key: str, value: Any) -> bool:
    """ìºì‹œ ì—…ë°ì´íŠ¸"""
    # contextê°€ ì „ë‹¬ë˜ë©´ í•´ë‹¹ contextì˜ cache_manager ì‚¬ìš©
    if context and 'cache' in context:
        cache_manager = CacheManager(context)
        return cache_manager.update(key, value)
    else:
        # ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        cm = _get_context_manager()
        return cm.cache_manager.update(key, value)

def get_value(context: dict, key: str, default: Any = None) -> Any:
    """ìºì‹œì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°"""
    if context and 'cache' in context:
        cache_manager = CacheManager(context)
        return cache_manager.get(key, default)
    else:
        cm = _get_context_manager()
        return cm.cache_manager.get(key, default)

def find_symbol(context: dict, symbol_name: str) -> Optional[str]:
    """ì‹¬ë³¼ì˜ íŒŒì¼ ìœ„ì¹˜ ì°¾ê¸°"""
    symbol_index = get_value(context, "symbol_index", {})
    return symbol_index.get(symbol_name)

def track_file_access(context: dict, file_path: str, operation: str = 'read') -> dict:
    """íŒŒì¼ ì ‘ê·¼ ì¶”ì """
    if context:
        work_tracker = WorkTracker(context)
        return work_tracker.track_file_access(file_path, operation)
    else:
        cm = _get_context_manager()
        return cm.work_tracker.track_file_access(file_path, operation)

def track_function_edit(context: dict, file_path: str, function_name: str, 
                       class_name: Optional[str] = None, operation: str = 'edit') -> dict:
    """í•¨ìˆ˜/ë©”ì„œë“œ ìˆ˜ì • ì¶”ì """
    if context:
        work_tracker = WorkTracker(context)
        return work_tracker.track_function_edit(file_path, function_name, class_name, operation)
    else:
        cm = _get_context_manager()
        return cm.work_tracker.track_function_edit(file_path, function_name, class_name, operation)

def get_work_tracking_summary(context: dict) -> dict:
    """ì‘ì—… ì¶”ì  ìš”ì•½ ì •ë³´"""
    if context:
        work_tracker = WorkTracker(context)
        return work_tracker.get_summary()
    else:
        cm = _get_context_manager()
        return cm.work_tracker.get_summary()

# ===========================================
# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
# ===========================================

def build_index(context: dict, analyzed_files: Optional[dict] = None) -> bool:
    """ì‹¬ë³¼ ì¸ë±ìŠ¤ êµ¬ì¶• (í•˜ìœ„ í˜¸í™˜ì„±)"""
    print("âœ… ì‹¬ë³¼ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘...")
    
    # CacheManager ì‚¬ìš©
    cache_manager = CacheManager(context)
    files_to_index = analyzed_files or context.get("cache", {}).get("analyzed_files", {})
    
    if not files_to_index:
        print("âš ï¸ ì¸ë±ì‹±í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    for file_path, analysis_data in files_to_index.items():
        if isinstance(analysis_data, dict):
            cache_manager._update_symbol_index(file_path, analysis_data)
    
    print(f"âœ… ì‹¬ë³¼ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ.")
    return True

def propose_next_steps(context: dict, limit: int = 3) -> list:
    """ë‹¤ìŒ ì‘ì—… ì œì•ˆ"""
    suggestions = []
    
    # work_trackingì´ ìˆëŠ”ì§€ í™•ì¸
    if 'cache' not in context or 'work_tracking' not in context.get('cache', {}):
        return []
    
    work_summary = get_work_tracking_summary(context)
    
    # 1. ê°€ì¥ ë§ì´ ì ‘ê·¼í•œ íŒŒì¼ ê¸°ë°˜ ì œì•ˆ
    most_accessed = work_summary.get('most_accessed_files', [])
    if most_accessed:
        file_path, access_data = most_accessed[0]
        # access_dataê°€ dictì¸ ê²½ìš°ì™€ intì¸ ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
        access_count = access_data.get('access_count', 0) if isinstance(access_data, dict) else access_data
        
        if access_count > 5:  # 5íšŒ ì´ìƒ ì ‘ê·¼í•œ íŒŒì¼
            suggestions.append({
                'type': 'focus',
                'text': f"'{os.path.basename(file_path)}' ê´€ë ¨ ì‘ì—… ê³„ì†í•˜ê¸°",
                'priority': 0.9,
                'rationale': f"ìµœê·¼ {access_count}íšŒ ì ‘ê·¼í•œ íŒŒì¼"
            })
    
    # 2. ê°€ì¥ ë§ì´ ìˆ˜ì •í•œ í•¨ìˆ˜ ê¸°ë°˜ ì œì•ˆ
    most_edited = work_summary.get('most_edited_functions', [])
    if most_edited and len(most_edited) > 0:
        func_key, edit_count = most_edited[0]
        if edit_count > 3:  # 3íšŒ ì´ìƒ ìˆ˜ì •í•œ í•¨ìˆ˜
            func_name = func_key.split('::')[-1] if '::' in func_key else func_key
            suggestions.append({
                'type': 'task',
                'text': f"'{func_name}' í•¨ìˆ˜ ë¦¬íŒ©í† ë§ ë˜ëŠ” í…ŒìŠ¤íŠ¸ ì‘ì„±",
                'priority': 0.8,
                'rationale': f"ìµœê·¼ {edit_count}íšŒ ìˆ˜ì •ë¨"
            })
    
    # 3. í˜„ì¬ ì‘ì—… ì¤‘ì¸ íŒŒì¼ ê¸°ë°˜ ì œì•ˆ
    current_context = work_summary.get('current_context', {})
    if current_context.get('current_file'):
        current_file = current_context['current_file']
        suggestions.append({
            'type': 'continue',
            'text': f"'{os.path.basename(current_file)}' ì‘ì—… ê³„ì†í•˜ê¸°",
            'priority': 0.7,
            'rationale': "í˜„ì¬ ì‘ì—… ì¤‘ì¸ íŒŒì¼"
        })
    
    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œ ë°˜í™˜
    suggestions.sort(key=lambda x: x['priority'], reverse=True)
    return suggestions[:limit]

# ê¸€ë¡œë²Œ í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
def save_project_cache(project_context: dict) -> bool:
    """í”„ë¡œì íŠ¸ ìºì‹œ ì €ì¥ (í•˜ìœ„ í˜¸í™˜ì„±)"""
    if project_context:
        cm = ContextManager(
            project_context.get('project_path', os.getcwd()),
            project_context.get('project_name', 'unknown')
        )
        cm.context = project_context
        return cm.save()
    return False

# ===========================================
# ì´ˆê¸°í™” ì½”ë“œ
# ===========================================

    
    def _generate_coding_flow_content(self) -> str:
        """coding_flow.md ë‚´ìš© ìƒì„±"""
        from datetime import datetime
        
        content = f"""# ğŸ”¥ Current Focus
*ì§€ê¸ˆ ë­í•˜ê³  ìˆëŠ”ì§€*

í˜„ì¬ ì„¸ì…˜ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M')}
**í˜„ì¬ Focus**: {self.context.get('current_focus', 'Not set')}

## â­ï¸ Next Up (1-3 items)
*ë°”ë¡œ ë‹¤ìŒì— í•  ì¼ë“¤*

"""
        # Next tasks
        tasks = self.context.get('tasks', {})
        for task in tasks.get('next', [])[:3]:
            content += f"- [ ] {task}\n"
        
        content += "\n\n## âœ… Done (Recent)\n*ìµœê·¼ ì™„ë£Œí•œ ê²ƒë“¤*\n\n"
        
        # Done tasks  
        for task in tasks.get('done', [])[-5:]:
            content += f"- [x] {task}\n"
        
        # Progress
        done_count = len(tasks.get('done', []))
        total_count = done_count + len(tasks.get('next', []))
        progress = (done_count / total_count * 100) if total_count > 0 else 0
        
        content += f"\n\n## ğŸ“Š Progress\nì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({done_count}/{total_count})\n"
        
        return content

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_context = initialize_context(os.getcwd(), 'test_project')
    print("\n--- ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡° ---")
    print(json.dumps({
        'project_name': test_context['project_name'],
        'version': test_context['version'],
        'cache_keys': list(test_context.get('cache', {}).keys()),
        'stats': test_context.get('stats', {})
    }, indent=2, ensure_ascii=False))
