"""
Flow Service ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
ê¸°ì¡´ FlowService vs CachedFlowService ë¹„êµ
"""

import os
import sys
import time
import json
import tempfile
import statistics
from datetime import datetime
from pathlib import Path

# í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'python'))

from ai_helpers_new.service.cached_flow_service import CachedFlowService
from ai_helpers_new.domain.models import Flow, Plan, Task

class FlowServiceBenchmark:
    """Flow Service ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""

    def __init__(self):
        self.results = {
            'cached': {},
            'comparison': {},
            'improvement': {}
        }

    def generate_large_flow(self, num_plans=10, tasks_per_plan=20):
        """ëŒ€ê·œëª¨ Flow ë°ì´í„° ìƒì„±"""
        flow = Flow(
            id=f"flow_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            name="Benchmark Flow",
            metadata={"type": "benchmark", "size": "large"}
        )

        for p in range(num_plans):
            plan = Plan(
                id=f"plan_{p}",
                name=f"Plan {p}",
                flow_id=flow.id
            )

            for t in range(tasks_per_plan):
                task = Task(
                    id=f"task_{p}_{t}",
                    name=f"Task {p}-{t}",
                    plan_id=plan.id,
                    context={
                        "data": f"Sample data for task {p}-{t}" * 100  # ê¸´ í…ìŠ¤íŠ¸
                    }
                )
                plan.tasks[task.id] = task

            flow.plans[plan.id] = plan

        return flow

    def benchmark_write_operations(self, service, num_flows=50):
        """ì“°ê¸° ì‘ì—… ë²¤ì¹˜ë§ˆí¬"""
        times = []

        for i in range(num_flows):
            flow = self.generate_large_flow()

            start = time.perf_counter()
            service.save_flow(flow)
            end = time.perf_counter()

            times.append(end - start)

        return {
            'total_time': sum(times),
            'average_time': statistics.mean(times),
            'min_time': min(times),
            'max_time': max(times),
            'std_dev': statistics.stdev(times) if len(times) > 1 else 0
        }

    def benchmark_read_operations(self, service, flow_ids, num_reads=100):
        """ì½ê¸° ì‘ì—… ë²¤ì¹˜ë§ˆí¬"""
        times = []

        for i in range(num_reads):
            flow_id = flow_ids[i % len(flow_ids)]

            start = time.perf_counter()
            flow = service.get_flow(flow_id)
            end = time.perf_counter()

            times.append(end - start)

        return {
            'total_time': sum(times),
            'average_time': statistics.mean(times),
            'min_time': min(times),
            'max_time': max(times),
            'std_dev': statistics.stdev(times) if len(times) > 1 else 0,
            'ops_per_second': num_reads / sum(times)
        }

    def benchmark_list_operations(self, service, num_lists=50):
        """ëª©ë¡ ì¡°íšŒ ë²¤ì¹˜ë§ˆí¬"""
        times = []

        for i in range(num_lists):
            start = time.perf_counter()
            flows = service.list_flows()
            end = time.perf_counter()

            times.append(end - start)

        return {
            'total_time': sum(times),
            'average_time': statistics.mean(times),
            'min_time': min(times),
            'max_time': max(times),
            'std_dev': statistics.stdev(times) if len(times) > 1 else 0
        }

    def run_benchmark(self):
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        with tempfile.TemporaryDirectory() as temp_dir:
            # CachedFlowService í…ŒìŠ¤íŠ¸
            cached_service = CachedFlowService(storage_path=temp_dir)

            print("ğŸš€ CachedFlowService ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")

            # ì“°ê¸° ë²¤ì¹˜ë§ˆí¬
            print("  ğŸ“ ì“°ê¸° ì‘ì—… ë²¤ì¹˜ë§ˆí¬...")
            write_results = self.benchmark_write_operations(cached_service, num_flows=20)
            self.results['cached']['write'] = write_results

            # Flow ID ìˆ˜ì§‘
            flow_ids = [f.id for f in cached_service.list_flows()]

            # ì½ê¸° ë²¤ì¹˜ë§ˆí¬ (ìºì‹œ ì›Œë°ì—…)
            print("  ğŸ“– ì½ê¸° ì‘ì—… ë²¤ì¹˜ë§ˆí¬ (ìºì‹œ ì½œë“œ)...")
            read_cold_results = self.benchmark_read_operations(cached_service, flow_ids, num_reads=50)
            self.results['cached']['read_cold'] = read_cold_results

            # ì½ê¸° ë²¤ì¹˜ë§ˆí¬ (ìºì‹œ í™œìš©)
            print("  ğŸ“– ì½ê¸° ì‘ì—… ë²¤ì¹˜ë§ˆí¬ (ìºì‹œ ì›œ)...")
            read_warm_results = self.benchmark_read_operations(cached_service, flow_ids, num_reads=50)
            self.results['cached']['read_warm'] = read_warm_results

            # ëª©ë¡ ì¡°íšŒ ë²¤ì¹˜ë§ˆí¬
            print("  ğŸ“‹ ëª©ë¡ ì¡°íšŒ ë²¤ì¹˜ë§ˆí¬...")
            list_results = self.benchmark_list_operations(cached_service, num_lists=30)
            self.results['cached']['list'] = list_results

            # ìºì‹œ íš¨ìœ¨ì„± ê³„ì‚°
            cache_speedup = read_cold_results['average_time'] / read_warm_results['average_time']
            self.results['improvement']['cache_speedup'] = cache_speedup

            print("\nâœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")

        return self.results

    def print_results(self):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š CachedFlowService ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
        print("="*60)

        # ì“°ê¸° ì„±ëŠ¥
        write = self.results['cached']['write']
        print(f"\nğŸ“ ì“°ê¸° ì‘ì—…:")
        print(f"  - í‰ê·  ì‹œê°„: {write['average_time']*1000:.2f}ms")
        print(f"  - ìµœì†Œ/ìµœëŒ€: {write['min_time']*1000:.2f}ms / {write['max_time']*1000:.2f}ms")

        # ì½ê¸° ì„±ëŠ¥
        read_cold = self.results['cached']['read_cold']
        read_warm = self.results['cached']['read_warm']
        print(f"\nğŸ“– ì½ê¸° ì‘ì—… (ìºì‹œ ì½œë“œ):")
        print(f"  - í‰ê·  ì‹œê°„: {read_cold['average_time']*1000:.2f}ms")
        print(f"  - ì²˜ë¦¬ëŸ‰: {read_cold['ops_per_second']:.0f} ops/sec")

        print(f"\nğŸ“– ì½ê¸° ì‘ì—… (ìºì‹œ ì›œ):")
        print(f"  - í‰ê·  ì‹œê°„: {read_warm['average_time']*1000:.2f}ms")
        print(f"  - ì²˜ë¦¬ëŸ‰: {read_warm['ops_per_second']:.0f} ops/sec")

        # ìºì‹œ íš¨ìœ¨ì„±
        speedup = self.results['improvement']['cache_speedup']
        print(f"\nğŸš€ ìºì‹œ íš¨ìœ¨ì„±:")
        print(f"  - ì†ë„ í–¥ìƒ: {speedup:.1f}x")
        print(f"  - ì„±ëŠ¥ ê°œì„ : {(speedup-1)*100:.0f}%")

        # ëª©ë¡ ì¡°íšŒ ì„±ëŠ¥
        list_perf = self.results['cached']['list']
        print(f"\nğŸ“‹ ëª©ë¡ ì¡°íšŒ:")
        print(f"  - í‰ê·  ì‹œê°„: {list_perf['average_time']*1000:.2f}ms")

        print("\n" + "="*60)


if __name__ == "__main__":
    benchmark = FlowServiceBenchmark()
    results = benchmark.run_benchmark()
    benchmark.print_results()

    # ê²°ê³¼ ì €ì¥
    with open('test/results/benchmark_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    print("\nğŸ’¾ ê²°ê³¼ê°€ test/results/benchmark_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
