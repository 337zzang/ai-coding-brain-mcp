#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ì˜¬ìŠ¤íƒ€ì „ ê²€ìƒ‰ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
ìƒì„± ì‹œê°„: 2025-07-13
"""

import time
import sys
import os

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from python.api.web_automation import WebAutomation


def search_naver_allstar():
    """ë„¤ì´ë²„ì—ì„œ ì˜¬ìŠ¤íƒ€ì „ ê²€ìƒ‰"""
    print("ğŸ¯ ë„¤ì´ë²„ ì˜¬ìŠ¤íƒ€ì „ ê²€ìƒ‰ ì‹œì‘")

    # WebAutomation ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    with WebAutomation(headless=False) as web:
        try:
            # 1. ë„¤ì´ë²„ ì ‘ì†
            print("\n1ï¸âƒ£ ë„¤ì´ë²„ í™ˆí˜ì´ì§€ ì ‘ì†...")
            result = web.go_to_page("https://www.naver.com")
            if not result["success"]:
                raise Exception(f"í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨: {result['message']}")
            print(f"âœ… ì ‘ì† ì„±ê³µ: {result['title']}")
            time.sleep(2)

            # 2. ê²€ìƒ‰ì–´ ì…ë ¥
            print("\n2ï¸âƒ£ ê²€ìƒ‰ì–´ 'ì˜¬ìŠ¤íƒ€ì „' ì…ë ¥...")
            result = web.input_text("input[name='query']", "ì˜¬ìŠ¤íƒ€ì „", by="css")
            if not result["success"]:
                raise Exception(f"ê²€ìƒ‰ì–´ ì…ë ¥ ì‹¤íŒ¨: {result['message']}")
            print("âœ… ê²€ìƒ‰ì–´ ì…ë ¥ ì™„ë£Œ")
            time.sleep(0.5)

            # 3. ê²€ìƒ‰ ì‹¤í–‰ (Enter)
            print("\n3ï¸âƒ£ ê²€ìƒ‰ ì‹¤í–‰...")
            result = web.input_text("input[name='query']", "", by="css", press_enter=True)
            print("âœ… ê²€ìƒ‰ ì‹¤í–‰ ì™„ë£Œ")
            time.sleep(3)  # ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ ëŒ€ê¸°

            # 4. ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
            print("\n4ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„...")

            # ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ
            news_result = web.extract_text("a.news_tit", by="css", all_matches=True)
            if news_result["success"] and news_result.get("texts"):
                print(f"\nğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ({len(news_result['texts'])}ê°œ):")
                for i, title in enumerate(news_result['texts'][:5], 1):
                    print(f"   {i}. {title[:60]}...")

            # ìŠ¤í¬ì¸  ì •ë³´ í™•ì¸
            sports_result = web.extract_text("div.sports_area", by="css")
            if sports_result["success"] and sports_result.get("text"):
                print("\nâš¾ ìŠ¤í¬ì¸  ì„¹ì…˜ ì •ë³´ ë°œê²¬")
                text_preview = sports_result["text"][:200]
                print(f"   ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {text_preview}...")

            # ì¶”ê°€ ì •ë³´ ì¶”ì¶œ ì‹œë„
            # ë‚ ì§œ/ì¼ì • ì •ë³´
            date_result = web.extract_text("span.date", by="css", all_matches=True)
            if date_result["success"] and date_result.get("texts"):
                print("\nğŸ“… ë‚ ì§œ ì •ë³´:")
                for date in date_result['texts'][:3]:
                    print(f"   - {date}")

            # 5. ìŠ¤í¬ë¦°ìƒ· (ì„ íƒì‚¬í•­)
            print("\n5ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ ìƒíƒœ")
            page_info = web.get_page_content()
            if page_info["success"]:
                print(f"   - í˜„ì¬ URL: {page_info['url']}")
                print(f"   - í˜ì´ì§€ ì œëª©: {page_info['title']}")
                print(f"   - í…ìŠ¤íŠ¸ ê¸¸ì´: {page_info['text_length']:,}ì")

            print("\nâœ… ê²€ìƒ‰ ì™„ë£Œ!")
            return True

        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    success = search_naver_allstar()

    if success:
        print("\nğŸ‰ ë„¤ì´ë²„ ì˜¬ìŠ¤íƒ€ì „ ê²€ìƒ‰ ìë™í™” ì„±ê³µ!")
    else:
        print("\nğŸ˜¢ ê²€ìƒ‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    return success


if __name__ == "__main__":
    # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    result = main()
    exit(0 if result else 1)
