{
  "id": "o3_task_0001",
  "status": "completed",
  "question": "\nAI-Coding-Brain-MCP 통합 아키텍처 심층 분석:\n\n=== 핵심 시스템 분석 대상 ===\n=== python/ai_helpers_new/flow_api.py (flow_system, critical priority) ===\n\"\"\"\nFlow API - 핵심 비즈니스 로직\n분리일: 2025-08-03\n원본: simple_flow_commands.",
  "start_time": "2025-08-23T11:32:45.588933",
  "reasoning_effort": "high",
  "last_update": "2025-08-23T11:35:27.730243",
  "result": {
    "answer": "다음 평가는 제공된 코드 스냅샷과 폴더 구조를 바탕으로 실제 동작 경로와 실패 가능 지점을 추론한 결과입니다. 일부 파일이 부분 공개되어 있어 추정이 포함되며, 해당 부분은 보수적으로 판단했습니다.\n\n요약 결론\n- Flow-Hook 연동의 현재 완성도는 60% 수준으로 보입니다. 핵심 결함은 unified_sync가 flow_api에서 존재하지 않는 FlowAPI 클래스를 import하는 인터페이스 불일치(치명적)와, 파일 기반 동기화(.ai-brain/flow/index.json)를 멀티 프로세스/스트리밍 실행(json_repl_session)과 동시에 사용할 때의 원자성·락·이벤트 전파 부재입니다.\n- execute_code 경로의 양방향 데이터 흐름은 부분 구현 상태입니다. 코드 실행 결과를 Hook 응답으로 반환하는 단방향은 동작 가능성이 높으나, Flow 상태 변화→Hook UI/세션 동기화로 이어지는 반대 방향 이벤트 전파가 체계적으로 연결되어 있지 않습니다.\n- 보안 측면에서 Hook 권한이 과도하게 광범위해(임의 Bash/python/node/cmd.exe) 실제 운영에 투입하기에는 위험합니다.\n\n1) Flow 시스템과 Hook 시스템 연동 메커니즘\n- 현재 데이터 흐름(추정)\n  - Hook(MCP)에서 mcp__ai-coding-brain-mcp__execute_code 호출\n  - python/json_repl_session.py가 EnhancedREPLSession으로 코드 실행\n  - 실행 코드에서 ai_helpers_new.flow_api 또는 unified_sync를 호출하여 .ai-brain/flow/* JSON에 상태 반영\n  - Hook는 execute_code 호출 응답(및 스트림)으로 일부 결과 수신\n  - UnifiedSync가 .ai-brain 하위의 claude_sessions, todo_sync, unified_plans와 Flow를 동기화(설계 상)\n- 상태 동기화/이벤트 전파\n  - Flow→Hook: 구조적으로는 EnhancedTaskLogger를 통해 콘솔/파일 로그는 가능하나, MCP 스트리밍 채널로의 구조화된 이벤트 전송 어댑터가 보이지 않습니다. UnifiedSync도 파일 폴링/수동 호출 기반으로 보이며 실시간 event push는 없음.\n  - Hook→Flow: execute_code를 통해 코드 실행 시 Flow API를 직접 호출함으로써 즉시 반영 가능.\n- 완성도와 문제점\n  - [치명적 P0] 인터페이스 불일치: python/ai_helpers_new/unified_sync.py가 from .flow_api import FlowAPI를 사용하나, python/ai_helpers_new/flow_api.py에는 FlowAPI 클래스가 보이지 않음. 런타임 ImportError로 UnifiedSync 초기화 실패.\n  - [높음 P0] 양방향 이벤트 파이프라인 부재: Flow 상태 변경 시 Hook UI/세션에 실시간 반영되는 표준 경로가 없음. EnhancedTaskLogger가 MCP 스트리밍으로 브리징되지 않음.\n  - [높음 P0] 파일 기반 동시 접근에 대한 락/원자성/버저닝 부재: .ai-brain/flow/index.json 등 JSON 파일을 멀티 프로세스(REPL, 별도 스크립트, Hook)에서 갱신 시 손상 위험.\n  - [중간 P1] REPL 재시작 경로: mcp__ai-coding-brain-mcp__restart_json_repl 존재. 이전 세션 정리/고아 프로세스 방지/단일 인스턴스 보장/헬스체크 미비 추정.\n\n개선 제안(핵심)\n- P0: flow_api에 공식 인터페이스(FlowAPI 클래스) 신속 구현 또는 unified_sync의 import 수정. Flow 기능을 다음 메서드로 표준화: get_plan, list_plans, create_plan, add_task, update_task_status, get_task, list_tasks, save/commit(원자성 보장).\n- P0: 이벤트 브리지 추가\n  - FlowAPI에서 도메인 이벤트(TaskCreated/Updated, PlanCreated/Updated)를 Outbox(JSONL)로 기록(.ai-brain/events/outbox.jsonl, 원자적 append).\n  - Hook 측 MCP가 이 Outbox를 폴링 또는 파일워처(Watchdog)로 구독하여 Claude 세션/패널을 실시간 갱신. 처리 후 Processed 오프셋 관리(.ai-brain/events/state.json).\n  - EnhancedTaskLogger → MCPStreamLogger 어댑터: json_repl_session 실행 중 표준 출력으로 구조화 이벤트(JSON line, type, plan_id, task_id, status, message)를 흘려 MCP 스트림으로 직결.\n- P0: 파일 잠금과 원자적 쓰기\n  - portalocker/filelock으로 .ai-brain/flow/*.json 및 index.json 갱신 시 파일락.\n  - 쓰기 시 tmp 파일→atomic rename, 버저닝(version, updated_at), ETag(파일 hash) 기반 충돌 감지.\n- P1: REPL 단일 인스턴스/정리\n  - PID 파일+락, 재시작 시 이전 PID 존재/활성 여부 확인 후 SIGTERM/강제종료 및 캐시 정리.\n  - 헬스체크 엔드포인트 또는 파일비트 비콘(heartbeat)로 세션 생존 감시.\n- P1: UnifiedSync 완성\n  - _ensure_dirs 구현, sync_state.json 스키마 정의(last_offsets, last_sync_ts, mapping Flow<->Claude).\n  - 충돌 정책(최신승/원천우선) 및 idempotency key(task_uid) 설계.\n- P1: execute_code 결과-상태 상관관계\n  - 요청에 correlation_id, plan_id, task_id 옵션 추가. Flow 업데이트 시 동일 id로 로깅/이벤트 발행, Hook가 응답과 이벤트를 매칭.\n\n2) 아키텍처 통합 품질\n- 결합도/응집도\n  - [중간 P2] UnifiedSync가 FlowAPI 구현 세부에 직접 의존(클래스 import). 인터페이스 분리(FlowClient 프로토콜) 미흡. 응집도는 디렉터리 구조상 역할 분리는 되었으나, 실제 캡슐화가 덜 됨.\n  - [중간 P2] wrappers.safe_api_get 등 래퍼가 다양한 계층에서 혼용. 네트워크/파일/내부 호출 구분이 불명확.\n- 데이터 일관성/동기화\n  - [높음 P0] JSON 파일 단일 소스에 다수 컴포넌트 접근, 동기화 원칙/락/버저닝 부재로 충돌과 손상 가능.\n  - [중간 P1] index.json과 개별 plan 파일의 트랜잭션 일관성 보장 필요(2단계 커밋 또는 저널+리플레이).\n- 확장성/유지보수성\n  - [중간 P2] .ai-brain에 산발적 디렉터리(claude_sessions, todo_sync, unified_plans)의 상호 관계가 문서화 부족. 모듈 간 경계 명확화와 인터페이스 프로토콜 정의 필요.\n\n개선 제안\n- P0: 파일 스토리지에 저널링 추가(events WAL)와 원자 쓰기.\n- P1: FlowClient/SyncClient 인터페이스 도입으로 구현체 교체 가능(파일/SQLite/HTTP).\n- P2: 스키마 버저닝(.schema.json), 마이그레이션 핸들러.\n\n3) 성능과 안정성 분석\n- 병목/성능 이슈\n  - [중간 P1] JSON 큰 파일 반복 읽기/쓰기, 멀티 프로세스 락 경쟁. 많은 태스크/플랜 증가 시 I/O 병목.\n  - [낮음 P3] json_repl_session의 DataStream은 대용량 처리 대응하나 Flow 상태 I/O는 여전히 JSON로 제한.\n- 메모리/리소스\n  - [중간 P2] REPL 캐시 스필-투-디스크는 좋으나 파일 핸들/임시파일 정리, gc 호출 시점 관리 필요.\n  - [낮음 P3] Windows stdout/stderr 인코딩 설정 코드 일부가 절단되어 있어 환경 변수 적용 누락 가능성.\n- 오류 처리/복구\n  - [높음 P1] ok_response/error_response는 단순 구조이며 에러 코드, 재시도 정책, 부분 실패 롤백 부재.\n  - [중간 P2] REPL 재시작 시 미정리 캐시/락으로 인한 교착 위험.\n\n개선 제안\n- P1: Flow 스토어를 SQLite(파일 잠금/트랜잭션)로 이전하거나 JSON+WAL+스냅샷 하이브리드로 개선.\n- P1: 표준 오류 코드 체계 정의(code, type, retriable, correlation_id). 에러 매핑 테이블.\n- P2: 리소스 파이널라이저/컨텍스트 매니저 도입, temp 디렉터리 주기 정리.\n\n4) 연동 최적화 기회\n- 미구현 통합 지점\n  - [높음 P1] Flow 도메인 이벤트→Hook 스트림 브리지.\n  - [중간 P2] Claude Code TodoWrite와의 양방향 매핑 규칙(TaskStatus↔Todo 상태).\n  - [중간 P2] Plan/Task 수준의 권한·owner 매핑.\n- 새로운 시너지\n  - [중간 P2] 실행 코드 셀과 Flow Task의 1:1 매핑으로 재현 가능한 실험 기록(artifact 경로/입출력 스냅샷).\n  - [중간 P2] 성능/자원 사용량을 Task 메타데이터로 축적, 이후 최적화 추천.\n- 자동화/효율\n  - [중간 P2] Watchdog 기반 실시간 동기화(파일 변경→즉시 UnifiedSync 트리거).\n  - [낮음 P3] 변경 감지 시 차등 업데이트(diff patch)로 I/O 절감.\n\n5) 근본적 아키텍처 개선점\n- 설계 패턴/구조\n  - [높음 P1] Outbox 패턴(+이벤트 컨슈머) 도입으로 일관성 보장 및 재처리 용이.\n  - [중간 P2] Command/Query 분리(CQRS): FlowAPI의 변경 명령과 조회 분리, 캐시/인덱싱 최적화.\n  - [중간 P2] 포맷 표준화(JSON Lines for events, JSON schema).\n- 장기 확장 리팩토링\n  - [중간 P2] Storage 추상화 계층: FileStore, SQLiteStore, RemoteStore 플러그 가능.\n  - [낮음 P3] 패키지 구조 정리(ai_helpers_new 내부 네이밍 일관화, repl_core 디펜던시 격리).\n- 보안/무결성\n  - [치명적 P0] .claude/settings.local.json 권한 축소: Bash(python:*), Bash(node:*), cmd.exe:* 제거. 특정 스크립트/디렉터리 화이트리스트만 허용(예: python/json_repl_session.py, python -m ai_brain.repl).\n  - [높음 P1] 입력 검증 및 경로 제한(safe_api_get 외 호출도 파라미터 검증).\n  - [중간 P2] 이벤트/스토리지 기록의 서명 또는 해시 체인(Optional)로 무결성 검증.\n\n구체 항목별 위치/심각도/우선순위/해결\n- 파일: python/ai_helpers_new/unified_sync.py\n  - 문제: from .flow_api import FlowAPI 불일치\n  - 심각도/우선순위: 치명적 P0\n  - 해결: flow_api에 FlowAPI 클래스 구현 또는 import를 get_manager/Flow 함수로 교체. 예) class FlowAPI: __init__(manager); create_plan(...); add_task(...); update_task_status(...).\n- 파일: python/ai_helpers_new/flow_api.py\n  - 문제: get_manager 미완성, ok_response/error_response의 모듈별 중복/불일치 가능.\n  - 심각도/우선순위: 높음 P1\n  - 해결: get_manager 완성(세션/프로젝트 컨텍스트), 응답 헬퍼 통합 모듈로 이동(ai_helpers_new.util).\n- 파일: python/json_repl_session.py\n  - 문제: 스트리밍 이벤트를 Hook에 구조화 전달 경로 부재.\n  - 심각도/우선순위: 높음 P0\n  - 해결: EnhancedREPLSession에 이벤트 핸들러 주입, stdout에 JSONL 프레임({\"type\":\"task_log\",\"task_id\":...}) 출력. MCP가 이를 스트림으로 노출.\n  - 문제: 재시작/단일 인스턴스 보장 미비\n  - 심각도/우선순위: 중간 P1\n  - 해결: PID 락, 헬스체크, 종료 시 캐시 정리.\n- 파일: .ai-brain/flow/index.json 및 전반 스토리지\n  - 문제: 원자성/락/버저닝 부재\n  - 심각도/우선순위: 높음 P0\n  - 해결: filelock, temp-write-then-rename, version/etag, WAL(outbox.jsonl)+주기적 스냅샷.\n- 파일: .claude/settings.local.json\n  - 문제: 과도 권한\n  - 심각도/우선순위: 치명적 P0\n  - 해결: 허용 목록 축소 예\n    - 허용: mcp__ai-coding-brain-mcp__execute_code, mcp__ai-coding-brain-mcp__restart_json_repl, Bash(python json_repl_session.py ...), Bash(dir \"C:\\\\Users\\\\82106\\\\.claude\\\\hooks\" /b)\n    - 제거: Bash(python:*), Bash(node:*), Bash(cmd.exe:*), Bash(npm run build:*), Bash(Bash:*) 와일드카드\n\nFlow-Hook 연동 한계와 개선 로드맵\n- 현재 한계\n  - 이벤트 역방향(Flow→Hook) 실시간 전파 부재\n  - 파일 기반 동기화의 경쟁 상태\n  - UnifiedSync의 API 불일치와 디렉터리 초기화 미완성\n  - 보안 정책 부재로 운영 리스크\n- 로드맵\n  - 0–2주(P0)\n    - FlowAPI 인터페이스 수립 및 UnifiedSync 수리\n    - 파일 잠금/원자 쓰기/버저닝 도입\n    - MCP 스트림 이벤트 브리지 구축(TaskLogger→MCPStreamLogger)\n    - Hook 권한 축소 및 화이트리스트\n  - 2–4주(P1)\n    - Outbox 이벤트 로그 + 컨슈머(Watchdog) 도입\n    - REPL 단일 인스턴스/헬스체크/재시작 안전화\n    - 에러 코드/재시도/롤백 정책 수립\n  - 4–8주(P2)\n    - Storage 추상화 및 SQLite 백엔드 옵션\n    - TodoWrite/Claude 상태 양방향 매핑 표준화\n    - 스키마 버저닝/마이그레이션\n  - 8주+(P3)\n    - 보안 강화를 위한 코드 서명/해시 체인(옵션)\n    - 관측성(메트릭/트레이스/프로파일링) 추가\n\n권장 구현 스케치\n- FlowAPI 클래스(요약)\n  - create_plan(name, meta) -> plan_id\n  - add_task(plan_id, task) -> task_id\n  - update_task_status(plan_id, task_id, status, log=None) -> ok\n  - list_plans(), list_tasks(plan_id)\n  - 내부: UltraSimpleFlowManager + UltraSimpleRepository + EnhancedTaskLogger + FileLock + atomic_write\n  - 이벤트: emit_event(dict) → Outbox append(JSONL)\n- MCPStreamLogger\n  - log(level, message, context) → print(json.dumps({\"type\":\"task_log\",\"level\":...}), flush=True)\n  - status(plan_id, task_id, status) → print({\"type\":\"task_status\", ...})\n- Outbox 컨슈머(Hook 사이드 또는 별도 워커)\n  - 파일워처로 outbox.jsonl tail → Claude UI 업데이트/TodoWrite 반영\n  - sync_state.json에 last_offset 저장\n\n테스트 계획\n- 동시성: 3개 프로세스가 같은 plan에 task 추가/상태 갱신 시 손상/경쟁 유무\n- 크래시 안전성: 쓰기 중 프로세스 kill 후 파일 일관성 검사 및 WAL 리플레이\n- REPL 재시작: 이전 프로세스 잔존 방지, 캐시/락 정리\n- 이벤트 전파 지연: Flow→Hook 200ms 내 스트림 수신 보장\n- 보안: 비허용 명령 거부, 디렉터리 탈출 방지\n\n마무리\n- 당장 막혀 있는 부분은 unified_sync와 flow_api 간 인터페이스 불일치(치명적)와 파일 동시 접근 안전성(치명적)입니다. 이 두 가지를 P0로 먼저 해결하고, 이벤트 브리지와 권한 축소를 함께 묶어 배포하면 Flow-Hook 양방향 연동의 토대가 갖춰집니다. 이후 Outbox/CQRS/스토리지 추상화로 점진적으로 확장성과 안정성을 강화하는 것을 권장합니다.",
    "reasoning_effort": "high",
    "usage": {
      "prompt_tokens": 1993,
      "completion_tokens": 7717,
      "total_tokens": 9710,
      "reasoning_tokens": 0
    }
  },
  "end_time": "2025-08-23T11:35:27.729234"
}