# from python.workflow_integration import switch_project_workflow  # Moved to method to avoid circular import
"""
í†µí•©ëœ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì
í”„ë¡œì íŠ¸ë³„ ìƒíƒœì™€ ì›Œí¬í”Œë¡œìš° ë°ì´í„°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""
import json
from pathlib import Path
from datetime import datetime
import os
import logging
from typing import Dict, Any, Optional, List

try:
    from path_utils import (
        get_context_path, 
        get_workflow_path,
        get_project_root,
        get_cache_dir
    )
except ImportError:
    # ìƒëŒ€ ì„í¬íŠ¸ ì‹¤íŒ¨ ì‹œ ì ˆëŒ€ ê²½ë¡œë¡œ ì‹œë„
    import sys
    sys.path.append("python")
    from path_utils import (
        get_context_path,
        get_workflow_path,
        get_project_root,
        get_cache_dir
    )
from utils.io_helpers import atomic_write, write_json, read_json
from core.cache_manager import get_cache_manager

logger = logging.getLogger(__name__)

class CacheAPI:
    """ContextManagerë¥¼ í†µí•œ ì¼ê´€ëœ ìºì‹œ ì ‘ê·¼ ì¸í„°í˜ì´ìŠ¤"""

    def __init__(self, cache_manager):
        """
        Args:
            cache_manager: CacheManager ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
        """
        self._manager = cache_manager
        self._fallback_cache = {}  # CacheManagerê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  í´ë°±

    def get(self, key: str, default=None):
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        if self._manager:
            value = self._manager.get(key)
            return value if value is not None else default
        else:
            return self._fallback_cache.get(key, default)

    def set(self, key: str, value: Any, ttl: int = None, dependencies: List[str] = None):
        """ìºì‹œì— ê°’ ì €ì¥"""
        if self._manager:
            # Path ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            dep_paths = [Path(d) for d in dependencies] if dependencies else []
            self._manager.set(key, value, ttl=ttl, dependencies=dep_paths)
        else:
            self._fallback_cache[key] = value

    def invalidate(self, key: str):
        """íŠ¹ì • í‚¤ ë¬´íš¨í™”"""
        if self._manager:
            self._manager.invalidate(key)
        else:
            self._fallback_cache.pop(key, None)

    def invalidate_by_file(self, filepath: str) -> List[str]:
        """íŒŒì¼ ë³€ê²½ì— ë”°ë¥¸ ë¬´íš¨í™”"""
        if self._manager:
            return self._manager.invalidate_by_file(Path(filepath))
        else:
            # í´ë°± ëª¨ë“œì—ì„œëŠ” ì „ì²´ ìºì‹œ í´ë¦¬ì–´
            keys = list(self._fallback_cache.keys())
            self._fallback_cache.clear()
            return keys

    def clear(self):
        """ì „ì²´ ìºì‹œ í´ë¦¬ì–´"""
        if self._manager:
            self._manager.clear_all()
        self._fallback_cache.clear()

    def exists(self, key: str) -> bool:
        """í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        if self._manager:
            return self._manager.get(key) is not None
        else:
            return key in self._fallback_cache

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        if self._manager:
            return self._manager.get_statistics()
        else:
            return {
                'mode': 'fallback',
                'items': len(self._fallback_cache),
                'cache_manager_available': False
            }

    def set_with_file_dependency(self, key: str, value: Any, filepath: str):
        """íŒŒì¼ ì˜ì¡´ì„±ê³¼ í•¨ê»˜ ìºì‹œ ì„¤ì • (í¸ì˜ ë©”ì„œë“œ)"""
        self.set(key, value, dependencies=[filepath])



class ContextManager:
    """í”„ë¡œì íŠ¸ë³„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.context = {}
        self.workflow_data = {}
        self.current_project_name = None
        # self.cache = {}  # [REMOVED] ë ˆê±°ì‹œ ìºì‹œ ì œê±°ë¨ - cache property ì‚¬ìš©
        self._cache_api = None  # CacheAPI ì¸ìŠ¤í„´ìŠ¤ (ë‚˜ì¤‘ì— ì´ˆê¸°í™”)
        self._cache_manager = None  # ìƒˆë¡œìš´ ìºì‹œ ë§¤ë‹ˆì €
        
    def get_current_project_name(self) -> str:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.current_project_name:
            return self.current_project_name
    
    @property
    def cache(self):
        """ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•œ ìºì‹œ ì ‘ê·¼ì"""
        if not hasattr(self, '_cache_api') or self._cache_api is None:
            # ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° í´ë°±
            if not hasattr(self, '_fallback_cache'):
                self._fallback_cache = {}
            return self._fallback_cache
        return self._cache_api
    
    def initialize(self, project_name: str = None):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.current_project_name = project_name or self.get_current_project_name()
        
        # ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™” - ì§€ì—° ì´ˆê¸°í™”ë¡œ ë³€ê²½
        self._cache_manager = None  # ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
        self._cache_dir = None  # ë‚˜ì¤‘ì— ì‚¬ìš©í•  ìºì‹œ ë””ë ‰í† ë¦¬ ì €ì¥
        
        # CacheAPIëŠ” ì¦‰ì‹œ ì´ˆê¸°í™” (ìºì‹œ ë§¤ë‹ˆì € ì—†ì´ë„ ì‘ë™)
        self._cache_api = CacheAPI(None)  # Noneìœ¼ë¡œ ì´ˆê¸°í™”í•˜ë©´ í´ë°± ëª¨ë“œ
        
        # í†µí•© tracking ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if 'tracking' not in self.context:
            self.context['tracking'] = {
                'tasks': {},
                'files': {},
                'operations': [],
                'errors': [],
                'statistics': {
                    'total_operations': 0,
                    'successful_operations': 0,
                    'failed_operations': 0,
                    'total_execution_time': 0
                }
            }
        
        if not project_name:
            project_name = self.get_current_project_name()
            
        self.current_project_name = project_name
        self.load_all()
        # print(f"ContextManager initialized: {project_name}")
    
    def _ensure_cache_manager(self):
        """ìºì‹œ ë§¤ë‹ˆì €ë¥¼ ì§€ì—° ì´ˆê¸°í™”í•©ë‹ˆë‹¤ (í•„ìš”í•  ë•Œë§Œ)"""
        if self._cache_manager is None and self.current_project_name:
            try:
                # ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
                if self._cache_dir is None:
                    self._cache_dir = get_cache_dir(self.current_project_name)
                
                # ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
                self._cache_manager = get_cache_manager(self._cache_dir)
                
                # CacheAPIì— ìºì‹œ ë§¤ë‹ˆì € ì—°ê²°
                if hasattr(self, '_cache_api') and self._cache_api:
                    self._cache_api._manager = self._cache_manager
                    
                logger.debug(f"Cache manager initialized for project: {self.current_project_name}")
                
            except Exception as e:
                logger.warning(f"Failed to initialize cache manager: {e}")
                self._cache_manager = None
    
    def switch_project(self, new_project_name: str):
        """í”„ë¡œì íŠ¸ë¥¼ ì „í™˜í•©ë‹ˆë‹¤."""
        # ì§€ì—° importë¡œ ìˆœí™˜ ì°¸ì¡° í•´ê²°
        from python.workflow_integration import switch_project_workflow

        if self.current_project_name == new_project_name:
            print(f"ì´ë¯¸ '{new_project_name}' í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.")
            return
            
        # 1. í˜„ì¬ í”„ë¡œì íŠ¸ ë°ì´í„° ì €ì¥
        if self.current_project_name:
            self.save_all()
            print(f"ğŸ’¾ '{self.current_project_name}' í”„ë¡œì íŠ¸ ë°ì´í„° ì €ì¥")
            
        # 2. ìƒˆ í”„ë¡œì íŠ¸ë¡œ ì „í™˜
        self.current_project_name = new_project_name
        project_root = get_project_root(new_project_name)
        
        # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not project_root.exists():
            raise ValueError(f"í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {project_root}")
            
        # 3. ìƒˆ í”„ë¡œì íŠ¸ ë°ì´í„° ë¡œë“œ
        # ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ë„ ì „í™˜ (Task 1 ê°œì„ )
        switch_project_workflow(new_project_name)
        
        self.load_all()
        
        # print(f"í”„ë¡œì íŠ¸ '{new_project_name}'ë¡œ ì „í™˜ ì™„ë£Œ")
        
    def load_all(self):
        """ëª¨ë“  ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        if not self.current_project_name:
            self.current_project_name = self.get_current_project_name()
            
        # context.json ë¡œë“œ
        context_path = get_context_path(self.current_project_name)
        if context_path.exists():
            try:
                self.context = read_json(context_path, default={})
                print(f"  âœ“ context.json ë¡œë“œ ({len(self.context)} keys)")
            except Exception as e:
                print(f"  âŒ context.json ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.context = {}
        else:
            # ê¸°ì¡´ ìºì‹œ íŒŒì¼ë“¤ì„ í†µí•©
            self._migrate_old_cache()
            
        # workflow.json ë¡œë“œ
        workflow_path = get_workflow_path(self.current_project_name)
        if workflow_path.exists():
            try:
                self.workflow_data = read_json(workflow_path, default={})
                print(f"  âœ“ workflow.json ë¡œë“œ")
            except Exception as e:
                print(f"  âŒ workflow.json ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.workflow_data = {}
        else:
            # ê¸°ì¡´ workflow_data.jsonì—ì„œ ë¡œë“œ
            self._migrate_old_workflow()
                
    def save_all(self):
        """ëª¨ë“  ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        if not self.current_project_name:
            return
            
        # context.json ì €ì¥ (ìµœì í™”ëœ ë²„ì „)
        context_path = get_context_path(self.current_project_name)
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„ (ë¶ˆí•„ìš”í•œ í•„ë“œ ì œì™¸)
        context_to_save = {}
        excluded_keys = ['__mcp_shared_vars__', 'analyzed_files', 'cache']
        
        for key, value in self.context.items():
            if key not in excluded_keys:
                context_to_save[key] = value
        
        # analyzed_filesëŠ” ë³„ë„ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥
        if 'analyzed_files' in self.context and self.context['analyzed_files']:
            cache_dir = os.path.join(os.path.dirname(context_path), 'cache')
            os.makedirs(cache_dir, exist_ok=True)
            analyzed_files_path = os.path.join(cache_dir, 'analyzed_files.json')
            
            try:
                write_json({
                    'analyzed_files': self.context['analyzed_files'],
                    'last_updated': datetime.now().isoformat()
                }, Path(analyzed_files_path))
            except Exception as e:
                print(f"  âš ï¸ analyzed_files ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        context_to_save['last_modified'] = datetime.now().isoformat()
        context_to_save['project_name'] = self.current_project_name
        
        try:
            write_json(context_to_save, Path(context_path))
            print(f"  âœ“ context.json ì €ì¥ (ì›ìì  ì“°ê¸° ì ìš©)")
        except Exception as e:
            print(f"  âŒ context.json ì €ì¥ ì‹¤íŒ¨: {e}")
            
        # workflow.json ì €ì¥
        if self.workflow_data:
            workflow_path = get_workflow_path(self.current_project_name)
            try:
                write_json(self.workflow_data, Path(workflow_path))
                print(f"  âœ“ workflow.json ì €ì¥ (ì›ìì  ì“°ê¸° ì ìš©)")
            except Exception as e:
                print(f"  âŒ workflow.json ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def save(self):
        """save_allì˜ ë³„ì¹­ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)"""
        self.save_all()
                
    def _migrate_old_cache(self):
        """ê¸°ì¡´ ìºì‹œ íŒŒì¼ë“¤ì„ ìƒˆ êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤."""
        old_cache_dir = Path('memory/.cache')
        if not old_cache_dir.exists():
            self.context = {'cache': {}}
            return
            
        print("  ğŸ”„ ê¸°ì¡´ ìºì‹œ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        
        # ê¸°ì¡´ ìºì‹œ íŒŒì¼ë“¤ í†µí•©
        self.context = {
            'project_name': self.current_project_name,
            'core': {},
            'analyzed_files': [],
            'cache': {}
        }
        
        # cache_core.json
        core_file = old_cache_dir / 'cache_core.json'
        if core_file.exists():
            try:
                with open(core_file, 'r', encoding='utf-8') as f:
                    self.context['core'] = json.load(f)
            except:
                pass
                
        # cache_analyzed_files.json
        analyzed_file = old_cache_dir / 'cache_analyzed_files.json'
        if analyzed_file.exists():
            try:
                with open(analyzed_file, 'r', encoding='utf-8') as f:
                    self.context['analyzed_files'] = json.load(f)
            except:
                pass
                
        # print("  ìºì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        
    def _migrate_old_workflow(self):
        """ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ë°ì´í„°ë¥¼ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤."""
        # workflow_data.json
        old_workflow = Path('workflow_data.json')
        if old_workflow.exists():
            try:
                with open(old_workflow, 'r', encoding='utf-8') as f:
                    self.workflow_data = json.load(f)
                print("  âœ“ workflow_data.json ë§ˆì´ê·¸ë ˆì´ì…˜")
            except:
                self.workflow_data = {}
                
        # ê¸°ì¡´ ìºì‹œì˜ ì›Œí¬í”Œë¡œìš° ê´€ë ¨ ë°ì´í„°
        old_cache_dir = Path('memory/.cache')
        if old_cache_dir.exists():
            for cache_file in ['cache_plan.json', 'cache_tasks.json', 'cache_work_tracking.json']:
                filepath = old_cache_dir / cache_file
                if filepath.exists():
                    try:
                        with open(filepath, 'r', encoding='utf-8') as f:
                            key = cache_file.replace('cache_', '').replace('.json', '')
                            self.workflow_data[key] = json.load(f)
                    except:
                        pass
                        
    def update_context(self, *args, **kwargs):
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        if args and len(args) == 2:
            key, value = args
            self.context[key] = value
            # self.cache[key] = value  # [DEPRECATED]
            if hasattr(self, "_cache_api") and self._cache_api:
                self._cache_api.set(key, value)
            
            # ìƒˆë¡œìš´ ìºì‹œ ë§¤ë‹ˆì €ì—ë„ ì €ì¥
            if self._cache_manager:
                # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ë“¤ì„ ì˜ì¡´ì„±ìœ¼ë¡œ ì¶”ê°€
                dependencies = []
                if 'current_file' in self.context:
                    dependencies.append(Path(self.context['current_file']))
                
                self._cache_manager.set(f"context_{key}", value, dependencies=dependencies)
                
        elif kwargs:
            self.context.update(kwargs)
            # self.cache.update(kwargs)  # [DEPRECATED]
            if hasattr(self, "_cache_api") and self._cache_api:
                for k, v in kwargs.items():
                    self._cache_api.set(k, v)
            
            # ìƒˆë¡œìš´ ìºì‹œ ë§¤ë‹ˆì €ì—ë„ ì €ì¥
            if self._cache_manager:
                for k, v in kwargs.items():
                    self._cache_manager.set(f"context_{k}", v)
    
    def update_cache(self, *args, **kwargs):
        """update_contextì˜ ë³„ì¹­ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)"""
        self.update_context(*args, **kwargs)
            
    def get_value(self, key: str, default=None):
        """ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        # ìºì‹œ API ì‚¬ìš©
        if hasattr(self, "_cache_api") and self._cache_api:
            cache_key = "context_" + str(key)
            cached_value = self._cache_api.get(cache_key)
            if cached_value is not None:
                return cached_value
        
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì¡°íšŒ
        value = self.context.get(key, default)
        
        # ìºì‹œì— ì €ì¥
        if value is not None and hasattr(self, "_cache_api") and self._cache_api:
            cache_key = "context_" + str(key)
            self._cache_api.set(cache_key, value)
        
        return value
    def get_context(self) -> dict:
        """ì „ì²´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (ìµœì í™”ëœ ë²„ì „)."""
        # __mcp_shared_vars__ ë“± ë¶ˆí•„ìš”í•œ í‚¤ ì œì™¸
        filtered_context = {}
        excluded_keys = ['__mcp_shared_vars__']
        
        for key, value in self.context.items():
            if key not in excluded_keys:
                filtered_context[key] = value
                
        return filtered_context
    
    def get(self, key: str, default=None):
        """get_valueì˜ ë³„ì¹­"""
        return self.get_value(key, default)
    
    def track_file_access(self, filepath: str):
        """íŒŒì¼ ì ‘ê·¼ì„ ì¶”ì í•©ë‹ˆë‹¤."""
        if 'accessed_files' not in self.context:
            self.context['accessed_files'] = []
        
        access_info = {
            'path': filepath,
            'timestamp': datetime.now().isoformat()
        }
        
        # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ê²½ë¡œë§Œ ì²´í¬
        paths = [f['path'] for f in self.context['accessed_files']]
        if filepath not in paths:
            self.context['accessed_files'].append(access_info)
            
        # ìºì‹œ ë§¤ë‹ˆì €ì— íŒŒì¼ ë³€ê²½ ê°ì§€ ìš”ì²­
        if self._cache_manager:
            # ì´ íŒŒì¼ì— ì˜ì¡´í•˜ëŠ” ìºì‹œë“¤ì„ ë¬´íš¨í™”
            invalidated = self._cache_manager.invalidate_by_file(Path(filepath))
            if invalidated:
                print(f"[Cache] Invalidated {len(invalidated)} cache entries due to file access: {filepath}")
            
    def track_function_edit(self, file: str, function: str, changes: str):
        """í•¨ìˆ˜ ìˆ˜ì •ì„ ì¶”ì í•©ë‹ˆë‹¤."""
        if 'function_edits' not in self.context:
            self.context['function_edits'] = []
            
        edit_info = {
            'file': file,
            'function': function,
            'changes': changes,
            'timestamp': datetime.now().isoformat()
        }
        
        self.context['function_edits'].append(edit_info)


    # ===== ì›Œí¬í”Œë¡œìš° V3 í†µí•© ë©”ì„œë“œ =====

    def update_workflow_summary(self, summary: Dict[str, Any]) -> None:
        """ì›Œí¬í”Œë¡œìš° ìš”ì•½ ì •ë³´ ì—…ë°ì´íŠ¸"""
        if not hasattr(self, 'workflow_data'):
            self.workflow_data = {}

        self.workflow_data['summary'] = {
            'current_plan': summary.get('current_plan'),
            'progress': summary.get('progress', 0),
            'total_tasks': summary.get('total_tasks', 0),
            'completed_tasks': summary.get('completed_tasks', 0),
            'updated_at': datetime.now().isoformat()
        }
        self.save()  # _mark_dirty ëŒ€ì‹  save ì‚¬ìš©

    def add_workflow_event(self, event: Dict[str, Any]) -> None:
        """ì›Œí¬í”Œë¡œìš° ì´ë²¤íŠ¸ ì¶”ê°€ (ì¤‘ìš” ì´ë²¤íŠ¸ë§Œ)"""
        if not hasattr(self, 'workflow_data'):
            self.workflow_data = {}

        if 'events' not in self.workflow_data:
            self.workflow_data['events'] = []

        # ìµœëŒ€ 50ê°œ ì´ë²¤íŠ¸ë§Œ ìœ ì§€
        self.workflow_data['events'].append(event)
        if len(self.workflow_data['events']) > 50:
            self.workflow_data['events'] = self.workflow_data['events'][-50:]

        self.save()

    def get_task_context(self, task_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • íƒœìŠ¤í¬ì˜ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ"""
        # íƒœìŠ¤í¬ë³„ ì»¨í…ìŠ¤íŠ¸ëŠ” workflow_v3ì—ì„œ ê´€ë¦¬í•˜ë¯€ë¡œ
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì°¸ì¡°ë§Œ ë°˜í™˜
        if hasattr(self, 'workflow_data') and 'tasks' in self.workflow_data:
            return self.workflow_data['tasks'].get(task_id)
        return None

    def clear_workflow_data(self) -> None:
        """ì›Œí¬í”Œë¡œìš° ë°ì´í„° ì´ˆê¸°í™”"""
        if hasattr(self, 'workflow_data'):
            self.workflow_data = {}
            self.save()

    def get_recent_workflow_events(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ìµœê·¼ ì›Œí¬í”Œë¡œìš° ì´ë²¤íŠ¸ ì¡°íšŒ"""
        if hasattr(self, 'workflow_data') and 'events' in self.workflow_data:
            return self.workflow_data['events'][-limit:]
        return []
    
    # ===== ìºì‹œ ë¬´íš¨í™” ë©”ì„œë“œ =====
    
    def invalidate_cache(self, key: str):
        """íŠ¹ì • ìºì‹œ í•­ëª© ë¬´íš¨í™”"""
        # CacheAPIë¥¼ í†µí•œ ë¬´íš¨í™”
        if hasattr(self, '_cache_api') and self._cache_api is not None:
            self._cache_api.invalidate(key)
        elif hasattr(self, '_fallback_cache'):
            self._fallback_cache.pop(key, None)
        
        # ìƒˆë¡œìš´ ìºì‹œ ë§¤ë‹ˆì € (ì§€ì—° ì´ˆê¸°í™”)
        self._ensure_cache_manager()
        if self._cache_manager:
            self._cache_manager.invalidate(f"context_{key}")
    
    def invalidate_cache_by_file(self, filepath: str) -> List[str]:
        """íŒŒì¼ ë³€ê²½ì— ë”°ë¥¸ ìºì‹œ ë¬´íš¨í™”"""
        invalidated = []
        
        # ì§€ì—° ì´ˆê¸°í™”
        self._ensure_cache_manager()
        
        if self._cache_manager:
            invalidated = self._cache_manager.invalidate_by_file(Path(filepath))
            
            # ë ˆê±°ì‹œ ë©”ëª¨ë¦¬ ìºì‹œë„ í´ë¦¬ì–´ (ì•ˆì „ì„ ìœ„í•´)
            if invalidated:
                if hasattr(self, '_cache_api') and self._cache_api is not None:
                    self._cache_api.clear()
                elif hasattr(self, '_fallback_cache'):
                    self._fallback_cache.clear()
                
        return invalidated
    
    def get_cache_statistics(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        stats = {}
        
        # CacheAPIê°€ ì´ˆê¸°í™”ëœ ê²½ìš°ì—ë§Œ get_stats() í˜¸ì¶œ
        if hasattr(self, '_cache_api') and self._cache_api is not None:
            stats = self._cache_api.get_stats()
        else:
            # í´ë°± ëª¨ë“œ
            stats = {
                'mode': 'fallback',
                'items': len(getattr(self, '_fallback_cache', {})),
                'cache_manager_available': False
            }
        
        # ì¶”ê°€ ì •ë³´
        stats['cache_manager_available'] = self._cache_manager is not None
        
        # ìºì‹œ ë§¤ë‹ˆì € í†µê³„ (ì§€ì—° ì´ˆê¸°í™”)
        if stats['cache_manager_available']:
            self._ensure_cache_manager()
            if self._cache_manager:
                manager_stats = self._cache_manager.get_statistics()
                stats.update(manager_stats)
            
        return stats
    
    def set_cache_with_dependencies(self, key: str, value: Any, dependencies: List[str]):
        """ì˜ì¡´ì„±ì´ ìˆëŠ” ìºì‹œ í•­ëª© ì„¤ì •"""
        # CacheAPIë¥¼ í†µí•œ ìºì‹œ ì„¤ì •
        if hasattr(self, "_cache_api") and self._cache_api:
            self._cache_api.set_with_file_dependency(key, value, dependencies[0] if dependencies else None)
        else:
            # í´ë°± - CacheManager ì§ì ‘ ì‚¬ìš© (ì§€ì—° ì´ˆê¸°í™”)
            self._ensure_cache_manager()
            if self._cache_manager:
                dep_paths = [Path(d) for d in dependencies]
                self._cache_manager.set(f"context_{key}", value, dependencies=dep_paths)
    
    # ===== í†µí•© Tracking ì‹œìŠ¤í…œ ë©”ì„œë“œ =====
    
    def get_tracking(self) -> Dict[str, Any]:
        """í†µí•© tracking ë°ì´í„° ë°˜í™˜"""
        if 'tracking' not in self.context:
            self.context['tracking'] = {
                'tasks': {},
                'files': {},
                'operations': [],
                'errors': [],
                'statistics': {
                    'total_operations': 0,
                    'successful_operations': 0,
                    'failed_operations': 0,
                    'total_execution_time': 0
                }
            }
        return self.context['tracking']
    
    def get_file_access_history(self) -> List[Dict[str, Any]]:
        """íŒŒì¼ ì ‘ê·¼ ì´ë ¥ ë°˜í™˜ (ë ˆê±°ì‹œ í˜¸í™˜ì„±)"""
        tracking = self.get_tracking()
        history = []
        for file_path, file_data in tracking['files'].items():
            for op in file_data.get('operations', []):
                history.append({
                    'file': file_path,
                    'operation': op['action'],
                    'timestamp': op['timestamp'],
                    'task_id': op.get('task_id')
                })
        # ì‹œê°„ ì—­ìˆœ ì •ë ¬
        return sorted(history, key=lambda x: x['timestamp'], reverse=True)[:100]
    
    def get_error_log(self) -> List[Dict[str, Any]]:
        """ì—ëŸ¬ ë¡œê·¸ ë°˜í™˜ (ë ˆê±°ì‹œ í˜¸í™˜ì„±)"""
        tracking = self.get_tracking()
        return tracking.get('errors', [])
    
    def get_tracking_statistics(self) -> Dict[str, Any]:
        """ì¶”ì  í†µê³„ ë°˜í™˜"""
        tracking = self.get_tracking()
        stats = tracking.get('statistics', {}).copy()
        stats['total_files_tracked'] = len(tracking.get('files', {}))
        stats['total_tasks_tracked'] = len(tracking.get('tasks', {}))
        return stats

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_context_manager_instance = None

def get_context_manager() -> ContextManager:
    """ì‹±ê¸€í†¤ ContextManager ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _context_manager_instance
    if _context_manager_instance is None:
        _context_manager_instance = ContextManager()
        _context_manager_instance.initialize()
    return _context_manager_instance