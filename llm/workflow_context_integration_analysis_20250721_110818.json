{
  "analysis_date": "2025-07-21T11:08:18.076170",
  "topic": "워크플로우-컨텍스트 통합 분석",
  "results": {
    "MCP 환경 최적 저장 전략": {
      "answer": "어느 쪽이 “정답”이라고 딱 잘라 말하기보다는, MCP( Model-Context Protocol )가 어떻게 동작하고 어떤 제약이 있는지를 먼저 정리해 두면 판단이 명확해집니다.\n\n────────────────────\n1. MCP 세션의 특성\n────────────────────\n• 짧은 수명 / 콜-기반 실행  \n  ‑ MCP 엔진은 REST/WS 호출을 받을 때마다 컨테이너(또는 워커)를 띄워서 모델을 실행하는 구조가 일반적입니다.  \n  ‑ 호출이 끝나면 워커가 바로 내려가거나, idle timeout(수~수십 초) 이후 자동 파기됩니다.\n\n• 상태의 휘발성  \n  ‑ 로컬 메모리나 /tmp 는 세션 종료와 함께 사라집니다.  \n  ‑ “지속성(persistence)”이 필요하면 외부 저장소(S3, 외부 DB, network FS 등)에 명시적으로 써야 합니다.\n\n• 리소스 과금/제한  \n  ‑ CPU·RAM·I/O 가 사용량 기반으로 과금되거나 쿼터 제한을 받습니다.  \n  ‑ 불필요한 주기적 디스크-I/O, 스레드 타이머는 곧바로 비용·제한 이슈로 이어집니다.\n\n────────────────────\n2. 5분 주기 자동저장 vs. Task 완료 시 저장\n────────────────────\n항목별로 비교하면 다음과 같습니다.\n\nA) 세션 수명주기 안정성\n   • 5분 주기 : MCP 워커가 5분 이상 살아 있을 가능성 자체가 낮습니다.  \n     (대부분의 inference call 은 수초~수십초)  \n     따라서 5분 타이머가 트리거되기도 전에 프로세스가 내려가 버립니다.  \n   • Task 완료 시 : “/complete” 시점은 어차피 결과를 클라이언트에 돌려주는 시점이므로  \n     MCP 워커가 살아 있음이 보장됩니다.\n\nB) 데이터 유실 위험\n   • WorkflowManager 는 명령 단위(/start, /task 등)로 이미 JSON 파일을 갱신하고 있습니다.  \n     즉, ‘task 진행 중 중간 상태’가 필요한 게 아니라면, 완료 시 저장만으로도 실질적 손실이 없습니다.  \n   • 장시간 연산(몇 시간짜리 fine-tuning 등)을 MCP에 맡기는 경우라면 주기적 체크포인트가 필요하겠지만,  \n     그런 워크로드는 애초에 inference-centric MCP에 얹지 않고 배치 잡/파이프라인으로 빼는 편이 일반적입니다.\n\nC) 리소스 효율성\n   • 5분 주기 :  \n     ‑ 타이머 스레드 유지 → 메모리·스케줄러 비용  \n     ‑ 빈번한 파일-I/O → 네트워크 스토리지일 경우 레이턴시·과금 증가\n   • 완료 시 : 이벤트-드리븐 I/O → 불필요한 오버헤드 없음\n\nD) 구현·운영 복잡도\n   • 5분 주기 : 스레드 관리, graceful-shutdown, 충돌 해결(동시 save), 타이머 drift 등 추가 코드 필요\n   • 완료 시 : 현재 /complete 훅에 ContextManager.save()만 붙이면 끝\n\n────────────────────\n3. 결론 및 권장안\n────────────────────\nMCP 환경에서 “5분마다 자동저장”은 비용 대비 효용이 거의 없습니다.  \n정상적인 워크플로우라면:\n\n1) 워크플로우 명령 처리 시( /start, /task … ) → 기존처럼 WorkflowManager 가 JSON 즉시 반영  \n2) 핵심 결과물(모델 산출물·요약) → /complete 시점에 ContextManager.save_session() 호출  \n3) 장시간 작업이 필요하다면 MCP 밖(전용 배치 파이프라인 or 비동기 워커)으로 분리\n\n이벤트 기반(=task 완료 시) 저장 방식이 MCP의 사용 패턴·리소스 모델·운영 안정성 측면에서 가장 적절합니다.\n\n────────────────────\n4. 실제 코드 반영 포인트\n────────────────────\npython/ai_helpers_new/workflow_manager.py  \n\n```python\n# (기존) task 완료 처리\ndef complete_task(self, task_id: str, result: dict):\n    ...\n    self._tasks[task_id]['status'] = 'done'\n    self._tasks[task_id]['result'] = result\n    self._save_state_to_json()          # 기존 저장\n    ContextManager.save_session(task_id)  # <- 추가\n```\n\nflow_project_v2/context/context_manager.py  \n\n```python\nclass ContextManager:\n    @staticmethod\n    def save_session(task_id: str):\n        session = SessionManager.current_session()\n        # 파일명 규칙 예) session_{task_id}_{timestamp}.json\n        storage_path = build_path(task_id)\n        with open(storage_path, \"w\") as fp:\n            json.dump(session, fp)\n        ContextSummarizer.generate_ai_summary(session, storage_path)\n```\n\n(주기적 타이머 및 5분 autosave 로직은 제거)\n\n────────────────────\n5. 보완 옵션 (선택)\n────────────────────\n• “대형 job” 표시 플래그:  \n  /start 시 `--long-running` 옵션이 들어오면  N 분 주기 체크포인트를 활성화해 별도 워커(비용 고정)를 사용하게 할 수 있습니다.\n\n• 에러/중단 시 자동 저장:  \n  try/except 블록에서 예외가 나면 마지막 known state를 즉시 save → 보안망 역할.\n\n이와 같은 방식으로,\n  – MCP의 짧은 세션,  \n  – 외부 스토리지 쓰기 비용,  \n  – 단순한 이벤트 모델  \n을 모두 만족시키면서 데이터 유실 위험 없이 운영할 수 있습니다.",
      "reasoning_effort": "medium",
      "usage": {
        "prompt_tokens": 296,
        "completion_tokens": 1768,
        "total_tokens": 2064,
        "reasoning_tokens": 0
      }
    },
    "통합 아키텍처 설계": {
      "answer": "아키텍처 통합 시 고려 요소\n──────────────────────────\n1. 기존 두 모듈(WorkflowManager, Context-System)을 최대한 건드리지 않는다.  \n2. “작업 완료(complete)” 시점에만 컨텍스트를 저장·요약하도록 변경한다.  \n3. MCP(모델 컨텍스트 프로토콜) 환경에서 모듈 분리가 유지돼야 한다.  \n4. 테스트·롤백·점진적 도입이 용이해야 한다.\n\n비교 후보\n────────\nA. Decorator(래퍼) 패턴  \nB. Mixin(다중 상속) 구조  \nC. 단순 상속(Subclassing)  \n(+ 참고: Service/Coordinator 객체를 이용한 “구성(Composition)”)\n\n비교 항목별 정리\n──────────────\n1. 침습성(기존 코드 변경 범위)  \n2. 런타임 교체 용이성(Prod 에서 핫스왑)  \n3. 의존성 커플링 · 테스트 편의성  \n4. 중복 코드 / 유지 보수 난이도  \n5. MCP 환경 적합성(다중 인스턴스, 세션 분리)  \n\n| 항목                     | Decorator                             | Mixin                              | 상속(Subclass)                     |\n|--------------------------|---------------------------------------|------------------------------------|------------------------------------|\n| 침습성                   | 가장 낮음 – 원본 클래스 그대로 두고 래핑 | 중간 – 인스턴스 생성부 수정 필요     | 중간 – Mixin보다 덜 복잡하지만 동일 |\n| 기능 추가 범위           | 원하는 메서드만 intercept             | super() 체인 통해 손쉽게 확장       | override 해야 할 메서드 개수 증가    |\n| 런타임 교체              | 주입 지점만 바꾸면 교체 가능          | 생성부 교체 필요                    | 생성부 교체 필요                    |\n| 다중 상속 문제           | 없음                                  | MRO 충돌·Diamond Risk              | 없음                                |\n| 테스트/Mock 용이성       | 독립 객체라 단위 테스트 쉽다           | 다중 상속 구조 Mocking 번거로움      | 비슷하나 내부 상태 조작 필요        |\n| 코드 중복                | 약간(프록시 메서드 위임 or __getattr__) | 거의 없음                           | override 시 중복 불가피              |\n| MCP 세션 분리            | 데코레이터가 세션 오브젝트 보유 가능    | self 내부에 통합 – 구분 힘들 수 있음 | self 내부 – 동일 문제               |\n| 롤백/기존 버전 병행 운용 | 쉬움                                  | 상대적 어려움                       | 상대적 어려움                       |\n\n핵심 논점\n────────\n• “최소 변경” ↔ “장기 유지보수” 균형 점에서 Decorator(혹은 Coordinator+Composition)가 가장 유리.  \n• Mixin/상속은 모든 호출부에서 새 클래스를 인스턴스해야 하므로 CI/CD 파이프라인, 스크립트 등을 일괄 수정해야 한다.  \n• MCP 는 세션마다 여러 WorkflowManager 인스턴스를 유지할 수 있어야 하므로, 상태 보관 객체를 외부로 빼 두는 Decorator 구조가 테스트와 메모리 관리에 편리.  \n\n권장 아키텍처(Decorator + Composition)\n───────────────────────────────────\n1. 기존 WorkflowManager, ContextManager, SessionManager, ContextSummarizer 코드 무변경.  \n2. 새 파일 ai_helpers_new/workflow_context_bridge.py 생성.\n\n```python\n# workflow_context_bridge.py\nclass WorkflowWithContext:\n    \"\"\"\n    Decorator that augments WorkflowManager with context tracking\n    without altering original implementation.\n    \"\"\"\n    def __init__(\n        self,\n        wf_manager,\n        ctx_manager,\n        session_manager,\n        summarizer,\n        save_on=\"complete\"  # 확장 가능성\n    ):\n        self._wf  = wf_manager\n        self._ctx = ctx_manager\n        self._session = session_manager\n        self._summarizer = summarizer\n        self._save_on = save_on\n\n    # ---- Intercept points ------------------------------------\n    def complete(self, *args, **kwargs):\n        result = self._wf.complete(*args, **kwargs)\n        self._ctx.update_from_task(result)          # 컨텍스트 누적\n        if self._save_on == \"complete\":\n            self._session.save(self._ctx.snapshot())# 즉시 저장\n            self._summarizer.generate(self._ctx)    # 요약\n        return result\n\n    # ---- Pass-through for every other attribute --------------\n    def __getattr__(self, item):\n        # delegate everything else\n        return getattr(self._wf, item)\n```\n\n3. 인스턴스 주입 (애플리케이션 엔트리 포인트):\n\n```python\nfrom ai_helpers_new.workflow_manager import WorkflowManager\nfrom flow_project_v2.context import ContextManager, SessionManager, ContextSummarizer\nfrom ai_helpers_new.workflow_context_bridge import WorkflowWithContext\n\nwf  = WorkflowManager(state_file=\"workflow.json\")\nctx = ContextManager()\nsess = SessionManager(auto_save=False)            # 5분 타이머 OFF\nsumm = ContextSummarizer()\n\nwf_ctx = WorkflowWithContext(wf, ctx, sess, summ)\n```\n\n4. CLI 혹은 MCP 라우터가 기존 `WorkflowManager` 대신 `wf_ctx`를 노출하도록만 변경 → 나머지 호출부는 동일한 메서드 시그니처를 사용.\n\n5. 테스트·롤백\n   - Decorator 제거 = 객체 교체만으로 원래 로직 복구.\n   - 기능 플래그(feature toggle)로 wrapper 적용 여부 결정 가능.\n\n6. 향후 확장\n   • save_on 값에 \"start\", \"fail\", \"manual\" 등을 추가.  \n   • ContextSummarizer 를 비동기로 호출(스레드/TaskPool)해 주 스레드 블로킹 방지.  \n\n간단 코드 diff 예상\n───────────────\n• 신규 파일: workflow_context_bridge.py (~40 LOC)  \n• main 진입점: `WorkflowManager()` → `WorkflowWithContext(WorkflowManager(), …)` 한 줄 변경  \n⇒ 전체 리포지터리 변경 범위 < 2%  \n\n결론\n────\n- 최소 수정, 가장 낮은 리스크, 롤백 용이성을 중시한다면 Decorator(또는 외부 Coordinator) 방식이 최적.  \n- 이미 여러 곳에서 다중 상속을 사용하고 있고, 생성부를 단일 지점에서 제어할 수 있다면 Mixin도 가능하지만 MRO 및 의존성 꼬임에 주의.  \n- 단순 상속은 코드 중복과 의존 결합이 커 장기적으로 불리.  \n\n따라서 “WorkflowManager 래핑 + ContextBridge(Decorator)” 아키텍처를 권장합니다.",
      "reasoning_effort": "high",
      "usage": {
        "prompt_tokens": 286,
        "completion_tokens": 2848,
        "total_tokens": 3134,
        "reasoning_tokens": 0
      }
    },
    "명령어 체계 설계": {
      "answer": "🧭 디자인 원칙\n1. Top-level 명령어는 “대상(noun) → 동작(verb)” 순서를 유지한다.  \n   예) /task add, /task complete ⟶ /context show, /session save  \n2. 가능한 한 기존 동작어(add, list, show, complete, delete 등)를 재사용해 학습비용을 줄인다.  \n3. ‘상태 저장’은 사용자가 인지할 수 있는 시점(완료·저장·로드)을 명령어로 노출하고, 자동저장은 /complete 시점 Hook 으로만 실행한다.  \n4. /help <noun> 으로 세부 도움말을 일관되게 제공한다.\n\n────────────────────────\n제안 명령어 트리\n────────────────────────\n/task …          (기존과 동일)\n/context …\n    • /context show [id|current]     ─ 현재 또는 지정 컨텍스트 상세\n    • /context list [filter]         ─ 컨텍스트 목록\n    • /context summarize [scope]     ─ AI 요약(현재/전체/선택범위)\n    • /context delete <id>           ─ 컨텍스트 제거\n    • /context set-meta <id> <k=v>   ─ 메타데이터 수정(선택)\n\n/session …\n    • /session save [name]           ─ 즉시 저장 (기본이름: timestamp)\n    • /session load <name>           ─ 저장된 세션 불러오기\n    • /session list                  ─ 저장된 세션 목록\n    • /session delete <name>         ─ 세션 삭제\n\n/history …\n    • /history list [n|all]          ─ 최근 n개 또는 전체 작업 로그\n    • /history search \"<keyword>\"    ─ 키워드 검색\n    • /history clear                 ─ 로그 초기화(권한 체크)\n\n/status           (기존 유지) ─ 전체 워크플로우+컨텍스트 요약\n/help [noun]      (도움말)\n\n────────────────────────\n사용 예시\n────────────────────────\n1) 컨텍스트 확인  \n   /context show current\n\n2) 현재 컨텍스트 요약을 팀에게 공유  \n   /context summarize current\n\n3) 세션 저장 후 다른 세션으로 전환  \n   /session save sprint_demo  \n   /session load hotfix_23.05\n\n4) 완료 시 저장(자동 Hook)  \n   /task complete 42          ← 내부적으로 ContextManager.save_state() 호출\n\n────────────────────────\n통합 구현 포인트\n────────────────────────\n• WorkflowManager.dispatch() 에서 ‘noun’ 1단계 라우팅 추가  \n  (task/context/session/history/status/help).\n\n• /task complete Hook  \n  - 기존 로직 후 → ContextManager.save_state() 호출  \n  - Config.enable_auto_save = False, Hook 기반 저장만 수행.\n\n• /status 는 WorkflowManager 와 ContextSummarizer 을 모두 호출해\n  “작업 진행도 + 주요 컨텍스트 요약”을 단일 리포트로 반환.\n\n• /help <noun> 시\n  └─ 동적 Docstring/Parser 로 각 명령어 리스트와 예시 출력.\n\n이 구조를 적용하면\n• 기존 사용자에게 익숙한 패턴 유지  \n• 대상별 명확한 그룹핑으로 탐색성 향상  \n• 자동저장 과잉 호출 제거(UX 단순화)  \n• 향후 기능(예: /context diff, /session merge) 확장 시 일관성 보장.",
      "reasoning_effort": "medium",
      "usage": {
        "prompt_tokens": 294,
        "completion_tokens": 1099,
        "total_tokens": 1393,
        "reasoning_tokens": 0
      }
    },
    "이벤트 기반 저장 시스템": {
      "answer": "────────────────────────────────────────────\n1. 저장이 트리거-되는 이벤트\n────────────────────────────────────────────\n(“작업 완료 시점”을 지키면서, 장애·종료 상황에서의 유실도 방지)\n\n필수 이벤트\n• TaskCompleted            : 정상 완료\n• TaskFailed / TaskAborted : 오류·취소 등 “종료”가 확정된 순간\n\n보조 이벤트  (실제로 “작업 완료”에 해당하므로 요구사항과 충돌 없음)\n• BatchCompleted           : 여러 하위 task 를 한 번에 끝낼 때\n• GracefulShutdown         : MCP 가 SIGINT/SIGTERM 을 받았는데 아직 미저장 task 가 있을 때\n• ManualSave               : 운영자가 /save 나 /complete all 등 임의 호출\n\n이벤트 흐름\nWorkflowManager → EventBus (싱글톤) → ContextSaveListener → ContextManager.save()\n\n────────────────────────────────────────────\n2. 저장 실패 시 복구 전략\n────────────────────────────────────────────\n2-1. Atomic write + WAL\n① ContextManager.save()  \n   └─▶ tmp_file.json  작성  \n   └─▶ fsync()  \n   └─▶ rename(tmp_file, context.json) (원자적 교체)  \n② save 전에 변경 내역을 wal/20240613-120855.log 에 먼저 append  \n   → rename 성공 시 해당 WAL 삭제  \n   → rename 실패·프로세스 크래시 시 재기동 후 WAL 로 재적용\n\n2-2. Retry Queue\n• Listener 가 try/except 로 실패를 잡아 in-memory RetryQueue 에 enqueue  \n• 백그라운드 RetryWorker(쓰레드/async task)가 지수백오프(1s→2s→5s…)로 재시도  \n• 재시도  N 회 실패 → “context-unsaved-*.dump” 로 로컬 드롭, 슬랙 알림\n\n2-3. 프로세스 비정상 종료\n• 종료 직전 GracefulShutdown 이벤트 발생하지 못했을 경우\n  → 재기동 시  boot_recover():\n       a) context-unsaved-*.dump 존재 → 가장 최신 덤프 병합\n       b) wal/*.log 존재        → 순서대로 replay\n\n────────────────────────────────────────────\n3. 성능 영향 최소화 기법\n────────────────────────────────────────────\n비동기 & 배치\n• Listener 는 즉시 변경 스냅샷(딕셔너리)만 Queue 에 밀어 넣고 리턴  \n  → 실제 I/O 는 BackgroundWriter 가 수행\n\n증분(serialized-diff) 저장\n• ContextManager.diff(prev_state, new_state) 만 저장  \n• full snapshot 은 K(예: 50) 회 diff 저장 후 1회만 수행\n\n경량 포맷\n• JSON 대신 msgpack + zstd (8~10× 압축, 직렬화 3~5× 빠름)  \n• 파일 사이즈 감소 → I/O latency 감소\n\nLock 최소화\n• GIL 진입을 줄이기 위해 멀티프로세스 대신\n  ‑ asyncio.StreamWriter(ofloop) 또는  \n  ‑ Dedicated I/O thread + queue.SimpleQueue 사용\n\n픽링 피하기\n• 데이터 모델은 dataclass→asdict() 한 평범한 dict → serializer 바로 통과  \n  (pickle 대비 10배 이상 빠름, 안전성 ↑)\n\n────────────────────────────────────────────\n4. 간단한 구현 스케치\n────────────────────────────────────────────\n# event_bus.py\nclass EventBus:\n    _subs = defaultdict(list)\n    def subscribe(evt, fn): EventBus._subs[evt].append(fn)\n    def publish(evt, **payload):\n        for fn in EventBus._subs[evt]: fn(payload)\n\n# workflow_manager.py (일부)\ndef complete_task(self, task_id):\n    ...\n    EventBus.publish('TaskCompleted', task=self.tasks[task_id])\n\n# context_save_listener.py\nclass SaveListener:\n    def __init__(self, ctx_mgr, queue):\n        self.ctx_mgr, self.q = ctx_mgr, queue\n        for evt in ['TaskCompleted','TaskFailed','TaskAborted','GracefulShutdown']:\n            EventBus.subscribe(evt, self.enqueue)\n\n    def enqueue(self, payload):\n        snapshot = self.ctx_mgr.make_snapshot(payload['task'])\n        self.q.put(snapshot)\n\n# writer.py\nclass BackgroundWriter(Thread):\n    def run(self):\n        while True:\n            snap = self.q.get()\n            try: atomic_save(snap)\n            except Exception as e: retry_queue.put((snap, 0))\n\n# atomic_save()\ndef atomic_save(data):\n    tmp = PATH/'context.tmp'\n    with tmp.open('wb') as f: f.write(zstd.compress(msgpack.packb(data)))\n    tmp.flush(); os.fsync(f.fileno())\n    tmp.replace(PATH/'context.msgpack.zst')\n\n────────────────────────────────────────────\n요약\n1. 저장 트리거: TaskCompleted / Failed / Aborted + 종료 시 미저장 내역 + 수동 호출  \n2. 복구: WAL, RetryQueue, Crash-Dump 재적용으로 0-시점 복구 보장  \n3. 성능: 비동기 처리, 증분 저장, 압축 포맷으로 작업 완료 경로에 대한 I/O 오버헤드 < 2–3 ms\n\n이렇게 하면 “작업 완료 시점”이라는 요구를 지키면서도 안정성·성능을 모두 확보할 수 있습니다.",
      "reasoning_effort": "medium",
      "usage": {
        "prompt_tokens": 281,
        "completion_tokens": 1812,
        "total_tokens": 2093,
        "reasoning_tokens": 0
      }
    },
    "호환성 전략": {
      "answer": "기존 사용자가 아무 변화-없이 WorkflowManager만 계속 쓸 수 있고, 필요할 때만 Flow Project v2 Context System을 “켜서” 쓰게 하려면 “토글(Feature Toggle)” 계층을 하나 두고, 세 가지 진입점을 마련하면 됩니다.\n\n1) 런타임 오버라이드(환경 변수)\n2) 사용자·프로젝트 단위 설정 파일\n3) 코드 레벨 기본값(하드코딩) ‑ 테스트·CI에서 편리\n\n아래에서 각 옵션의 장단점, 권장 조합, 예시 코드를 순서대로 설명합니다.\n\n────────────────\n1. 환경 변수 기반 토글\n────────────────\n언제 쓰나  \n• 컨테이너, CI/CD, 서버리스 환경처럼 “배포된 바이너리 그대로 두고 실행 시점에만 바꾸고 싶을 때”  \n• 깃 분기나 이미지 재배포 없이 실험·롤백을 자주 할 때\n\n예시  \nCONTEXT_SYSTEM=on  (켜기)  \nCONTEXT_SYSTEM=off (끄기)\n\n장점  \n• 가장 빠르고 간단: export 한 줄, docker run ‑e …  \n• 운영 중 *에러나 장애* 발생 시 즉시 off 가능  \n단점  \n• 로컬 사용자는 매번 셸에 설정해야 함  \n• IDE·윈도우 사용자는 번거로움\n\n────────────────\n2. 설정 파일 기반 토글\n────────────────\n언제 쓰나  \n• 프로젝트(깃 리포) 별로 기본값을 주고 싶을 때  \n• 다수 사용자가 하나의 코드베이스를 공유하지만, 각자 켜고 끌 수 있어야 할 때  \n• 사용자 명령(/setup, /config)로 쉽게 수정되길 원할 때\n\n예시 (workflow_config.yaml)  \nfeature_flags:  \n  context_system: false     # 기본값 off\n\n장점  \n• git 에 버전 관리 → 변경 이력 추적, PR 리뷰 가능  \n• 사용자는 파일 하나만 건드리면 됨; IDE 친화적  \n단점  \n• 설정 파일 파싱 코드 추가 필요  \n• 실행 경로가 바뀌면 찾기 어렵다 → 절대경로 or XDG 규칙 추천\n\n────────────────\n3. 코드 레벨 · 디폴트 상수\n────────────────\n언제 쓰나  \n• 새 기능을 배포 전까지 완전히 숨기고 싶을 때  \n• 테스트 코드에서만 강제 on/off 할 때\n\n예시 (workflow_manager.py)  \nDEFAULT_CONTEXT_ENABLED = False\n\n장점  \n• 가장 확실히 “off”된 상태로 배포 가능  \n단점  \n• 값 변경하려면 재배포 or 브랜치 필요  \n• 운영 단계에서 토글로 활용하기엔 유연성 부족\n\n────────────────\n권장 구조: “3단 우선순위 병행”\n────────────────\n1. 코드(컴파일-타임) 기본값  \n2. 설정 파일 값(있으면 덮어씀)  \n3. 환경 변수 값(가장 우선)  \n\n즉, defaults → config → env 순.  \n이렇게 하면  \n• 새 릴리스의 안전한 기본값을 코드에 하드코딩(FALSE)  \n• 조직/프로젝트 표준 세팅은 config 파일로 관리  \n• 특별 상황(실험·비상)에서는 env 변수가 모든 것을 덮어쓴다.\n\n────────────────\n간단 구현 스케치\n────────────────\n# python/ai_helpers_new/feature_flags.py\nimport os\nimport yaml\nfrom pathlib import Path\n\nDEFAULTS = {\n    \"context_system\": False\n}\n\ndef _load_config_file():\n    cfg_path = Path.cwd() / \"workflow_config.yaml\"\n    if not cfg_path.exists():\n        return {}\n    with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n        return yaml.safe_load(f) or {}\n\ndef is_context_enabled():\n    # 1) 기본값\n    enabled = DEFAULTS[\"context_system\"]\n\n    # 2) 설정 파일\n    file_cfg = _load_config_file()\n    enabled = file_cfg.get(\"feature_flags\", {}).get(\"context_system\", enabled)\n\n    # 3) 환경 변수 최종 오버라이드\n    env = os.getenv(\"CONTEXT_SYSTEM\")\n    if env is not None:\n        enabled = env.lower() in (\"1\", \"true\", \"yes\", \"on\")\n    return enabled\n\n그다음 기존 WorkflowManager 내부에서 다음처럼 분기 처리.\n\nfrom feature_flags import is_context_enabled\n\nclass WorkflowManager:\n    ...\n    def complete_task(self, task_id):\n        ...\n        if is_context_enabled():\n            ContextManager.save_current_state()\n        ...\n\n────────────────\n자동저장 주기 변경 반영\n────────────────\n요구사항: “5분 저장은 과하고, task 완료 시만 저장”  \n위 토글가드 뒤에서 Context System 안쪽 구현을 다음처럼 바꾸면 됨.\n\nclass ContextManager:\n    def save_current_state(self):\n        SessionManager.save()  # 즉시 저장\n    # 더 이상 5분 타이머 X\n\n────────────────\n운영/배포 예시\n────────────────\n• 로컬 사용자는 config 파일 켜고 끌기  \n  $ sed -i 's/context_system: false/context_system: true/' workflow_config.yaml\n\n• 개발 브랜치에서 자동 켜기  \n  export CONTEXT_SYSTEM=on; pytest\n\n• 프로덕션 서버에서 기본 off 두고, canary 5%만 on  \n  k8s Deployment → env: CONTEXT_SYSTEM=on (per pod)\n\n────────────────\n요약\n────────────────\n1. 3-단계(코드 기본값 → 설정 파일 → 환경 변수)로 토글 가드를 만든다.  \n2. 기존 사용자에게는 아무 것도 설정하지 않으면 그대로 WorkflowManager만 동작한다.  \n3. Context System을 키면, 5분 타이머를 제거하고 task 완료 시점에 SessionManager.save() 호출해서 요구사항도 충족한다.",
      "reasoning_effort": "low",
      "usage": {
        "prompt_tokens": 278,
        "completion_tokens": 1285,
        "total_tokens": 1563,
        "reasoning_tokens": 0
      }
    }
  },
  "task_count": 5
}