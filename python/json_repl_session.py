#!/usr/bin/env python
# -*- coding: utf-8 -*-


"""
ğŸš€ JSON REPL Session for AI Coding Brain v6.0
==============================================

# ì•ˆì „í•œ ì‹¤í–‰ í—¬í¼ (êµ¬ë¬¸ ê²€ì‚¬ í¬í•¨)
try:
    from safe_exec_helpers import enhanced_safe_exec, quick_syntax_check
    SAFE_EXEC_AVAILABLE = True
except ImportError:
    enhanced_safe_exec = None
    quick_syntax_check = None
    SAFE_EXEC_AVAILABLE = False


Claude Desktopê³¼ í†µì‹ í•˜ëŠ” í†µí•© JSON REPL ì„¸ì…˜
- AI Helpers v2 ì™„ì „ í†µí•©
- Workflow ì‹œìŠ¤í…œ í†µí•©
- ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë³´í˜¸ (AIHelpers í´ë˜ìŠ¤)
- ìµœì†Œ ì˜ì¡´ì„±, í•µì‹¬ ê¸°ëŠ¥ë§Œ ìœ ì§€

ì‘ì„±ì¼: 2025-07-15
"""

import sys
import os

# Windowsì—ì„œ UTF-8 ì¶œë ¥ ê°•ì œ ì„¤ì •
if sys.platform == 'win32':
    import locale
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')
    os.environ['PYTHONIOENCODING'] = 'utf-8'

import json
import io
import traceback
import time
import datetime as dt
import platform
import subprocess
import builtins
from pathlib import Path
from typing import Dict, Any, Optional
from contextlib import contextmanager

# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •


# Enhanced Safe Execution v2 - f-string ë° ì •ê·œì‹ ì•ˆì „ì„± ê²€ì‚¬
try:
    from safe_execution_v2 import (
        safe_exec as safe_exec_v2,
        check_regex,
        benchmark_regex_safety
    )
    SAFE_EXEC_V2_AVAILABLE = True
except ImportError:
    SAFE_EXEC_V2_AVAILABLE = False
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# AI Helpers v2 í†µí•©
try:
    from ai_helpers_v2 import (
        # File operations
        read_file, write_file, create_file, file_exists, append_to_file,
        read_json, write_json,
        # Search operations
        search_code, search_files, grep, find_function, find_class,
        # Code operations
        parse_with_snippets, insert_block, replace_block,
        # Git operations
        git_status, git_add, git_commit, git_branch, git_push, git_pull,
        # Project operations
        get_current_project, scan_directory_dict, create_project_structure,
        # Core operations
        get_metrics, clear_cache, get_execution_history
    )
    AI_HELPERS_V2_LOADED = True
    print("âœ… AI Helpers v2 ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ AI Helpers v2 ë¡œë“œ ì‹¤íŒ¨: {e}")
    AI_HELPERS_V2_LOADED = False



# ì‹¤í–‰ ì„¤ì •
CONFIG = {
    'use_safe_exec_v2': True,      # Enhanced Safe Execution v2 ì‚¬ìš©
    'fstring_check': True,         # f-string ë¯¸ì •ì˜ ë³€ìˆ˜ ê²€ì‚¬
    'regex_check': True,           # ì •ê·œì‹ ì•ˆì „ì„± ê²€ì‚¬
    'redos_protection': True,      # ReDoS íŒ¨í„´ ê²½ê³ 
    'show_warnings': True,         # ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ
}

# ============================================================================
# ğŸŒŸ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
# ============================================================================
repl_globals = {}  # REPL ì „ì—­ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
execution_count = 0  # ì‹¤í–‰ ì¹´ìš´í„°

class AIHelpersV2:
    """AI Helpers v2 í†µí•© ë˜í¼ - Workflow ì‹œìŠ¤í…œ í¬í•¨"""
    
    def __init__(self):
        """AI Helpers v2 ë©”ì„œë“œë“¤ì„ í†µí•©"""
        if not AI_HELPERS_V2_LOADED:
            print("âš ï¸ AI Helpers v2ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return
        
        # ì˜ì†ì  íˆìŠ¤í† ë¦¬ ë§¤ë‹ˆì € ì¶”ê°€
        self._history_manager = None
            
        # File operations
        self.read_file = read_file
        self.write_file = write_file
        self.create_file = create_file
        self.file_exists = file_exists
        self.exists = file_exists  # ë³„ì¹­
        self.append_to_file = append_to_file
        self.read_json = read_json
        self.write_json = write_json
        
        # Search operations
        self.search_code = search_code
        self.search_files = search_files
        self.search_in_files = search_code  # ë³„ì¹­
        self.grep = grep
        self.find_function = find_function
        self.find_class = find_class
        
        # Code operations
        self.parse_with_snippets = parse_with_snippets
        self.insert_block = insert_block
        self.replace_block = replace_block
        
        # Git operations
        self.git_status = git_status
        self.git_add = git_add
        self.git_commit = git_commit
        self.git_branch = git_branch
        self.git_push = git_push
        self.git_pull = git_pull
        
        # Project operations
        self.get_current_project = get_current_project
        self.scan_directory_dict = scan_directory_dict
        self.create_project_structure = create_project_structure
        
        # Core operations
        self.get_metrics = get_metrics
        self.clear_cache = clear_cache
        self.get_execution_history = get_execution_history
        
        # flow_project êµ¬í˜„
        self.flow_project = self._flow_project
        self.cmd_flow_with_context = self._flow_project  # ë³„ì¹­
        
        # Workflow ì‹œìŠ¤í…œ í†µí•©
        self.execute_workflow_command = self._execute_workflow_command
        self.get_workflow_status = self._get_workflow_status

        # workflow ë©”ì„œë“œ ë³„ì¹­ ì¶”ê°€
        def workflow(command=None, *args, **kwargs):
            if command:
                return self._execute_workflow_command(command, *args, **kwargs)
            else:
                return self._get_workflow_status()
        self.workflow = workflow
        self.update_file_directory = self._update_file_directory
        


        # LLM operations (llm_ops)
        try:
            from ai_helpers_v2.llm_ops import (
                ask_o3, analyze_code, explain_error, generate_docstring
            )
            self.ask_o3 = ask_o3
            self.analyze_code = analyze_code
            self.explain_error = explain_error
            self.generate_docstring = generate_docstring
        except ImportError:
            pass
        
        # Workflow ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self._workflow_manager = None
        
        # íˆìŠ¤í† ë¦¬ ê´€ë ¨ ë©”ì„œë“œ ì¶”ê°€
        self.add_history_action = self._add_history_action
        self.get_history = self._get_history
        self.continue_from_last = self._continue_from_last
        self.show_history = self._show_history
        
        # í”„ë¡œì íŠ¸ ê´€ë¦¬ ë©”ì„œë“œ ì¶”ê°€
        self.list_desktop_projects = self._list_desktop_projects
        self.get_project_info = self._get_project_info
        
    def _add_history_action(self, action, details=None, data=None):
        """íˆìŠ¤í† ë¦¬ì— ì•¡ì…˜ ì¶”ê°€ (ì˜ì†ì  ì €ì¥)"""
        if self._history_manager is None:
            self._init_history_manager()
        return self._history_manager.add_action(action, details, data)
    
    def _get_history(self, limit=None):
        """íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        if self._history_manager is None:
            self._init_history_manager()
        history = self._history_manager._load_history()
        if limit:
            return history[-limit:] if len(history) > limit else history
        return history
    
    def _continue_from_last(self):
        """ë§ˆì§€ë§‰ ì‘ì—…ì—ì„œ ì´ì–´ì„œ ì‹œì‘"""
        if self._history_manager is None:
            self._init_history_manager()
        return self._history_manager.continue_from_last()
    
    def _show_history(self, limit=10):
        """íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
        if self._history_manager is None:
            self._init_history_manager()
        self._history_manager.show_history(limit)
    
    def _init_history_manager(self):
        """íˆìŠ¤í† ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        from persistent_history import PersistentHistoryManager
        self._history_manager = PersistentHistoryManager()
    
    def _list_desktop_projects(self):
        """ë°”íƒ•í™”ë©´ì˜ í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ"""
        from pathlib import Path
        desktop = Path.home() / "Desktop"
        projects = []
        
        for item in desktop.iterdir():
            if item.is_dir() and (item / "memory").exists():
                # í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° í™•ì¸
                project_json = item / "memory" / "project.json"
                if project_json.exists():
                    try:
                        import json
                        with open(project_json, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                            projects.append({
                                "name": item.name,
                                "path": str(item),
                                "created": metadata.get("created_at", "Unknown"),
                                "type": metadata.get("type", "unknown")
                            })
                    except:
                        # project.jsonì´ ì—†ì–´ë„ memory í´ë”ê°€ ìˆìœ¼ë©´ í”„ë¡œì íŠ¸ë¡œ ê°„ì£¼
                        projects.append({
                            "name": item.name,
                            "path": str(item),
                            "created": "Unknown",
                            "type": "legacy"
                        })
        
        return projects
    
    def _get_project_info(self, project_name=None):
        """í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ"""
        from pathlib import Path
        
        if project_name is None:
            # í˜„ì¬ í”„ë¡œì íŠ¸ ì •ë³´
            project_path = Path.cwd()
            project_name = project_path.name
        else:
            # íŠ¹ì • í”„ë¡œì íŠ¸ ì •ë³´
            project_path = Path.home() / "Desktop" / project_name
            if not project_path.exists():
                return None
        
        memory_path = project_path / "memory"
        if not memory_path.exists():
            return None
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
        total_size = 0
        file_count = 0
        for file in memory_path.rglob("*"):
            if file.is_file():
                total_size += file.stat().st_size
                file_count += 1
        
        # ì›Œí¬í”Œë¡œìš° ìƒíƒœ í™•ì¸
        workflow_file = memory_path / "workflow.json"
        has_active_workflow = False
        if workflow_file.exists():
            try:
                import json
                with open(workflow_file, 'r', encoding='utf-8') as f:
                    workflow_data = json.load(f)
                    has_active_workflow = bool(workflow_data.get("active_plan_id"))
            except:
                pass
        
        return {
            "name": project_name,
            "path": str(project_path),
            "memory_files": file_count,
            "memory_size_kb": total_size / 1024,
            "has_workflow": workflow_file.exists(),
            "has_active_workflow": has_active_workflow,
            "has_history": (memory_path / "workflow_history.json").exists()
        }
        
    def _flow_project(self, project_name, desktop=True):
        """í”„ë¡œì íŠ¸ ì „í™˜ ë° ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ (ë°”íƒ•í™”ë©´ ê¸°ë°˜)"""
        import json
        from datetime import datetime
        from pathlib import Path
        
        try:
            # ë°”íƒ•í™”ë©´ ë˜ëŠ” í•˜ìœ„ í”„ë¡œì íŠ¸ ê²½ë¡œ ê²°ì •
            if desktop:
                # ë°”íƒ•í™”ë©´ì— í”„ë¡œì íŠ¸ ìƒì„± (ê¸°ë³¸ê°’)
                project_path = Path.home() / "Desktop" / project_name
            else:
                # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í”„ë¡œì íŠ¸)
                projects_dir = Path("projects")
                projects_dir.mkdir(exist_ok=True)
                project_path = projects_dir / project_name
            
            # í˜„ì¬ í”„ë¡œì íŠ¸ ë°±ì—… (í”„ë¡œì íŠ¸ë³„ memoryì— ì €ì¥)
            if hasattr(self, 'get_current_project'):
                current = self.get_current_project()
                if current and current.get('name'):
                    current_memory = Path(current['path']) / "memory"
                    if current_memory.exists():
                        # í˜„ì¬ ì›Œí¬í”Œë¡œìš° ë°±ì—…
                        current_workflow = Path("memory/workflow.json")
                        if current_workflow.exists():
                            backup_path = current_memory / "workflow_backup.json"
                            import shutil
                            shutil.copy2(current_workflow, backup_path)
                            print(f"ğŸ’¾ ì›Œí¬í”Œë¡œìš° ë°±ì—…: {backup_path}")
            
            # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
            is_new = not project_path.exists()
            if is_new:
                print(f"ğŸ†• ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±: {project_name}")
                project_path.mkdir(parents=True, exist_ok=True)
                
                # ê¸°ë³¸ êµ¬ì¡° ìƒì„±
                (project_path / "src").mkdir(exist_ok=True)
                (project_path / "docs").mkdir(exist_ok=True)
                (project_path / "tests").mkdir(exist_ok=True)
                (project_path / "memory").mkdir(exist_ok=True)
                (project_path / "memory" / "checkpoints").mkdir(exist_ok=True)
                
                # README ìƒì„±
                readme_content = f"""# {project_name}

Created: {datetime.now().strftime('%Y-%m-%d %H:%M')}
Location: {"Desktop" if desktop else "Subproject"}

## Structure
- `src/` - Source code
- `docs/` - Documentation  
- `tests/` - Test files
- `memory/` - Project memory and state
  - `workflow.json` - Current workflow
  - `workflow_history.json` - Action history
  - `checkpoints/` - State snapshots
"""
                (project_path / "README.md").write_text(readme_content, encoding='utf-8')
                
                # í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„°
                metadata = {
                    "project_name": project_name,
                    "created_at": datetime.now().isoformat(),
                    "path": str(project_path),
                    "type": "desktop" if desktop else "subproject"
                }
                
                (project_path / "memory" / "project.json").write_text(
                    json.dumps(metadata, indent=2), encoding='utf-8'
                )
            else:
                print(f"ğŸ“‚ ê¸°ì¡´ í”„ë¡œì íŠ¸ë¡œ ì „í™˜: {project_name}")

                # ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ ê²½ìš° project_context.jsonì„ ë¨¼ì € í‘œì‹œ
                context_file = project_path / "memory" / "project_context.json"
                if context_file.exists():
                    try:
                        with open(context_file, 'r', encoding='utf-8') as f:
                            project_context = json.load(f)

                        print(f"\nğŸ“Š í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì •ë³´:")
                        print(f"  - ë¶„ì„ì¼ì‹œ: {project_context.get('analyzed_at', 'N/A')}")
                        print(f"  - í”„ë¡œì íŠ¸ íƒ€ì…: {project_context.get('project_type', 'N/A')}")

                        tech_stack = project_context.get('tech_stack', [])
                        if tech_stack:
                            print(f"  - ê¸°ìˆ  ìŠ¤íƒ: {', '.join(tech_stack)}")

                        structure = project_context.get('structure', {})
                        if structure:
                            print(f"  - ì „ì²´ íŒŒì¼: {structure.get('total_files', 0)}ê°œ")
                            print(f"  - ì†ŒìŠ¤ íŒŒì¼: {structure.get('source_files', 0)}ê°œ")
                            print(f"  - í…ŒìŠ¤íŠ¸ íŒŒì¼: {structure.get('test_files', 0)}ê°œ")
                    except Exception as e:
                        print(f"  âš ï¸ project_context.json ë¡œë“œ ì˜¤ë¥˜: {e}")
            
            # ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½
            os.chdir(str(project_path))
            
            # í”„ë¡œì íŠ¸ë³„ memory ë””ë ‰í† ë¦¬ í™•ì¸
            memory_dir = Path("memory")
            memory_dir.mkdir(exist_ok=True)
            
            # í”„ë¡œì íŠ¸ë³„ ì›Œí¬í”Œë¡œìš° ë¡œë“œ
            project_workflow = memory_dir / "workflow.json"
            if project_workflow.exists():
                # ì „ì—­ memory í´ë”ë¡œ ë³µì‚¬ (í˜¸í™˜ì„± ìœ ì§€)
                global_memory = Path("memory")
                if not global_memory.samefile(memory_dir):
                    global_memory.mkdir(exist_ok=True)
                    import shutil
                    shutil.copy2(project_workflow, global_memory / "workflow.json")
                print(f"âœ… í”„ë¡œì íŠ¸ ì›Œí¬í”Œë¡œìš° ë¡œë“œ")
            
            # ì›Œí¬í”Œë¡œìš°/íˆìŠ¤í† ë¦¬ ë§¤ë‹ˆì € ì¬ì´ˆê¸°í™”
            self._workflow_manager = None
            self._history_manager = None
            
            # ë¶„ì„ íŒŒì¼ í™•ì¸ ë° ì œì•ˆ (ìƒˆ í”„ë¡œì íŠ¸ì¼ ë•Œë§Œ)
            if is_new:
                analysis_files = {
                    "file_directory.md": project_path / "file_directory.md",
                    "project_context": project_path / "memory" / "project_context.json"
                }

                missing_files = []
                for name, filepath in analysis_files.items():
                    if not filepath.exists():
                        missing_files.append(name)

                if missing_files:
                    print(f"\nâš ï¸ ë‹¤ìŒ ë¶„ì„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤:")
                    for file in missing_files:
                        print(f"  - {file}")
                    print(f"\nğŸ’¡ í”„ë¡œì íŠ¸ ë¶„ì„ì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                    print(f"   ğŸ‘‰ helpers.workflow('/a') ë˜ëŠ” /a ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
                    print(f"   - file_directory.md ìƒì„±/ì—…ë°ì´íŠ¸")
                    print(f"   - project_context.json ìƒì„±")
                    print(f"   - í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„")
            
            # project_context.json ë¡œë“œ ë° í‘œì‹œ (ìƒˆ í”„ë¡œì íŠ¸ì¼ ë•Œë§Œ)
            if is_new and "project_context" in locals() and analysis_files["project_context"].exists():
                try:
                    with open(analysis_files["project_context"], 'r', encoding='utf-8') as f:
                        project_context = json.load(f)

                    print(f"\nğŸ“Š í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì •ë³´:")
                    print(f"  - ë¶„ì„ì¼ì‹œ: {project_context.get('analyzed_at', 'N/A')}")
                    print(f"  - í”„ë¡œì íŠ¸ íƒ€ì…: {project_context.get('project_type', 'N/A')}")

                    tech_stack = project_context.get('tech_stack', [])
                    if tech_stack:
                        print(f"  - ê¸°ìˆ  ìŠ¤íƒ: {', '.join(tech_stack)}")

                    structure = project_context.get('structure', {})
                    if structure:
                        print(f"  - ì „ì²´ íŒŒì¼: {structure.get('total_files', 0)}ê°œ")
                        print(f"  - ì†ŒìŠ¤ íŒŒì¼: {structure.get('source_files', 0)}ê°œ")
                        print(f"  - í…ŒìŠ¤íŠ¸ íŒŒì¼: {structure.get('test_files', 0)}ê°œ")

                except Exception as e:
                    print(f"  âš ï¸ project_context.json ë¡œë“œ ì˜¤ë¥˜: {e}")

            # í”„ë¡œì íŠ¸ ë¬¸ì„œ ë¡œë“œ
            project_docs = self._load_project_docs(project_path)
            
            print(f"\nâœ… í”„ë¡œì íŠ¸ '{project_name}'ë¡œ ì „í™˜ ì™„ë£Œ!")
            print(f"ğŸ“ ê²½ë¡œ: {project_path.absolute()}")
            print(f"ğŸ’¾ ëª¨ë“  ë°ì´í„°ëŠ” {project_path}/memory/ì— ì €ì¥ë©ë‹ˆë‹¤")
            
            if project_docs['loaded']:
                print(f"ğŸ“„ í”„ë¡œì íŠ¸ ë¬¸ì„œ ë¡œë“œë¨: {', '.join(project_docs['files'])}")

            # ìë™ í”„ë¡œì íŠ¸ ì •ë³´ í‘œì‹œ
            print("\n" + "="*60)
            print("ğŸ“Š í”„ë¡œì íŠ¸ ì •ë³´ ìë™ ë¶„ì„")
            print("="*60)

            # 1. í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´
            try:
                if hasattr(self, 'pi'):
                    info = self.pi()
                    if info:
                        print("\nğŸ“‹ í”„ë¡œì íŠ¸ ìƒíƒœ:")
                        print(f"  - ë©”ëª¨ë¦¬ íŒŒì¼: {info.get('memory_files', 0)}ê°œ")
                        print(f"  - ë©”ëª¨ë¦¬ í¬ê¸°: {info.get('memory_size_kb', 0)/1024:.2f} MB")
                        print(f"  - í™œì„± ì›Œí¬í”Œë¡œìš°: {info.get('has_active_workflow', False)}")
            except:
                pass

            # 2. ì›Œí¬í”Œë¡œìš° ìƒíƒœ (ê°„ë‹¨íˆ)
            try:
                if hasattr(self, '_workflow_manager') and self._workflow_manager:
                    from .workflow.improved_manager import WorkflowStatus
                    status = self._workflow_manager.get_status()
                    if status:
                        print(f"\nğŸ“Š ì›Œí¬í”Œë¡œìš°: {status.get('project_name', 'N/A')}")
                        print(f"  - ì‘ì—…: {status.get('total_tasks', 0)}ê°œ (ì™„ë£Œ: {status.get('completed_tasks', 0)}ê°œ)")
            except:
                pass

            # 3. ìµœê·¼ íˆìŠ¤í† ë¦¬ (ê°„ë‹¨íˆ)
            try:
                if hasattr(self, '_history_manager') and self._history_manager:
                    history = self._history_manager.get_history(limit=3)
                    if history:
                        print("\nğŸ“œ ìµœê·¼ ì‘ì—…:")
                        for item in history[:3]:
                            print(f"  - {item.get('name', 'N/A')}")
            except:
                pass

            # 4. README ì²« ì¤„
            try:
                readme_path = project_path / "README.md"
                if readme_path.exists():
                    readme = readme_path.read_text(encoding='utf-8')
                    first_line = readme.split('\n')[0].strip()
                    if first_line:
                        print(f"\nğŸ“„ {first_line}")
            except:
                pass

            print("\nğŸš€ í”„ë¡œì íŠ¸ ì¤€ë¹„ ì™„ë£Œ!")
            print("="*60)

            return {
                "success": True,
                "project_name": project_name,
                "path": str(project_path.absolute()),
                "is_new": is_new,
                "type": "desktop" if desktop else "subproject",
                "docs": project_docs
            }
            
        except Exception as e:
            print(f"âŒ flow_project ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}
    
    def _load_project_docs(self, project_path: Path) -> dict:
        """í”„ë¡œì íŠ¸ ë¬¸ì„œ(README.md, file_directory.md) ë¡œë“œ"""
        docs = {
            "loaded": False,
            "files": [],
            "readme": None,
            "file_directory": None,
            "parsed_tree": None,
            "project_context": None
        }
        
        try:
            # README.md ì½ê¸°
            readme_path = project_path / "README.md"
            if readme_path.exists():
                docs["readme"] = self.read_file(str(readme_path))
                docs["files"].append("README.md")
            
            # file_directory.md ì½ê¸°
            file_dir_path = project_path / "file_directory.md"
            if file_dir_path.exists():
                docs["file_directory"] = self.read_file(str(file_dir_path))
                docs["files"].append("file_directory.md")
                
                # êµ¬ì¡° íŒŒì‹± ì‹œë„
                try:
                    from workflow_helper import parse_file_directory_md
                    docs["parsed_tree"] = parse_file_directory_md(docs["file_directory"])
                except Exception as e:
                    print(f"âš ï¸ íŒŒì¼ êµ¬ì¡° íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            docs["loaded"] = len(docs["files"]) > 0
            
            # ì „ì—­ ë³€ìˆ˜ì— ì €ì¥ (ì‰¬ìš´ ì ‘ê·¼ì„ ìœ„í•´)
            if docs["loaded"]:
                repl_globals["project_docs"] = docs
                
        except Exception as e:
            print(f"âš ï¸ í”„ë¡œì íŠ¸ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return docs
    
    def _update_file_directory(self, project_path: str):
        """file_directory.md ì—…ë°ì´íŠ¸"""
        from datetime import datetime
        
        content = [
            f"# File Directory - {os.path.basename(project_path)}",
            f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            ""
        ]
        
        # scan_directory_dict ì‚¬ìš©í•˜ì—¬ ì¬ê·€ì  ìŠ¤ìº”
        def scan_recursive(path: str, level: int = 0):
            scan_result = self.scan_directory_dict(path)
            indent = "  " * level
            
            # íŒŒì¼ë“¤
            for file in sorted(scan_result.get('files', [])):
                content.append(f"{indent}â”œâ”€â”€ {file}")
            
            # í•˜ìœ„ ë””ë ‰í† ë¦¬ë“¤
            dirs = sorted(scan_result.get('directories', []))
            for i, dir_name in enumerate(dirs):
                if not dir_name.startswith('.'):
                    is_last = (i == len(dirs) - 1)
                    prefix = "â””â”€â”€" if is_last else "â”œâ”€â”€"
                    content.append(f"{indent}{prefix} {dir_name}/")
                    subdir_path = os.path.join(path, dir_name)
                    scan_recursive(subdir_path, level + 1)
        
        scan_recursive(project_path)
        
        file_path = os.path.join(project_path, 'file_directory.md')
        self.create_file(file_path, "\n".join(content))
    
    def _backup_current_context(self):
        """í˜„ì¬ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë°±ì—…"""
        try:
            current_project = self.get_current_project()
            if not current_project or not current_project.get('name'):
                return
            
            backup_data = {
                'project': current_project['name'],
                'timestamp': dt.datetime.now().isoformat(),
                'session_data': {
                    'execution_count': execution_count,
                    'variables': len(repl_globals)
                }
            }
            
            backup_dir = os.path.join(os.getcwd(), 'memory', 'backups')
            if not os.path.exists(backup_dir):
                os.makedirs(backup_dir, exist_ok=True)
            
            backup_file = os.path.join(backup_dir, f"backup_{current_project['name']}_{int(time.time())}.json")
            self.write_json(backup_file, backup_data)
            print(f"ğŸ’¾ í”„ë¡œì íŠ¸ ë°±ì—… ì™„ë£Œ: {backup_file}")
        except Exception as e:
            print(f"âš ï¸ ë°±ì—… ì‹¤íŒ¨: {e}")
    
    def _execute_workflow_command(self, command: str):
        """ì›Œí¬í”Œë¡œìš° ëª…ë ¹ ì‹¤í–‰"""
        try:
            # dispatcherë¥¼ í†µí•´ ëª…ë ¹ ì‹¤í–‰
            from workflow.dispatcher import execute_workflow_command as dispatch_command
            result_message = dispatch_command(command)
            
            # ì„±ê³µ/ì‹¤íŒ¨ íŒë‹¨
            if result_message.startswith("Error:"):
                return result_message
            else:
                # íˆìŠ¤í† ë¦¬ì— ê¸°ë¡
                if self._history_manager is None:
                    self._init_history_manager()
                
                # ì›Œí¬í”Œë¡œìš° ëª…ë ¹ì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                action_data = {
                    "command": command,
                    "result": result_message
                }
                self._history_manager.add_action(
                    f"ì›Œí¬í”Œë¡œìš° ëª…ë ¹: {command.split()[0]}",
                    result_message,
                    action_data
                )
                
                return result_message
                
        except Exception as e:
            return f"Error: {str(e)}"
    
    def _get_workflow_status(self):
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì¡°íšŒ"""
        try:
            if self._workflow_manager is None:
                from workflow.improved_manager import ImprovedWorkflowManager
                project_name = self.get_current_project().get('name', 'default')
                self._workflow_manager = ImprovedWorkflowManager(project_name)
            
            return self._workflow_manager.get_status()
        except Exception as e:
            return {"status": "error", "message": str(e)}
    
    def _not_implemented(self, *args, **kwargs):
        """êµ¬í˜„ë˜ì§€ ì•Šì€ ë©”ì„œë“œ"""
        return None
    
    def __getattr__(self, name):
        """ë™ì  ì†ì„± ì ‘ê·¼ - í˜¸í™˜ì„±ì„ ìœ„í•´"""
        if AI_HELPERS_V2_LOADED:
            # v2 ëª¨ë“ˆì—ì„œ ì°¾ê¸°
            for module in ['file_ops', 'search_ops', 'code_ops', 'git_ops', 'project_ops', 'llm_ops', 'core']:
                module_name = f'ai_helpers_v2.{module}'
                if module_name in sys.modules:
                    module_obj = sys.modules[module_name]
                    if hasattr(module_obj, name):
                        return getattr(module_obj, name)
        
        # ê¸°ë³¸ ë™ì‘
        def not_implemented(*args, **kwargs):
            print(f"âš ï¸ {name} ë©”ì„œë“œëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
        return not_implemented
    
    def __dir__(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ì„œë“œ ëª©ë¡"""
        base_attrs = list(self.__dict__.keys())
        if AI_HELPERS_V2_LOADED:
            # v2 ëª¨ë“ˆì˜ ëª¨ë“  ê³µê°œ í•¨ìˆ˜ ì¶”ê°€
            for module in ['file_ops', 'search_ops', 'code_ops', 'git_ops', 'project_ops', 'core']:
                module_name = f'ai_helpers_v2.{module}'
                if module_name in sys.modules:
                    module_obj = sys.modules[module_name]
                    base_attrs.extend([
                        attr for attr in dir(module_obj) 
                        if not attr.startswith('_') and callable(getattr(module_obj, attr))
                    ])
        # Workflow ë©”ì„œë“œ ì¶”ê°€
        base_attrs.extend(['execute_workflow_command', 'get_workflow_status', 'update_file_directory'])
        return sorted(set(base_attrs))


def ensure_helpers_loaded():
    """AI Helpers v2ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œ"""
    import sys
    import pathlib
    
    try:
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
        project_root = pathlib.Path(__file__).parent.parent
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))
        
        # AI Helpers v2 ì‚¬ìš©
        if AI_HELPERS_V2_LOADED:
            helpers = AIHelpersV2()
            print("âœ… AI Helpers v2 ë¡œë“œ ì™„ë£Œ!")
            return helpers
        else:
            print("âš ï¸ AI Helpers v2 ë¡œë“œ ì‹¤íŒ¨ - ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            # ë¹ˆ helpers ê°ì²´ ë°˜í™˜
            return AIHelpersV2()
    
    except Exception as e:
        print(f"âŒ helpers ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None
    
def initialize_repl():
    """REPL í™˜ê²½ ì´ˆê¸°í™”"""
    global repl_globals
    
    # 1. helpers ê°ì²´ ìƒì„±
    helpers = ensure_helpers_loaded()
    if helpers:
        repl_globals['helpers'] = helpers
        repl_globals['h'] = helpers
        builtins.helpers = helpers
    else:
        sys.stderr.write('âš ï¸ helpers ë¡œë”© ì‹¤íŒ¨\n')
    
    # 2. í•µì‹¬ ê¸°ëŠ¥ë“¤ë§Œ ì „ì—­ì— ë…¸ì¶œ (q_toolsì™€ ì¤‘ë³µ ì œê±°)
    essential_funcs = {}
    
    # ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ (ìµœìš°ì„  - q_toolsì— ì—†ìŒ)
    if hasattr(helpers, 'execute_workflow_command'):
        essential_funcs['workflow'] = helpers.execute_workflow_command
        essential_funcs['wf'] = helpers.execute_workflow_command
    
    # í”„ë¡œì íŠ¸ ê´€ë¦¬ (ìµœìš°ì„  - q_toolsì— ì—†ìŒ)
    if hasattr(helpers, 'flow_project'):
        essential_funcs['flow_project'] = helpers.flow_project
        essential_funcs['fp'] = helpers.flow_project
    
    if hasattr(helpers, 'list_desktop_projects'):
        essential_funcs['list_projects'] = helpers.list_desktop_projects
        essential_funcs['lp'] = helpers.list_desktop_projects
    
    if hasattr(helpers, 'get_project_info'):
        essential_funcs['project_info'] = helpers.get_project_info
        essential_funcs['pi'] = helpers.get_project_info
    
    # íˆìŠ¤í† ë¦¬ ê´€ë¦¬ (ìµœìš°ì„  - q_toolsì— ì—†ìŒ)
    if hasattr(helpers, 'add_history_action'):
        essential_funcs['add_history_action'] = helpers.add_history_action
        essential_funcs['add_history'] = helpers.add_history_action
        essential_funcs['show_history'] = helpers.show_history
        essential_funcs['continue_from_last'] = helpers.continue_from_last
        essential_funcs['get_history'] = helpers.get_history
    
    # Git ê³ ê¸‰ ê¸°ëŠ¥ (q_toolsì— ì—†ëŠ” ê²ƒë“¤)
    if hasattr(helpers, 'git_add'):
        essential_funcs['git_add'] = helpers.git_add
    if hasattr(helpers, 'git_push'):
        essential_funcs['git_push'] = helpers.git_push
    if hasattr(helpers, 'git_pull'):
        essential_funcs['git_pull'] = helpers.git_pull
    
    # ê³ ê¸‰ íŒŒì¼ ê´€ë¦¬ (q_toolsì— ì—†ëŠ” ê²ƒë“¤)
    if hasattr(helpers, 'scan_directory_dict'):
        essential_funcs['scan_directory_dict'] = helpers.scan_directory_dict
    if hasattr(helpers, 'get_file_info'):
        essential_funcs['get_file_info'] = helpers.get_file_info
    if hasattr(helpers, 'create_directory'):
        essential_funcs['create_directory'] = helpers.create_directory
    if hasattr(helpers, 'move_file'):
        essential_funcs['move_file'] = helpers.move_file
    if hasattr(helpers, 'insert_block'):
        essential_funcs['insert_block'] = helpers.insert_block
    
    # ì „ì—­ì— ì¶”ê°€
    for name, func in essential_funcs.items():
        if callable(func):
            repl_globals[name] = func
    
    print(f"âœ… í•µì‹¬ helpers ê¸°ëŠ¥ ë¡œë“œ ì™„ë£Œ: {len(essential_funcs)}ê°œ (ì¤‘ë³µ ì œê±°)")
    
    # 3. ê¸°ë³¸ ëª¨ë“ˆë“¤
    import os
    import sys
    import json
    import time
    from pathlib import Path
    import datetime as dt
    import numpy as np
    import pandas as pd
    
    repl_globals.update({
        'os': os,
        'sys': sys,
        'json': json,
        'Path': Path,
        'datetime': dt,
        'np': np,
        'pd': pd,
        'time': time,
    })
    
    # 4. í”„ë¡œì íŠ¸ ìë™ ì´ˆê¸°í™” (í˜„ì¬ ë””ë ‰í† ë¦¬)
    try:
        # ê¸°ë³¸ì ìœ¼ë¡œ ai-coding-brain-mcp í”„ë¡œì íŠ¸ë¡œ ì„¤ì •
        default_project = "ai-coding-brain-mcp"
        
        # OS ë…ë¦½ì ì¸ Desktop ê²½ë¡œ ì°¾ê¸°
        desktop_paths = [
            Path.home() / "Desktop",  # ì˜ë¬¸ Windows/Mac/Linux
            Path.home() / "ë°”íƒ•í™”ë©´",  # í•œê¸€ Windows
            Path.home() / "æ¡Œé¢",      # ì¤‘êµ­ì–´
            Path.home() / "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—"  # ì¼ë³¸ì–´
        ]
        
        project_path = None
        for desktop in desktop_paths:
            if desktop.exists():
                test_path = desktop / default_project
                if test_path.exists():
                    project_path = test_path
                    os.chdir(str(project_path))
                    project_name = default_project
                    break
        
        # í”„ë¡œì íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        if not project_path:
            project_path = Path.cwd()
            project_name = project_path.name
    except Exception as e:
        pass
    
    # 5. Git Version Manager (ì œê±°ë¨ - íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ)
    # git_version_manager ëª¨ë“ˆì´ í”„ë¡œì íŠ¸ì— ì—†ì–´ ì œê±°
    git_manager = None

    # 6. q_tools ìë™ ë¡œë“œ (ì¶”ê°€ë¨)
    try:
        import sys
        import os
        
        # q_tools ê²½ë¡œ ì¶”ê°€
        current_dir = os.getcwd()
        python_path = os.path.join(current_dir, "python")
        if python_path not in sys.path:
            sys.path.insert(0, python_path)
        
        # q_tools ëª¨ë“  í•¨ìˆ˜ ë¡œë“œ
        import q_tools
        q_functions = {}
        for name in dir(q_tools):
            if not name.startswith('_') and callable(getattr(q_tools, name)):
                q_functions[name] = getattr(q_tools, name)
        
        # repl_globalsì— q_tools í•¨ìˆ˜ë“¤ ì¶”ê°€
        repl_globals.update(q_functions)
        
        # builtinsì—ë„ ì¶”ê°€ (ê¸€ë¡œë²Œ ì ‘ê·¼ ê°€ëŠ¥)
        for name, func in q_functions.items():
            setattr(builtins, name, func)
        
        print(f"âœ… q_tools ë¡œë“œ ì™„ë£Œ! {len(q_functions)}ê°œ í•¨ìˆ˜ ì‚¬ìš© ê°€ëŠ¥")
        
    except Exception as e:
        pass
    
    # 7. AST ê¸°ë°˜ ì½”ë“œ ë„êµ¬ ìë™ ë¡œë“œ (ì¶”ê°€ë¨)
    try:
        # ai_helpers_v2 ê²½ë¡œ ì¶”ê°€
        ai_helpers_path = os.path.join(python_path, "ai_helpers_v2")
        if ai_helpers_path not in sys.path:
            sys.path.insert(0, ai_helpers_path)

        # 1. ez_code ê°œì„ ëœ í•¨ìˆ˜ë“¤
        try:
            from ez_code import ez_parse, ez_replace, ez_view, ez_replace_safe
            repl_globals.update({
                'ez_parse': ez_parse,
                'ez_replace': ez_replace,
                'ez_view': ez_view,
                'ez_replace_safe': ez_replace_safe,
                # ì§§ì€ ë³„ì¹­ ì¶”ê°€
                'ezp': ez_parse,      # íŒŒì‹±
                'ezr': ez_replace,    # êµì²´
                'ezv': ez_view,       # ë³´ê¸°
                'ezrs': ez_replace_safe  # ì•ˆì „í•œ êµì²´
            })
            print("  âœ… ez_code í•¨ìˆ˜ ë¡œë“œ: ez_parse(ezp), ez_replace(ezr), ez_view(ezv), ez_replace_safe(ezrs)")
        except Exception as e:
            print(f"  âŒ ez_code ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 2. ê°œì„ ëœ AST íŒŒì„œ
        try:
            from improved_ast_parser import ez_parse_advanced, ez_parse_cached, ImprovedASTParser
            repl_globals.update({
                'ez_parse_advanced': ez_parse_advanced,
                'ez_parse_cached': ez_parse_cached,
                'ImprovedASTParser': ImprovedASTParser,
                # ì§§ì€ ë³„ì¹­
                'ezpa': ez_parse_advanced,  # ê³ ê¸‰ íŒŒì‹±
                'ezpc': ez_parse_cached     # ìºì‹œëœ íŒŒì‹±
            })
            print("  âœ… ê°œì„ ëœ AST íŒŒì„œ ë¡œë“œ: ez_parse_advanced(ezpa), ez_parse_cached(ezpc)")
        except Exception as e:
            print(f"  âŒ improved_ast_parser ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 3. ì•ˆì „í•œ ì½”ë“œ ìˆ˜ì • ë„êµ¬
        try:
            from safe_code_modifier import SafeCodeModifier
            repl_globals.update({
                'SafeCodeModifier': SafeCodeModifier
            })
            # ê°„í¸í•œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            safe_modifier = SafeCodeModifier()
            repl_globals['safe_modifier'] = safe_modifier
            repl_globals['safe_replace'] = safe_modifier.safe_replace
            repl_globals['sr'] = safe_modifier.safe_replace  # ì§§ì€ ë³„ì¹­
            print("  âœ… ì•ˆì „í•œ ì½”ë“œ ìˆ˜ì • ë„êµ¬ ë¡œë“œ: SafeCodeModifier, safe_replace(sr)")
        except Exception as e:
            print(f"  âŒ safe_code_modifier ë¡œë“œ ì‹¤íŒ¨: {e}")

        print("âœ… AST ê¸°ë°˜ ì½”ë“œ ë„êµ¬ ë¡œë“œ ì™„ë£Œ!")

        # ì‚¬ìš© ê°€ì´ë“œ ì¶œë ¥
        print("""
ğŸ“š AST ì½”ë“œ ë„êµ¬ ì‚¬ìš©ë²•:
  â€¢ ezp('file.py') - íŒŒì¼ êµ¬ì¡° íŒŒì‹±
  â€¢ ezv('file.py', 'function_name') - í•¨ìˆ˜ ì½”ë“œ ë³´ê¸°
  â€¢ ezr('file.py', 'function_name', new_code) - í•¨ìˆ˜ êµì²´
  â€¢ ezrs('file.py', 'function_name', new_code) - ì•ˆì „í•œ êµì²´ (ë¬¸ë²• ê²€ì¦)
  â€¢ ezpa('file.py', include_docstrings=True) - ê³ ê¸‰ íŒŒì‹±
  â€¢ sr('file.py', 'function_name', new_code) - ì•ˆì „í•œ êµì²´ (ë³„ì¹­)
        """)

    except Exception as e:
        print(f"âŒ AST ê¸°ë°˜ ì½”ë“œ ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")

    except Exception as e:
        print(f"âŒ AST ê¸°ë°˜ ì½”ë“œ ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")



    # 7. AST ê¸°ë°˜ ì½”ë“œ ë„êµ¬ ìë™ ë¡œë“œ (ì¶”ê°€ë¨)
    try:
        # ai_helpers_v2 ê²½ë¡œ ì¶”ê°€
        ai_helpers_path = os.path.join(python_path, "ai_helpers_v2")
        if ai_helpers_path not in sys.path:
            sys.path.insert(0, ai_helpers_path)

        # 1. ez_code ê°œì„ ëœ í•¨ìˆ˜ë“¤
        try:
            from ez_code import ez_parse, ez_replace, ez_view, ez_replace_safe
            repl_globals.update({
                'ez_parse': ez_parse,
                'ez_replace': ez_replace,
                'ez_view': ez_view,
                'ez_replace_safe': ez_replace_safe
            })
            print("  âœ… ez_code í•¨ìˆ˜ ë¡œë“œ: ez_parse, ez_replace, ez_view, ez_replace_safe")
        except Exception as e:
            print(f"  âŒ ez_code ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 2. ê°œì„ ëœ AST íŒŒì„œ
        try:
            from improved_ast_parser import ez_parse_advanced, ez_parse_cached, ImprovedASTParser
            repl_globals.update({
                'ez_parse_advanced': ez_parse_advanced,
                'ez_parse_cached': ez_parse_cached,
                'ImprovedASTParser': ImprovedASTParser
            })
            print("  âœ… ê°œì„ ëœ AST íŒŒì„œ ë¡œë“œ: ez_parse_advanced, ez_parse_cached")
        except Exception as e:
            print(f"  âŒ improved_ast_parser ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 3. ì•ˆì „í•œ ì½”ë“œ ìˆ˜ì • ë„êµ¬
        try:
            from safe_code_modifier import SafeCodeModifier
            repl_globals.update({
                'SafeCodeModifier': SafeCodeModifier
            })
            # ê°„í¸í•œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            safe_modifier = SafeCodeModifier()
            repl_globals['safe_modifier'] = safe_modifier
            repl_globals['safe_replace'] = safe_modifier.safe_replace
            print("  âœ… ì•ˆì „í•œ ì½”ë“œ ìˆ˜ì • ë„êµ¬ ë¡œë“œ: SafeCodeModifier, safe_replace")
        except Exception as e:
            print(f"  âŒ safe_code_modifier ë¡œë“œ ì‹¤íŒ¨: {e}")

        print("âœ… AST ê¸°ë°˜ ì½”ë“œ ë„êµ¬ ë¡œë“œ ì™„ë£Œ!")

    except Exception as e:
        print(f"âŒ AST ê¸°ë°˜ ì½”ë“œ ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")


        print(f"âŒ q_tools ë¡œë“œ ì‹¤íŒ¨: {e}")

# ============================================================================
# ğŸ’» ì½”ë“œ ì‹¤í–‰
# ============================================================================

def safe_exec(code: str, globals_dict: dict) -> tuple[bool, str]:
    """
    ì•ˆì „í•œ ì½”ë“œ ì‹¤í–‰ - Enhanced v2 í†µí•©

    v2ê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ì„¤ì •ì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ v2 ì‚¬ìš©,
    ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
    """
    # Enhanced Safe Execution v2 ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)
    if SAFE_EXEC_V2_AVAILABLE and CONFIG.get('use_safe_exec_v2', True):
        try:
            success, output = safe_exec_v2(code, globals_dict)
            return success, output
        except Exception as e:
            # v2 ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
            print(f"âš ï¸ Safe Execution v2 ì˜¤ë¥˜, ê¸°ë³¸ ëª¨ë“œë¡œ ì „í™˜: {e}")

    # ê¸°ì¡´ ë°©ì‹ (enhanced_safe_exec ë˜ëŠ” ê¸°ë³¸)
    try:
        return enhanced_safe_exec(code, globals_dict)
    except NameError:
        # enhanced_safe_execê°€ importë˜ì§€ ì•Šì€ ê²½ìš° ê³„ì† ì§„í–‰
        pass

    # ìµœì¢… í´ë°± - ê¸°ë³¸ ì‹¤í–‰
    from textwrap import dedent

    try:
        # ë“¤ì—¬ì“°ê¸° ì •ë¦¬
        dedented_code = dedent(code).strip()

        # ì»´íŒŒì¼ ë‹¨ê³„ (êµ¬ë¬¸ ê²€ì‚¬)
        try:
            compiled_code = compile(dedented_code, '<json_repl>', 'exec')
        except SyntaxError as e:
            error_msg = f"âŒ êµ¬ë¬¸ ì˜¤ë¥˜: {e.msg}"
            if e.lineno:
                error_msg += f" (ë¼ì¸ {e.lineno})"
            return False, error_msg

        # ì‹¤í–‰
        exec(compiled_code, globals_dict)
        return True, ""

    except Exception as e:
        return False, f"âŒ ëŸ°íƒ€ì„ ì˜¤ë¥˜: {type(e).__name__}: {str(e)}"
def execute_code(code: str) -> Dict[str, Any]:
    """Python ì½”ë“œ ì‹¤í–‰"""
    global execution_count
    
    start_time = time.time()
    
    try:
        # safe_execë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ì‹¤í–‰
        # safe_execëŠ” ì´ë¯¸ stdoutì„ ìº¡ì²˜í•˜ì—¬ ë°˜í™˜í•¨
        success, output_or_error = safe_exec(code, repl_globals)
        
        if success:
            stdout_output = output_or_error
            stderr_output = ""
        else:
            stdout_output = ""
            stderr_output = output_or_error
            
        execution_count += 1
        
        # ìë™ ì €ì¥ (10íšŒë§ˆë‹¤)
        if execution_count % 10 == 0 and 'save_context' in repl_globals:
            try:
                repl_globals['save_context']()
            except Exception:
                pass
        
        # ë³€ìˆ˜ ê°œìˆ˜ ê³„ì‚°
        user_vars = [k for k in repl_globals.keys() 
                    if not k.startswith('_') and k not in ['__builtins__']]
        
        return {
            "success": True,
            "stdout": stdout_output,
            "stderr": stderr_output,
            "execution_time": time.time() - start_time,
            "variable_count": len(user_vars),
            "execution_count": execution_count,
            "session_mode": "JSON_REPL",
            "note": "JSON REPL Session - Variables persist between executions",
            "debug_info": {
                "repl_process_active": True,
                "repl_ready": True,
                "execution": "success"
            }
        }
        
    except Exception as e:
        execution_count += 1
        
        return {
            "success": False,
            "stdout": "",
            "stderr": f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}",
            "execution_time": time.time() - start_time,
            "variable_count": len(repl_globals),
            "execution_count": execution_count,
            "error": str(e),
            "error_type": type(e).__name__,
            "session_mode": "JSON_REPL",
            "debug_info": {
                "repl_process_active": True,
                "repl_ready": True,
                "execution": "error"
            }
        }

# ============================================================================
# ğŸ”Œ JSON í†µì‹ 
# ============================================================================

def read_json_input() -> Optional[str]:
    """EOT ë¬¸ìë¡œ ì¢…ë£Œë˜ëŠ” JSON ì…ë ¥ ì½ê¸°"""
    try:
        input_data = ""
        while True:
            char = sys.stdin.read(1)
            if not char:  # EOF
                return None
            if char == '\x04':  # EOT
                break
            input_data += char
        
        return input_data.strip()
    except Exception:
        return None

def send_json_response(response: Dict[str, Any]):
    """JSON ì‘ë‹µ ì „ì†¡ (EOT ë¬¸ìë¡œ ì¢…ë£Œ)"""
    try:
        response['timestamp'] = dt.datetime.now().isoformat()
        response_json = json.dumps(response, ensure_ascii=False)
        # í”„ë¡œí† ì½œ íƒœê·¸ë¡œ ê°ì‹¸ì„œ ì•ˆì „í•˜ê²Œ ì „ì†¡
        sys.stdout.write("__JSON_START__" + response_json + "__JSON_END__\x04")
        sys.stdout.flush()
    except Exception as e:
        error_response = {
            "success": False,
            "error": f"Response encoding error: {str(e)}",
            "error_type": "ResponseError"
        }
        sys.stdout.write("__JSON_START__" + json.dumps(error_response) + "__JSON_END__\x04")
        sys.stdout.flush()

# ============================================================================
# ğŸ”„ ë©”ì¸ ë£¨í”„
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
    global repl_globals
    
    # í•„ìš”í•œ ëª¨ë“ˆ import
    import sys
    import platform
    import subprocess
    import os
    
    # Windows UTF-8 ì„¤ì •
    if platform.system() == 'Windows':
        try:
            subprocess.run(['chcp', '65001'], shell=True, capture_output=True)
        except subprocess.SubprocessError:
            pass
    
    # ìŠ¤íŠ¸ë¦¼ ì¸ì½”ë”© ì„¤ì •
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    else:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'replace')
    
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    else:
        import codecs
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'replace')
    
    # ê¸°ë³¸ ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
    try:
        from pathlib import Path
        
        # OS ë…ë¦½ì ì¸ Desktop ê²½ë¡œ ì°¾ê¸°
        desktop_paths = [
            Path.home() / "Desktop",  # ì˜ë¬¸ Windows/Mac/Linux
            Path.home() / "ë°”íƒ•í™”ë©´",  # í•œê¸€ Windows
            Path.home() / "æ¡Œé¢",      # ì¤‘êµ­ì–´
            Path.home() / "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—"  # ì¼ë³¸ì–´
        ]
        
        for desktop in desktop_paths:
            if desktop.exists():
                default_project_path = desktop / "ai-coding-brain-mcp"
                if default_project_path.exists():
                    os.chdir(str(default_project_path))
                    break
    except Exception:
        pass
    
    # ì´ˆê¸°í™”
    initialize_repl()
    
    # ============================================================================
    # ğŸ›¡ï¸ Safe Wrapper ìë™ ë¡œë“œ
    # ============================================================================
    try:
        # safe_wrapper ëª¨ë“ˆ import
        import sys
        import os
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ python ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€  
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        python_dir = os.path.join(project_root, 'python')
        if python_dir not in sys.path:
            sys.path.insert(0, python_dir)
        
        from safe_wrapper import register_safe_helpers
        
        # helpersê°€ repl_globalsì— ìˆëŠ”ì§€ í™•ì¸
        if 'helpers' in repl_globals:
            # ì•ˆì „í•œ í—¬í¼ í•¨ìˆ˜ë“¤ì„ ì „ì—­ì— ë“±ë¡
            register_safe_helpers(repl_globals['helpers'], repl_globals)
            print("âœ… Safe Helper í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ", file=sys.stderr)
        else:
            print("âš ï¸ helpersë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ Safe Helper ë¡œë“œ ê±´ë„ˆëœ€", file=sys.stderr)
            
    except Exception as e:
        print(f"âŒ Safe Helper ë¡œë“œ ì‹¤íŒ¨: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
    
    # ì´ì „ ì„¸ì…˜ ì •ë³´ í‘œì‹œ
    try:
        from persistent_history import PersistentHistoryManager
        history_manager = PersistentHistoryManager()
        sync_data = history_manager.get_workflow_sync_data()
        
        if sync_data['total_actions'] > 0:
            print("\nğŸ“Š ì´ì „ ì„¸ì…˜ ì •ë³´:")
            print(f"   ì´ ì‘ì—…: {sync_data['total_actions']}ê°œ")
            print(f"   ëŒ€í™” ìˆ˜: {sync_data['conversations']}ê°œ")
            if sync_data['last_action']:
                print(f"   ë§ˆì§€ë§‰ ì‘ì—…: {sync_data['last_action']['action']} ({sync_data['last_action']['timestamp']})")
            print("\nğŸ’¡ continue_from_last()ë¡œ ì´ì „ ì‘ì—…ì„ ì´ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    except Exception:
        pass
    
    # ì¤€ë¹„ ì™„ë£Œ ì‹ í˜¸
    print("__READY__", flush=True)
    
    # ë©”ì¸ ë£¨í”„
    try:
        while True:
            # JSON ì…ë ¥ ì½ê¸°
            code_input = read_json_input()
            if code_input is None:
                break
            
            try:
                # ìš”ì²­ íŒŒì‹±
                request = json.loads(code_input)
                request_id = request.get('id')
                code = request.get('code', '')
                language = request.get('language', 'python')
                
                if language != 'python':
                    response = {
                        "success": False,
                        "error": f"Unsupported language: {language}",
                        "error_type": "LanguageError"
                    }
                else:
                    # ì½”ë“œ ì‹¤í–‰
                    response = execute_code(code)
                    response['language'] = language
                
                # ìš”ì²­ ID ìœ ì§€
                if request_id:
                    response['id'] = request_id
                    
            except json.JSONDecodeError as e:
                response = {
                    "success": False,
                    "error": f"Invalid JSON: {str(e)}",
                    "error_type": "JSONDecodeError"
                }
            
            # ì‘ë‹µ ì „ì†¡
            send_json_response(response)
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ JSON REPL Session ì¢…ë£Œ", file=sys.stderr)
    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)
    finally:
        # ì¢…ë£Œ ì‹œ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        try:
            if 'save_context' in repl_globals:
                repl_globals['save_context']()
                print("âœ… ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ì €ì¥", file=sys.stderr)
        except Exception:
            pass


# ============================================================================
# ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    main()